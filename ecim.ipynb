{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcusapel/ecletp/blob/main/ecim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BM-UakduoXM"
      },
      "source": [
        "# OSDU Hands-on Lab Environment Setup\n",
        "\n",
        "This notebook provides hands-on exercises for interacting with the OSDU Data Platform using Python and REST APIs.\n",
        "\n",
        "**Target Audience:** Users familiar with basic data concepts but not necessarily developers.\n",
        "\n",
        "**Goal:** To demonstrate fundamental interactions with OSDU services like Storage, Search, Legal, and Domain Data Management Services (DDMS).\n",
        "\n",
        "**Structure:**\n",
        "1.  **Initial Setup:** Dependency installation and authentication.\n",
        "2.  **Lab Exercises:** Step-by-step instructions for specific tasks.\n",
        "\n",
        "**How to Use:**\n",
        "*   Read the Markdown cells for explanations.\n",
        "*   Run the Code cells sequentially by clicking the 'Play' button or using `Shift+Enter`.\n",
        "*   Observe the output generated by each code cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfgZcHkvuoXP"
      },
      "source": [
        "## 1. Initial Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTlyflwouoXP"
      },
      "source": [
        "### 1.1 Install Dependencies\n",
        "\n",
        "This command installs the necessary Python libraries required for the labs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzRPPy4MuoXP",
        "outputId": "ea35313a-2eea-4c76-879e-bedfddab9d60",
        "tags": [
          "setup"
        ]
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m657.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install --quiet --extra-index-url https://community.opengroup.org/api/v4/projects/148/packages/pypi/simple requests requests-oauthlib osdu-api==0.28.0 tenacity dotenv ipython pandas pyarrow matplotlib plotly numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXbf53GouoXQ"
      },
      "source": [
        "### 1.2 Configure Connection and Authentication\n",
        "\n",
        "This section configures the connection details for your OSDU instance and handles authentication. It attempts to load configuration from a `.env` file first, and falls back to hardcoded variables if the file is not found or incomplete.\n",
        "\n",
        "**Using a `.env` file (Recommended):**\n",
        "\n",
        "1.  Create a file named `.env` in the same directory as this notebook.\n",
        "1.  Copy the content from .env.sample and fill out the variables.\n",
        "1.  Add the following environment variables to the file, replacing the example values with your actual OSDU instance details:\n",
        "1.  Save the `.env` file.\n",
        "\n",
        "*(On Windows, you can create this file using Notepad or any text editor. Make sure it's saved as `.env` and not `.env.txt`)*\n",
        "\n",
        "| Variable | Description | Example |\n",
        "|-----|-------------|---------|\n",
        "| osdu_endpoint | This is the base endpoint of you OSDU instance (before /api/) | https://osdu.osdu-bootcamp.com/api/config/v1/postman-environment |\n",
        "| osdu_data_partition_id | This is the data partition ID you want to connect to | osdu |\n",
        "| osdu_group_domain | This is the Entitlements Domain (or Group Domain) (users@{dataPartitionId}.<span style=\"color:green\">{osduGroupDomain}</span>) | company.com |\n",
        "| token_endpoint | OAuth2.0 *token* endpoint (ends with /token) | https://idpdomain.com/oauth2/v2.0/token |\n",
        "| client_id | *optional* App registration/client ID | osdu-admin |\n",
        "| client_secret | *optional* App registration/client secret | YTOonDBJfSGxoqje |\n",
        "| scope | *optional* Permissions that the token will have | aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee/.default |\n",
        "| refresh_token | *optional* User Refresh Token if client credentials are not supported | RjY2NjM5NzA2OWJjuE7c... |\n",
        "\n",
        "**Fallback (Hardcoded):**\n",
        "\n",
        "If the `.env` file is not found or you prefer not to use one, you can directly edit the `initialize_from_local_variables` function within the code cell below to set your configuration details. **However, avoid committing sensitive information like secrets directly into notebooks.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlueexMuuoXR"
      },
      "source": [
        "### 1.3 Generate Personal Identifier\n",
        "\n",
        "This creates a unique suffix (`user_id`) that will be appended to the names of resources created during this lab session. This helps prevent naming conflicts if multiple users run the labs simultaneously against the same OSDU instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-ILOCK-uoXR",
        "outputId": "97f75ca9-b12d-4431-8c9a-217088184667",
        "tags": [
          "setup",
          "user-id"
        ]
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated user_id for this session: 7073\n",
            "This ID will be used to create unique resource names.\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "# Generate a random user_id with 4 digits\n",
        "user_id = f\"{random.randint(1000, 9999)}\"\n",
        "print(f\"Generated user_id for this session: {user_id}\")\n",
        "print(\"This ID will be used to create unique resource names.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "id": "JF8w6-GxuoXQ",
        "outputId": "2915bb15-b6bd-4225-cd4d-694c693b2ee3",
        "tags": [
          "setup",
          "authentication"
        ]
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration file '.env' not found or empty.\n",
            "Falling back to loading configuration from local variables...\n",
            "Configuration loaded from local variables within the notebook.\n",
            "Configuration loaded. Attempting authentication...\n",
            "Token is expired or not available. Fetching new token...\n",
            "Attempting token fetch using client credentials...\n",
            "Client credentials flow failed: HTTPSConnectionPool(host='keycloak.osdu-bootcamp.com', port=443): Max retries exceeded with url: /realms/osdu/protocol/openid-connect/token (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x79e2751ea720>, 'Connection to keycloak.osdu-bootcamp.com timed out. (connect timeout=None)')). Checking for refresh token.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <div style=\"\n",
              "            background-color: lightcoral;\n",
              "            color: black;\n",
              "            font-size: 16pt;\n",
              "            font-weight: bold;\n",
              "            text-align: center;\n",
              "            padding: 15px;\n",
              "            border-radius: 8px;\n",
              "            margin: 15px 0;\n",
              "        \">\n",
              "            AUTHENTICATION FAILED<br><span style='font-size: 12pt;'>Exception: Failed to obtain authentication token using both client credentials and refresh token methods.</span>\n",
              "        </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import time\n",
        "import json\n",
        "import os\n",
        "import requests\n",
        "import pandas as pd\n",
        "import urllib\n",
        "from oauthlib.oauth2 import BackendApplicationClient\n",
        "from requests_oauthlib import OAuth2Session\n",
        "from dotenv import load_dotenv\n",
        "from IPython.display import Markdown, display, HTML\n",
        "\n",
        "# --- Configuration Loading ---\n",
        "dotenv_file = \".env\"\n",
        "\n",
        "# Initialize global variables to None\n",
        "osdu_endpoint = None\n",
        "osdu_data_partition_id = None\n",
        "osdu_group_domain = None\n",
        "token_endpoint = None\n",
        "client_id = None\n",
        "client_secret = None\n",
        "scope = None\n",
        "refresh_token = None\n",
        "headers = None\n",
        "parquet_headers = None\n",
        "entitlements_domain = None\n",
        "\n",
        "def initialize_from_local_variables():\n",
        "    \"\"\"Sets config from hardcoded values if .env fails. **Modify with caution**.\"\"\"\n",
        "    global osdu_endpoint, osdu_data_partition_id, osdu_group_domain, token_endpoint, client_id, client_secret, scope, refresh_token\n",
        "\n",
        "    # --- OSDU instance configuration (MODIFY HERE IF NOT USING .env) ---\n",
        "    local_osdu_endpoint = \"https://osdu.osdu-bootcamp.com\"\n",
        "    local_osdu_data_partition_id = \"osdu\"\n",
        "    local_osdu_group_domain = \"group\"\n",
        "\n",
        "    # --- OAuth2 configuration (MODIFY HERE IF NOT USING .env) ---\n",
        "    local_token_endpoint = \"https://keycloak.osdu-bootcamp.com/realms/osdu/protocol/openid-connect/token\"  # e.g., \"https://your-idp.com/oauth2/v2.0/token\"\n",
        "    local_client_id = \"osdu-admin\"\n",
        "    local_client_secret = \"YTOonDBJfSGxoqje\"\n",
        "    local_scope = []\n",
        "    local_refresh_token = \"\" # Required only if client_credentials grant is not supported\n",
        "    # --- End of modification section ---\n",
        "\n",
        "    if local_osdu_endpoint and local_osdu_data_partition_id: # Basic check if values were entered\n",
        "        osdu_endpoint = local_osdu_endpoint\n",
        "        osdu_data_partition_id = local_osdu_data_partition_id\n",
        "        osdu_group_domain = local_osdu_group_domain\n",
        "        token_endpoint = local_token_endpoint\n",
        "        client_id = local_client_id\n",
        "        client_secret = local_client_secret\n",
        "        scope = local_scope\n",
        "        refresh_token = local_refresh_token\n",
        "        print(f\"Configuration loaded from local variables within the notebook.\")\n",
        "        return True\n",
        "    else:\n",
        "        print(\"Local variables seem empty, skipping.\")\n",
        "        return False\n",
        "\n",
        "def initialize_from_env_file(file_path):\n",
        "    \"\"\"Loads config from a .env file.\"\"\"\n",
        "    global osdu_endpoint, osdu_data_partition_id, osdu_group_domain, token_endpoint, client_id, client_secret, scope, refresh_token\n",
        "    try:\n",
        "        if load_dotenv(file_path, override=True):\n",
        "            print(f\"Attempting to load configuration from '{file_path}'...\")\n",
        "            osdu_endpoint = os.getenv(\"OSDU_ENDPOINT\")\n",
        "            osdu_data_partition_id = os.getenv(\"OSDU_DATA_PARTITION_ID\")\n",
        "            osdu_group_domain = os.getenv(\"OSDU_GROUP_DOMAIN\")\n",
        "            token_endpoint = os.getenv(\"TOKEN_ENDPOINT\")\n",
        "            client_id = os.getenv(\"CLIENT_ID\")\n",
        "            client_secret = os.getenv(\"CLIENT_SECRET\")\n",
        "            scope_str = os.getenv(\"SCOPE\")\n",
        "            scope = list(map(lambda x: x.strip(), scope_str.split(\",\"))) if scope_str else None\n",
        "            refresh_token = os.getenv(\"REFRESH_TOKEN\")\n",
        "\n",
        "            # Basic validation\n",
        "            if all([osdu_endpoint, osdu_data_partition_id, token_endpoint, client_id, (client_secret or refresh_token)]):\n",
        "                 print(f\"Configuration successfully loaded from '{file_path}'.\")\n",
        "                 return True\n",
        "            else:\n",
        "                print(f\"Configuration file '{file_path}' is missing one or more required variables.\")\n",
        "                return False\n",
        "        else:\n",
        "            print(f\"Configuration file '{file_path}' not found or empty.\")\n",
        "            return False\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading configuration from '{file_path}': {e}\")\n",
        "        return False\n",
        "\n",
        "# --- Token Management ---\n",
        "_token_context = {\n",
        "    \"token\": None,\n",
        "    \"expires_at\": 0\n",
        "}\n",
        "\n",
        "def fetch_new_token():\n",
        "    \"\"\"Fetches a new OAuth2 token using client credentials or refresh token.\"\"\"\n",
        "    if not all([token_endpoint, client_id]):\n",
        "        raise ValueError(\"Token Endpoint and Client ID must be configured.\")\n",
        "\n",
        "    token = None\n",
        "    oauth = None # Initialize oauth session\n",
        "\n",
        "    # Try client credentials flow first (requires client_secret)\n",
        "    if client_secret:\n",
        "        try:\n",
        "            print(\"Attempting token fetch using client credentials...\")\n",
        "            client = BackendApplicationClient(client_id=client_id) #, scope=scope)\n",
        "            oauth = OAuth2Session(client=client)\n",
        "            token = oauth.fetch_token(\n",
        "                token_url=token_endpoint,\n",
        "                client_id=client_id,\n",
        "                client_secret=client_secret #,\n",
        "                # scope=scope\n",
        "            )\n",
        "            print(\"Token fetched successfully via client credentials.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Client credentials flow failed: {e}. Checking for refresh token.\")\n",
        "            token = None # Ensure token is None if this flow fails\n",
        "\n",
        "    # If client credentials failed or no secret provided, try refresh token flow (requires refresh_token)\n",
        "    if token is None and refresh_token:\n",
        "        try:\n",
        "            print(\"Attempting token refresh...\")\n",
        "            # Need a session object even for refresh if not created above\n",
        "            if oauth is None:\n",
        "                 client = BackendApplicationClient(client_id=client_id, scope=scope)\n",
        "                 oauth = OAuth2Session(client=client)\n",
        "\n",
        "            token = oauth.refresh_token(\n",
        "                token_url=token_endpoint,\n",
        "                client_id=client_id, # Some IDPs might still require client_id/secret for refresh\n",
        "                client_secret=client_secret,\n",
        "                refresh_token=refresh_token\n",
        "            )\n",
        "            print(f\"Token refreshed successfully.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Refresh token flow failed: {e}\")\n",
        "            token = None\n",
        "\n",
        "    # If both flows failed\n",
        "    if token is None:\n",
        "         raise ConnectionError(\"Failed to obtain authentication token using both client credentials and refresh token methods.\")\n",
        "\n",
        "    _token_context[\"token\"] = token[\"access_token\"]\n",
        "    # Use 'expires_at' if provided, otherwise calculate from 'expires_in'\n",
        "    _token_context[\"expires_at\"] = token.get(\"expires_at\", time.time() + token.get(\"expires_in\", 3600) - 60) # 60s buffer\n",
        "\n",
        "def get_token():\n",
        "    \"\"\"Gets the current valid token, fetching a new one if needed.\"\"\"\n",
        "    if _token_context[\"token\"] is None or _token_context[\"expires_at\"] <= time.time():\n",
        "        print(\"Token is expired or not available. Fetching new token...\")\n",
        "        fetch_new_token()\n",
        "    # else:\n",
        "        # print(\"Using existing token.\") # Optional: for debugging\n",
        "    return _token_context[\"token\"]\n",
        "\n",
        "# --- UI Helpers ---\n",
        "def printmd(string):\n",
        "    \"\"\"Displays text as Markdown.\"\"\"\n",
        "    display(Markdown(string))\n",
        "\n",
        "def display_banner(text, color):\n",
        "    \"\"\"Displays a colored banner.\"\"\"\n",
        "    background_color = 'lightgreen' if color == 'green' else 'lightcoral'\n",
        "    text_color = 'black'\n",
        "    html_banner = f'''\n",
        "        <div style=\"\n",
        "            background-color: {background_color};\n",
        "            color: {text_color};\n",
        "            font-size: 16pt;\n",
        "            font-weight: bold;\n",
        "            text-align: center;\n",
        "            padding: 15px;\n",
        "            border-radius: 8px;\n",
        "            margin: 15px 0;\n",
        "        \">\n",
        "            {text}\n",
        "        </div>\n",
        "    '''\n",
        "    display(HTML(html_banner))\n",
        "\n",
        "# --- Initialization and Validation ---\n",
        "if __name__ == \"__main__\":\n",
        "    config_loaded = False\n",
        "    # Try loading from .env file first\n",
        "    if initialize_from_env_file(dotenv_file):\n",
        "        config_loaded = True\n",
        "    else:\n",
        "        # Fallback to local variables if .env loading fails\n",
        "        print(\"Falling back to loading configuration from local variables...\")\n",
        "        if initialize_from_local_variables():\n",
        "            config_loaded = True\n",
        "        else:\n",
        "             print(\"Failed to load configuration from local variables as well.\")\n",
        "\n",
        "    if not config_loaded:\n",
        "        error_message = \"CONFIGURATION FAILED: Could not load connection details from .env file or local variables. Please check the setup instructions.\"\n",
        "        display_banner(error_message, color='red')\n",
        "        # Stop execution if config failed\n",
        "        raise ValueError(error_message)\n",
        "    else:\n",
        "        try:\n",
        "            print(\"Configuration loaded. Attempting authentication...\")\n",
        "            token = get_token() # This will trigger fetch_new_token\n",
        "\n",
        "            # Construct Entitlements Domain (handle case where group domain might be missing)\n",
        "            if osdu_group_domain:\n",
        "                 entitlements_domain = f\"{osdu_data_partition_id}.{osdu_group_domain}\"\n",
        "            else:\n",
        "                 entitlements_domain = osdu_data_partition_id # Or handle as an error if required\n",
        "                 print(f\"Warning: OSDU_GROUP_DOMAIN is not set. Entitlements might not work as expected.\")\n",
        "\n",
        "            # Prepare standard request headers\n",
        "            headers = {\n",
        "                \"data-partition-id\": osdu_data_partition_id,\n",
        "                \"content-type\": \"application/json\",\n",
        "                \"accept\": \"application/json\",\n",
        "                \"authorization\": f\"Bearer {get_token()}\", # Use get_token() to ensure it's valid\n",
        "            }\n",
        "\n",
        "            # Prepare headers for Parquet uploads\n",
        "            parquet_headers = {\n",
        "                \"data-partition-id\": osdu_data_partition_id,\n",
        "                \"content-type\": \"application/x-parquet\",\n",
        "                \"accept\": \"application/json\", # Usually expect JSON response even for binary upload\n",
        "                \"authorization\": f\"Bearer {get_token()}\"\n",
        "            }\n",
        "\n",
        "            # Test connection with a simple Search API call\n",
        "            print(\"Testing connection to OSDU Search service...\")\n",
        "            test_url = f\"{osdu_endpoint}/api/search/v2/query\"\n",
        "            test_payload = json.dumps({\n",
        "                \"kind\": \"*:*:*:*\",\n",
        "                \"query\": \"*\",\n",
        "                \"limit\": 1\n",
        "            })\n",
        "\n",
        "            response = requests.post(test_url, headers=headers, data=test_payload)\n",
        "            response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                display_banner(\"AUTHENTICATION SUCCESSFUL<br><span style='font-size: 12pt;'>Connected to OSDU instance.</span>\", color='green')\n",
        "                print(f\"OSDU Endpoint: {osdu_endpoint}\")\n",
        "                print(f\"Data Partition ID: {osdu_data_partition_id}\")\n",
        "            else:\n",
        "                 # This case might not be reached due to raise_for_status, but included for completeness\n",
        "                 error_details = f\"<span style='font-size: 12pt;'>Received status code {response.status_code}.</span>\"\n",
        "                 display_banner(f\"AUTHENTICATION FAILED<br>{error_details}\", color='red')\n",
        "                 print(f\"Response: {response.text}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            error_details = f\"<span style='font-size: 12pt;'>Exception: {str(e)}</span>\"\n",
        "            display_banner(f\"AUTHENTICATION FAILED<br>{error_details}\", color='red')\n",
        "            # Optionally print more details for debugging\n",
        "            # import traceback\n",
        "            # traceback.print_exc()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kf9moPafPXUO"
      },
      "source": [
        "###1.4 Google Colab Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SN1TbR9NFvY1"
      },
      "outputs": [],
      "source": [
        "### 1.3 Google Colab Functions\n",
        "\n",
        "# get a file from the bucket\n",
        "from google.cloud import storage as google_storage\n",
        "import os\n",
        "\n",
        "def get_bytes(filename: str) -> bytes:\n",
        "  gs_client = google_storage.Client.create_anonymous_client()\n",
        "  bucket = gs_client.bucket(\"amsterdam-f2f-25\")\n",
        "  blob = bucket.get_blob(filename)\n",
        "  file_content = blob.download_as_bytes()\n",
        "  print(len(file_content))\n",
        "  return file_content\n",
        "\n",
        "def download_blob_to_file(blob_name: str, file_name: str):\n",
        "    \"\"\"Downloads a blob from the bucket to a local file.\"\"\"\n",
        "    os.makedirs('./assets', exist_ok=True)\n",
        "\n",
        "    destination_file_name = './assets/' + file_name\n",
        "\n",
        "    client = google_storage.Client.create_anonymous_client()\n",
        "    bucket = client.bucket(\"amsterdam-f2f-25\")\n",
        "    blob = bucket.blob(blob_name)\n",
        "\n",
        "    blob.download_to_filename(destination_file_name)\n",
        "    print(f\"Blob {blob_name} downloaded to {destination_file_name}.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKr1cMXNuoXR"
      },
      "source": [
        "# Lab 1: Using Core APIs\n",
        "\n",
        "This lab focuses on fundamental OSDU services like Entitlements, Legal, Schema, Search, Storage, and Dataset. We will perform operations like creating/managing groups, applying legal tags, exploring schemas, searching for records, and uploading/downloading data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs3-siQvuoXR"
      },
      "source": [
        "## OSDU Entitlements Service Lab\n",
        "\n",
        "This lab demonstrates how to interact with the OSDU Entitlements Service. The Entitlements Service manages user groups and their access permissions within a data partition.\n",
        "\n",
        "**Key Concepts:**\n",
        "*   **Groups:** Collections of users identified by an email address (e.g., `my-group@data-partition.domain.com`).\n",
        "*   **Members:** Users within a group, identified by their OSDU user ID.\n",
        "*   **Roles:** Permissions within a group (e.g., `OWNER`, `MEMBER`).\n",
        "\n",
        "**Documentation:**\n",
        "*   [Entitlements Service](https://osdu.pages.opengroup.org/platform/security-and-compliance/entitlements/)\n",
        "*   [Entitlements API](https://osdu.pages.opengroup.org/platform/security-and-compliance/entitlements/api/)\n",
        "*   [API Specification](https://community.opengroup.org/osdu/platform/security-and-compliance/entitlements/-/raw/master/docs/api/entitlements_openapi.yaml?ref_type=heads)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAbyI-pOuoXS"
      },
      "source": [
        "### Setup: Entitlements Lab\n",
        "\n",
        "This cell sets up the necessary variables for the Entitlements lab exercises.\n",
        "\n",
        "**Dependencies:**\n",
        "*   Requires the `requests` and `json` libraries (imported in the initial setup).\n",
        "*   Relies on variables defined during the initial authentication: `osdu_endpoint`, `headers`, `user_id`, `entitlements_domain`, `osdu_data_partition_id`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7VXavAfZuoXS",
        "tags": [],
        "outputId": "539d7017-2201-4d8b-db5e-ac1367f3ef00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Entitlements API Endpoint: https://osdu.osdu-bootcamp.com/api/entitlements/v2\n",
            "Using user email for membership actions: user7073\n"
          ]
        }
      ],
      "source": [
        "# Define the base endpoint for the Entitlements API\n",
        "entitlements_endpoint = f\"{osdu_endpoint}/api/entitlements/v2\"\n",
        "print(f\"Using Entitlements API Endpoint: {entitlements_endpoint}\")\n",
        "\n",
        "# IMPORTANT: Define the email address of the user who is authenticated.\n",
        "# This email MUST correspond to a valid user in the OSDU instance for adding/removing members.\n",
        "# The {user_id} variable (a random number) is used to create unique group names during the lab.\n",
        "# Example format: user.name@domain.com\n",
        "# Replace this with the ACTUAL user email if needed for specific OSDU environments.\n",
        "user_id_for_membership = f\"user{user_id}\" # Constructing a plausible email based on domain\n",
        "print(f\"Using user email for membership actions: {user_id_for_membership}\")\n",
        "\n",
        "# This variable will store the email of the group created in Step 2\n",
        "group_email = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ygn9x7siuoXS"
      },
      "source": [
        "### 1. List All Groups\n",
        "\n",
        "Retrieve a list of all entitlement groups within the data partition.\n",
        "\n",
        "**API Endpoint:** `GET /groups`\n",
        "**Access needed:** `service.entitlements.user`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "T0p7Ke5juoXS",
        "tags": [],
        "outputId": "9c8136f0-894b-4c84-b7b6-85ffc61298f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to list all groups...\n",
            "Error listing groups: HTTPSConnectionPool(host='osdu.osdu-bootcamp.com', port=443): Max retries exceeded with url: /api/entitlements/v2/groups?all (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x79e2536dbf50>, 'Connection to osdu.osdu-bootcamp.com timed out. (connect timeout=None)'))\n"
          ]
        }
      ],
      "source": [
        "print(\"Attempting to list all groups...\")\n",
        "try:\n",
        "    # Send a GET request to the /groups endpoint\n",
        "    list_groups_response = requests.get(\n",
        "        f\"{entitlements_endpoint}/groups?all\",\n",
        "        headers=headers\n",
        "    )\n",
        "    # Raise an exception if the API returned an error (e.g., 4xx or 5xx)\n",
        "    list_groups_response.raise_for_status()\n",
        "\n",
        "    # Pretty print the JSON response\n",
        "    print(f\"List Groups Status Code: {list_groups_response.status_code}\")\n",
        "    print(json.dumps(list_groups_response.json(), indent=2))\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error listing groups: {e}\")\n",
        "    # Print response body if available, helpful for debugging\n",
        "    if e.response is not None:\n",
        "        print(f\"Response Body: {e.response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4x9hYB8NuoXS"
      },
      "source": [
        "### 2. Create a Group\n",
        "\n",
        "Create a new entitlements group. Group names must follow the pattern `<name>@<domain>.com`. The domain typically matches your data partition ID or organization. We incorporate the `user_id` number into the group name to avoid collisions between lab users.\n",
        "\n",
        "**API Endpoint:** `POST /groups`\n",
        "**Access needed:** `service.entitlements.admin`\n",
        "\n",
        "| ⚠️ A **409 Client Error (Conflict)** response usually means that the group already exists. This is okay for the lab. |\n",
        "|-------------------------------------------------------------------------------------------------------------------|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VwRlBFquuoXS",
        "tags": [],
        "outputId": "82101900-6039-482e-a165-d7a792dc2ed6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to create group with email: lab-7073-group@None\n",
            "Request Body: {\"name\": \"lab-7073-group\", \"description\": \"Temporary group for lab exercise User 7073\"}\n",
            "Error creating group lab-7073-group@None: HTTPSConnectionPool(host='osdu.osdu-bootcamp.com', port=443): Max retries exceeded with url: /api/entitlements/v2/groups (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x79e2518e2a20>, 'Connection to osdu.osdu-bootcamp.com timed out. (connect timeout=None)'))\n"
          ]
        }
      ],
      "source": [
        "# Define the name and description for the new group\n",
        "# Using user_id ensures the name is unique for each lab participant\n",
        "group_name_prefix = f\"lab-{user_id}-group\"\n",
        "group_description = f\"Temporary group for lab exercise User {user_id}\"\n",
        "group_email = f\"{group_name_prefix}@{entitlements_domain}\"\n",
        "\n",
        "# Prepare the request payload (body)\n",
        "create_payload = {\n",
        "    \"name\": group_name_prefix,\n",
        "    \"description\": group_description\n",
        "}\n",
        "\n",
        "print(f\"Attempting to create group with email: {group_email}\")\n",
        "print(f\"Request Body: {json.dumps(create_payload)}\")\n",
        "\n",
        "try:\n",
        "    # Send a POST request to create the group\n",
        "    create_response = requests.post(\n",
        "        f\"{entitlements_endpoint}/groups\",\n",
        "        headers=headers,\n",
        "        data=json.dumps(create_payload) # Send payload as JSON string\n",
        "    )\n",
        "\n",
        "    # Check for common non-fatal error (Conflict = already exists)\n",
        "    if create_response.status_code == 409:\n",
        "        print(f\"Group '{group_email}' already exists (Status Code: 409). Proceeding...\")\n",
        "        # Optionally retrieve the existing group details if needed\n",
        "        print(f\"Response Body: {create_response.text}\")\n",
        "    else:\n",
        "        # Raise exception for other errors\n",
        "        create_response.raise_for_status()\n",
        "        print(f\"Group '{group_email}' created successfully (Status Code: {create_response.status_code}).\")\n",
        "        # Print the response from the server (usually confirms the group details)\n",
        "        print(json.dumps(create_response.json(), indent=2))\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error creating group {group_email}: {e}\")\n",
        "    if e.response is not None:\n",
        "        print(f\"Response Body: {e.response.text}\")\n",
        "finally:\n",
        "    # Ensure group_email is set even if creation failed with 409\n",
        "    if group_email is None:\n",
        "       group_email = f\"{group_name_prefix}@{entitlements_domain}\"\n",
        "       print(f\"Setting group_email to {group_email} for subsequent steps.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IP7pEYC7uoXS"
      },
      "source": [
        "### 3. Get Group Members\n",
        "\n",
        "Retrieve the list of members for the group created (or identified) in the previous step. Since it was just created, it should be empty.\n",
        "\n",
        "**API Endpoint:** `GET /groups/{group_email}/members`\n",
        "**Access needed:** `service.entitlements.user`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MFQSfueeuoXS",
        "tags": [],
        "outputId": "04957e0d-431a-407d-f508-cc5449363acf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to get members for group: lab-7073-group@None\n",
            "Error getting members for group lab-7073-group@None: HTTPSConnectionPool(host='osdu.osdu-bootcamp.com', port=443): Max retries exceeded with url: /api/entitlements/v2/groups/lab-7073-group@None/members (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x79e2518e24e0>, 'Connection to osdu.osdu-bootcamp.com timed out. (connect timeout=None)'))\n"
          ]
        }
      ],
      "source": [
        "# Ensure group_email is defined from the previous step\n",
        "if group_email:\n",
        "    print(f\"Attempting to get members for group: {group_email}\")\n",
        "    try:\n",
        "        # Send a GET request to the specific group's members endpoint\n",
        "        get_members_response = requests.get(\n",
        "            f\"{entitlements_endpoint}/groups/{group_email}/members\",\n",
        "            headers=headers\n",
        "        )\n",
        "        get_members_response.raise_for_status()\n",
        "\n",
        "        print(f\"Get Members Status Code: {get_members_response.status_code}\")\n",
        "        print(f\"Members for group '{group_email}':\")\n",
        "        print(json.dumps(get_members_response.json(), indent=2))\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error getting members for group {group_email}: {e}\")\n",
        "        if e.response is not None:\n",
        "            print(f\"Response Body: {e.response.text}\")\n",
        "else:\n",
        "    print(\"Variable 'group_email' is not defined. Please run the 'Create a Group' step (Step 2) successfully first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QjVYpHruoXT"
      },
      "source": [
        "### 4. Add Member to Group\n",
        "\n",
        "Add the current user (using their email `user_id_for_membership` defined in Setup) to the group with a specific role (`OWNER` or `MEMBER`).\n",
        "\n",
        "**API Endpoint:** `POST /groups/{group_email}/members`\n",
        "**Access needed:** `service.entitlements.admin` AND the caller must be an `OWNER` of the target group."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ulJMfQuJuoXT",
        "tags": [],
        "outputId": "baeb0ab6-d234-4120-c7b2-04c77120d02f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to add member 'user7073' with role 'MEMBER' to group 'lab-7073-group@None'...\n",
            "Request Body: {\"email\": \"user7073\", \"role\": \"MEMBER\"}\n",
            "Error adding member user7073 to group lab-7073-group@None: HTTPSConnectionPool(host='osdu.osdu-bootcamp.com', port=443): Max retries exceeded with url: /api/entitlements/v2/groups/lab-7073-group@None/members (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x79e2519a2540>, 'Connection to osdu.osdu-bootcamp.com timed out. (connect timeout=None)'))\n"
          ]
        }
      ],
      "source": [
        "# Ensure group_email is defined\n",
        "if group_email:\n",
        "    # Prepare the payload to add a member\n",
        "    member_payload = {\n",
        "        \"email\": user_id_for_membership,\n",
        "        \"role\": \"MEMBER\" # Role can be MEMBER or OWNER\n",
        "    }\n",
        "\n",
        "    print(f\"Attempting to add member '{member_payload['email']}' with role '{member_payload['role']}' to group '{group_email}'...\")\n",
        "    print(f\"Request Body: {json.dumps(member_payload)}\")\n",
        "\n",
        "    try:\n",
        "        # Send a POST request to add the member\n",
        "        add_member_response = requests.post(\n",
        "            f\"{entitlements_endpoint}/groups/{group_email}/members\",\n",
        "            headers=headers,\n",
        "            data=json.dumps(member_payload)\n",
        "        )\n",
        "        add_member_response.raise_for_status()\n",
        "\n",
        "        # A successful add operation usually returns 200 OK with an empty body or member details\n",
        "        print(f\"Add Member Status Code: {add_member_response.status_code}\")\n",
        "        print(f\"Member '{member_payload['email']}' added to group '{group_email}' with role '{member_payload['role']}'.\")\n",
        "        # Response body might be empty or contain member details\n",
        "        if add_member_response.text:\n",
        "            print(f\"Response Body: {json.dumps(add_member_response.json(), indent=2)}\")\n",
        "        else:\n",
        "             print(\"Response Body: (empty)\")\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error adding member {member_payload['email']} to group {group_email}: {e}\")\n",
        "        # Note: A 403 Forbidden error might indicate the authenticated user is not an OWNER of the group.\n",
        "        if e.response is not None:\n",
        "            print(f\"Response Body: {e.response.text}\")\n",
        "else:\n",
        "    print(\"Variable 'group_email' is not defined. Please run the 'Create a Group' step (Step 2) successfully first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkimYeACuoXT"
      },
      "source": [
        "### 5. List Group Members (Again)\n",
        "\n",
        "Retrieve the list of members for the group again. This time, it should show the member added in the previous step.\n",
        "\n",
        "**API Endpoint:** `GET /groups/{group_email}/members`\n",
        "**Access needed:** `service.entitlements.user`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6oYA6somuoXT",
        "tags": [],
        "outputId": "dec4aa2a-1a80-4067-bba7-5471e520a4e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to get members for group: lab-7073-group@None (after adding member)\n",
            "Error getting members for group lab-7073-group@None: HTTPSConnectionPool(host='osdu.osdu-bootcamp.com', port=443): Max retries exceeded with url: /api/entitlements/v2/groups/lab-7073-group@None/members (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x79e2519a3f50>, 'Connection to osdu.osdu-bootcamp.com timed out. (connect timeout=None)'))\n"
          ]
        }
      ],
      "source": [
        "# Ensure group_email is defined from the previous step\n",
        "if group_email:\n",
        "    print(f\"Attempting to get members for group: {group_email} (after adding member)\")\n",
        "    try:\n",
        "        # Send a GET request to the specific group's members endpoint\n",
        "        get_members_response = requests.get(\n",
        "            f\"{entitlements_endpoint}/groups/{group_email}/members\",\n",
        "            headers=headers\n",
        "        )\n",
        "        get_members_response.raise_for_status()\n",
        "\n",
        "        print(f\"Get Members Status Code: {get_members_response.status_code}\")\n",
        "        print(f\"Members for group '{group_email}':\")\n",
        "        print(json.dumps(get_members_response.json(), indent=2))\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error getting members for group {group_email}: {e}\")\n",
        "        if e.response is not None:\n",
        "            print(f\"Response Body: {e.response.text}\")\n",
        "else:\n",
        "    print(\"Variable 'group_email' is not defined. Please run the 'Create a Group' step (Step 2) successfully first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIVyWz6LuoXT"
      },
      "source": [
        "### 6. Remove Member from Group\n",
        "\n",
        "Remove the member (`user_id_for_membership`) that was added in Step 4.\n",
        "\n",
        "**API Endpoint:** `DELETE /groups/{group_email}/members/{member_email}`\n",
        "**Access needed:** `service.entitlements.admin` AND the caller must be an `OWNER` of the target group."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "wENmbfqxuoXT",
        "tags": [],
        "outputId": "23cfebe3-0e3c-4ff2-eb80-2e27b365aa75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to remove member 'user7073' from group 'lab-7073-group@None'...\n",
            "Error removing member user7073 from group lab-7073-group@None: HTTPSConnectionPool(host='osdu.osdu-bootcamp.com', port=443): Max retries exceeded with url: /api/entitlements/v2/groups/lab-7073-group@None/members/user7073 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x79e2519a3770>, 'Connection to osdu.osdu-bootcamp.com timed out. (connect timeout=None)'))\n",
            "\n",
            "Verifying removal by listing members for group: lab-7073-group@None\n",
            "Error verifying group members for lab-7073-group@None: HTTPSConnectionPool(host='osdu.osdu-bootcamp.com', port=443): Max retries exceeded with url: /api/entitlements/v2/groups/lab-7073-group@None/members (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x79e2518e2c30>, 'Connection to osdu.osdu-bootcamp.com timed out. (connect timeout=None)'))\n"
          ]
        }
      ],
      "source": [
        "# Ensure group_email is defined\n",
        "if group_email:\n",
        "    member_to_remove = user_id_for_membership\n",
        "    print(f\"Attempting to remove member '{member_to_remove}' from group '{group_email}'...\")\n",
        "\n",
        "    try:\n",
        "        # Send a DELETE request to remove the member\n",
        "        remove_response = requests.delete(\n",
        "            f\"{entitlements_endpoint}/groups/{group_email}/members/{member_to_remove}\",\n",
        "            headers=headers\n",
        "        )\n",
        "        remove_response.raise_for_status()\n",
        "\n",
        "        # A successful deletion usually returns 204 No Content\n",
        "        print(f\"Remove Member Status Code: {remove_response.status_code}\")\n",
        "        print(f\"Member '{member_to_remove}' removed from group '{group_email}'.\")\n",
        "        # Response body is typically empty on success\n",
        "        if remove_response.text:\n",
        "            print(f\"Response Body: {remove_response.text}\")\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error removing member {member_to_remove} from group {group_email}: {e}\")\n",
        "        if e.response is not None:\n",
        "            print(f\"Response Body: {e.response.text}\")\n",
        "\n",
        "    # Verify removal by listing members again (Optional but recommended)\n",
        "    print(f\"\\nVerifying removal by listing members for group: {group_email}\")\n",
        "    try:\n",
        "        verify_response = requests.get(\n",
        "            f\"{entitlements_endpoint}/groups/{group_email}/members\",\n",
        "            headers=headers\n",
        "        )\n",
        "        verify_response.raise_for_status()\n",
        "        print(f\"Verification - Get Members Status Code: {verify_response.status_code}\")\n",
        "        print(f\"Current members for group '{group_email}':\")\n",
        "        print(json.dumps(verify_response.json(), indent=2))\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error verifying group members for {group_email}: {e}\")\n",
        "        if e.response is not None:\n",
        "             print(f\"Verification Response Body: {e.response.text}\")\n",
        "\n",
        "else:\n",
        "    print(\"Variable 'group_email' is not defined. Please run the 'Create a Group' step (Step 2) successfully first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKch0yBIuoXT"
      },
      "source": [
        "### 7. Delete Group\n",
        "\n",
        "Delete the group created earlier in the lab.\n",
        "\n",
        "**API Endpoint:** `DELETE /groups/{group_email}`\n",
        "**Access needed:** `service.entitlements.admin` AND the caller must be an `OWNER` of the group."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QmV4I2TbuoXT",
        "tags": [],
        "outputId": "c7c99223-147b-4688-cd57-0726ccded5ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to delete group: lab-7073-group@None\n",
            "Error deleting group lab-7073-group@None: HTTPSConnectionPool(host='osdu.osdu-bootcamp.com', port=443): Max retries exceeded with url: /api/entitlements/v2/groups/lab-7073-group@None (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x79e25170ccb0>, 'Connection to osdu.osdu-bootcamp.com timed out. (connect timeout=None)'))\n"
          ]
        }
      ],
      "source": [
        "# Ensure group_email is defined\n",
        "if group_email:\n",
        "    print(f\"Attempting to delete group: {group_email}\")\n",
        "    try:\n",
        "        # Send a DELETE request to remove the group\n",
        "        # NOTE: The API spec shows DELETE /groups/{group_email} requires no specific headers beyond auth and data-partition-id\n",
        "        delete_response = requests.delete(\n",
        "            f\"{entitlements_endpoint}/groups/{group_email}\",\n",
        "            headers=headers # Standard headers are sufficient\n",
        "        )\n",
        "        delete_response.raise_for_status()\n",
        "\n",
        "        # Successful deletion usually returns 204 No Content\n",
        "        print(f\"Delete Group Status Code: {delete_response.status_code}\")\n",
        "        print(f\"Group '{group_email}' deleted successfully.\")\n",
        "        # Response is typically empty on success\n",
        "        if delete_response.text:\n",
        "             print(f\"Response Body: {delete_response.text}\")\n",
        "\n",
        "        # Clean up variable to prevent accidental reuse in subsequent runs\n",
        "        print(f\"Deleting variable group_email ('{group_email}') from notebook memory.\")\n",
        "        del group_email\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error deleting group {group_email}: {e}\")\n",
        "        if e.response is not None:\n",
        "            print(f\"Response Body: {e.response.text}\")\n",
        "    except NameError:\n",
        "        # This case handles if 'del group_email' was successful but cell is run again\n",
        "        print(\"Variable 'group_email' no longer exists (likely already deleted). \")\n",
        "else:\n",
        "    # This case handles if group_email was never defined (e.g., Step 2 failed)\n",
        "    print(\"Variable 'group_email' is not defined. Cannot delete group. Please run 'Create a Group' (Step 2) first or the group may have already been deleted.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3REBy74zuoXT"
      },
      "source": [
        "### Challenge\n",
        "\n",
        "1.  Create a new group named `challenge-{user_id}-users` (where `{user_id}` is your unique number) with the description \"Challenge Group for {user_id}\".\n",
        "2.  Add two members to this group:\n",
        "    *   Your own user email (`user_id_for_membership`) with the role `OWNER`.\n",
        "    *   A *different* email address (e.g., `user{user_id}-teammate@{entitlements_domain}`) with the role `MEMBER`.\n",
        "3.  List all members of the challenge group to verify additions.\n",
        "4.  Remove the second member (`user{user_id}-teammate@{entitlements_domain}`) from the group.\n",
        "5.  List the members again to verify the removal.\n",
        "6.  Delete the challenge group."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HdFMqCuQuoXT",
        "outputId": "ced55ed2-99c6-42eb-8906-a0f39fcaa963",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Entitlements Challenge ---\n",
            "Challenge Group Email: challenge-7073-users@None\n",
            "Challenge Member 1 (OWNER): user7073\n",
            "Challenge Member 2 (MEMBER): user7073-teammate@None\n"
          ]
        }
      ],
      "source": [
        "# Code block for setting up challenge variables\n",
        "print(\"--- Starting Entitlements Challenge ---\")\n",
        "\n",
        "# Define unique names and emails for the challenge\n",
        "challenge_group_prefix = f\"challenge-{user_id}-users\"\n",
        "challenge_group_desc = f\"Challenge Group for {user_id}\"\n",
        "challenge_group_email = f\"{challenge_group_prefix}@{entitlements_domain}\"\n",
        "\n",
        "# Member 1: Your own email (defined in Setup)\n",
        "member1_email_challenge = user_id_for_membership\n",
        "# Member 2: A different email address (doesn't have to be a real user for this exercise unless testing actual permissions)\n",
        "member2_email_challenge = f\"user{user_id}-teammate@{entitlements_domain}\"\n",
        "\n",
        "print(f\"Challenge Group Email: {challenge_group_email}\")\n",
        "print(f\"Challenge Member 1 (OWNER): {member1_email_challenge}\")\n",
        "print(f\"Challenge Member 2 (MEMBER): {member2_email_challenge}\")\n",
        "\n",
        "# Use the standard 'headers' defined in the initial setup\n",
        "# headers = { ... }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG2VHlTsuoXT"
      },
      "source": [
        "#### 💡 Solution Code Cells"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODiR_AsKuoXU"
      },
      "source": [
        "##### 1. Create Challenge Group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Hqy0NH-RuoXU",
        "outputId": "2eed6f32-5fd0-4190-82d9-6c0b55e87667",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Challenge Step 1: Creating group: challenge-7073-users@None\n",
            "   Error creating challenge group: HTTPSConnectionPool(host='osdu.osdu-bootcamp.com', port=443): Max retries exceeded with url: /api/entitlements/v2/groups (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x79e2519a2240>, 'Connection to osdu.osdu-bootcamp.com timed out. (connect timeout=None)'))\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nChallenge Step 1: Creating group: {challenge_group_email}\")\n",
        "challenge_group_payload = {\n",
        "    \"name\": challenge_group_prefix,\n",
        "    \"description\": challenge_group_desc,\n",
        "}\n",
        "\n",
        "try:\n",
        "    response = requests.post(\n",
        "        f\"{entitlements_endpoint}/groups\",\n",
        "        headers=headers,\n",
        "        data=json.dumps(challenge_group_payload)\n",
        "    )\n",
        "    if response.status_code == 409:\n",
        "        print(f\"   Group '{challenge_group_email}' already exists (409). Proceeding...\")\n",
        "    else:\n",
        "        response.raise_for_status()\n",
        "        print(f\"   Group '{challenge_group_email}' created successfully ({response.status_code}).\")\n",
        "        # print(json.dumps(response.json(), indent=2))\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"   Error creating challenge group: {e}\")\n",
        "    if e.response is not None:\n",
        "        print(f\"   Response Body: {e.response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNBYDdKf1Snt"
      },
      "source": [
        "##### Create Member 2 Group"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiBqOTdq1fDo"
      },
      "source": [
        "- Challenge Member 1 (OWNER): user123\n",
        "- Challenge Member 2 (MEMBER): user123-teammate@osdu.group\n",
        "\n",
        "user123-teammate@osdu.group is recognized as a group (because it has 'osdu' and 'group'). If we have any other postfix (@gmail.com. @osdu1.group, etc), the following code is not mandatory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5QHDffiY0hNm",
        "outputId": "895628a3-4d18-4fc2-ddc4-d90a90f274b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Challenge Step 1: Creating group: user7073-teammate@None\n",
            "   Error creating challenge group: HTTPSConnectionPool(host='osdu.osdu-bootcamp.com', port=443): Max retries exceeded with url: /api/entitlements/v2/groups (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x79e2519a34a0>, 'Connection to osdu.osdu-bootcamp.com timed out. (connect timeout=None)'))\n"
          ]
        }
      ],
      "source": [
        "challenge_group_email\n",
        "member2_email_challenge\n",
        "print(f\"\\nChallenge Step 1: Creating group: {member2_email_challenge}\")\n",
        "challenge_group_payload = {\n",
        "    \"name\": member2_email_challenge.replace(f\"@{osdu_data_partition_id}.{osdu_group_domain}\", \"\"),\n",
        "    \"description\": f\"Description for {member2_email_challenge}\",\n",
        "}\n",
        "\n",
        "try:\n",
        "    response = requests.post(\n",
        "        f\"{entitlements_endpoint}/groups\",\n",
        "        headers=headers,\n",
        "        data=json.dumps(challenge_group_payload)\n",
        "    )\n",
        "    if response.status_code == 409:\n",
        "        print(f\"   Group '{member2_email_challenge}' already exists (409). Proceeding...\")\n",
        "    else:\n",
        "        response.raise_for_status()\n",
        "        print(f\"   Group '{member2_email_challenge}' created successfully ({response.status_code}).\")\n",
        "        # print(json.dumps(response.json(), indent=2))\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"   Error creating challenge group: {e}\")\n",
        "    if e.response is not None:\n",
        "        print(f\"   Response Body: {e.response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiWqhGhzuoXU"
      },
      "source": [
        "##### 2. Add Members to Challenge Group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "SYKcoWoUuoXU",
        "outputId": "9c9c3c9e-748c-4cf7-ec83-0932d72c30a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Challenge Step 2: Adding members...\n",
            "   Adding Member 1: user7073 as OWNER\n",
            "      Error adding member 1: HTTPSConnectionPool(host='osdu.osdu-bootcamp.com', port=443): Max retries exceeded with url: /api/entitlements/v2/groups/challenge-7073-users@None/members (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x79e25170e570>, 'Connection to osdu.osdu-bootcamp.com timed out. (connect timeout=None)'))\n",
            "   Adding Member 2: user7073-teammate@None as MEMBER\n",
            "      Error adding member 2: HTTPSConnectionPool(host='osdu.osdu-bootcamp.com', port=443): Max retries exceeded with url: /api/entitlements/v2/groups/challenge-7073-users@None/members (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x79e25170c200>, 'Connection to osdu.osdu-bootcamp.com timed out. (connect timeout=None)'))\n"
          ]
        }
      ],
      "source": [
        "# Note: Removed unused import 'from osdu_api.model.entitlements.group_member import GroupMember'\n",
        "print(\"\\nChallenge Step 2: Adding members...\")\n",
        "\n",
        "# Prepare payloads for each member\n",
        "member1_payload_challenge = {\n",
        "    \"email\": member1_email_challenge,\n",
        "    \"role\": \"OWNER\"\n",
        "}\n",
        "\n",
        "member2_payload_challenge = {\n",
        "    \"email\": member2_email_challenge,\n",
        "    \"role\": \"MEMBER\"\n",
        "}\n",
        "\n",
        "# Add Member 1\n",
        "try:\n",
        "    print(f\"   Adding Member 1: {member1_email_challenge} as {member1_payload_challenge['role']}\")\n",
        "    response1 = requests.post(\n",
        "        f\"{entitlements_endpoint}/groups/{challenge_group_email}/members\",\n",
        "        headers=headers,\n",
        "        data=json.dumps(member1_payload_challenge)\n",
        "    )\n",
        "    response1.raise_for_status()\n",
        "    print(f\"      Success ({response1.status_code}).\")\n",
        "except requests.exceptions.RequestException as e:\n",
        "    # Handle case where member might already exist in the group (common if re-running)\n",
        "    # The API might return 400 or other codes depending on implementation if member exists.\n",
        "    print(f\"      Error adding member 1: {e}\")\n",
        "    if e.response is not None:\n",
        "        print(f\"      Response Body: {e.response.text}\")\n",
        "\n",
        "# Add Member 2\n",
        "try:\n",
        "    print(f\"   Adding Member 2: {member2_email_challenge} as {member2_payload_challenge['role']}\")\n",
        "    response2 = requests.post(\n",
        "        f\"{entitlements_endpoint}/groups/{challenge_group_email}/members\",\n",
        "        headers=headers,\n",
        "        data=json.dumps(member2_payload_challenge)\n",
        "    )\n",
        "    response2.raise_for_status()\n",
        "    print(f\"      Success ({response2.status_code}).\")\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"      Error adding member 2: {e}\")\n",
        "    if e.response is not None:\n",
        "        print(f\"      Response Body: {e.response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrKawpU7uoXU"
      },
      "source": [
        "##### 3. List Challenge Group Members"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "GsFcXpXMuoXU",
        "outputId": "437afba1-a336-417d-f5ac-3220e116044f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Challenge Step 3: Listing members of challenge-7073-users@None\n",
            "   Error listing challenge group members: HTTPSConnectionPool(host='osdu.osdu-bootcamp.com', port=443): Max retries exceeded with url: /api/entitlements/v2/groups/challenge-7073-users@None/members (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x79e25170dd30>, 'Connection to osdu.osdu-bootcamp.com timed out. (connect timeout=None)'))\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nChallenge Step 3: Listing members of {challenge_group_email}\")\n",
        "try:\n",
        "    list_members_response = requests.get(\n",
        "        f\"{entitlements_endpoint}/groups/{challenge_group_email}/members\",\n",
        "        headers=headers\n",
        "    )\n",
        "    list_members_response.raise_for_status()\n",
        "    print(f\"   List Members Status Code: {list_members_response.status_code}\")\n",
        "    print(\"   Current Members:\")\n",
        "    print(json.dumps(list_members_response.json(), indent=2))\n",
        "except requests.exceptions.RequestException as e:\n",
        "     print(f\"   Error listing challenge group members: {e}\")\n",
        "     if e.response is not None:\n",
        "        print(f\"   Response Body: {e.response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViN7WXCquoXU"
      },
      "source": [
        "##### 4. Remove Member 2 from Challenge Group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "iHWK7O7cuoXU",
        "outputId": "8e83a8ed-dd43-4bc9-e76c-359b99f66d2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Challenge Step 4: Removing member user7073-teammate@None from challenge-7073-users@None\n",
            "   Error removing member 2: HTTPSConnectionPool(host='osdu.osdu-bootcamp.com', port=443): Max retries exceeded with url: /api/entitlements/v2/groups/challenge-7073-users@None/members/user7073-teammate@None (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x79e2519a3140>, 'Connection to osdu.osdu-bootcamp.com timed out. (connect timeout=None)'))\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nChallenge Step 4: Removing member {member2_email_challenge} from {challenge_group_email}\")\n",
        "try:\n",
        "    remove_response = requests.delete(\n",
        "        f\"{entitlements_endpoint}/groups/{challenge_group_email}/members/{member2_email_challenge}\",\n",
        "        headers=headers\n",
        "    )\n",
        "    remove_response.raise_for_status()\n",
        "    print(f\"   Member {member2_email_challenge} removed successfully ({remove_response.status_code}).\")\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"   Error removing member 2: {e}\")\n",
        "    if e.response is not None:\n",
        "        # A 404 might mean the member was already removed or never added successfully\n",
        "        print(f\"   Response Body: {e.response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TloYbuFouoXU"
      },
      "source": [
        "##### 5. List Challenge Group Members Again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "3eCziFmYuoXU",
        "outputId": "29adba26-b997-404e-e55a-fc5d1dbe19af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Challenge Step 5: Listing members of challenge-7073-users@None (after removal)\n",
            "   Error listing challenge group members: HTTPSConnectionPool(host='osdu.osdu-bootcamp.com', port=443): Max retries exceeded with url: /api/entitlements/v2/groups/challenge-7073-users@None/members (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x79e25170dfd0>, 'Connection to osdu.osdu-bootcamp.com timed out. (connect timeout=None)'))\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nChallenge Step 5: Listing members of {challenge_group_email} (after removal)\")\n",
        "try:\n",
        "    list_members_response_after = requests.get(\n",
        "        f\"{entitlements_endpoint}/groups/{challenge_group_email}/members\",\n",
        "        headers=headers\n",
        "    )\n",
        "    list_members_response_after.raise_for_status()\n",
        "    print(f\"   List Members Status Code: {list_members_response_after.status_code}\")\n",
        "    print(\"   Current Members:\")\n",
        "    print(json.dumps(list_members_response_after.json(), indent=2))\n",
        "except requests.exceptions.RequestException as e:\n",
        "     print(f\"   Error listing challenge group members: {e}\")\n",
        "     if e.response is not None:\n",
        "        print(f\"   Response Body: {e.response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Supa8iBiuoXY"
      },
      "source": [
        "##### 6. Delete Challenge Group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "5HqenBnVuoXY",
        "outputId": "5615b55c-6cb0-46e8-ecc7-5d8b020e9374",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Challenge Step 6: Deleting group challenge-7073-users@None\n",
            "   Error deleting challenge group: HTTPSConnectionPool(host='osdu.osdu-bootcamp.com', port=443): Max retries exceeded with url: /api/entitlements/v2/groups/challenge-7073-users@None (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x79e251768ad0>, 'Connection to osdu.osdu-bootcamp.com timed out. (connect timeout=None)'))\n",
            "--- Entitlements Challenge Complete ---\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nChallenge Step 6: Deleting group {challenge_group_email}\")\n",
        "try:\n",
        "    delete_response = requests.delete(\n",
        "        f\"{entitlements_endpoint}/groups/{challenge_group_email}\",\n",
        "        headers=headers\n",
        "    )\n",
        "    delete_response.raise_for_status()\n",
        "    print(f\"   Group '{challenge_group_email}' deleted successfully ({delete_response.status_code}).\")\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"   Error deleting challenge group: {e}\")\n",
        "    if e.response is not None:\n",
        "        # A 404 might mean it was already deleted\n",
        "        print(f\"   Response Body: {e.response.text}\")\n",
        "\n",
        "print(\"--- Entitlements Challenge Complete ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgMkCvqi4GaH"
      },
      "source": [
        "##### Delete Member 2 Group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "IqJyY72S43C4",
        "outputId": "64ba6ce7-6e70-4d4e-85db-dd29ae13793b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Challenge Step 6: Deleting group user7073-teammate@None\n",
            "   Error deleting challenge group: HTTPSConnectionPool(host='osdu.osdu-bootcamp.com', port=443): Max retries exceeded with url: /api/entitlements/v2/groups/user7073-teammate@None (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x79e25170e390>, 'Connection to osdu.osdu-bootcamp.com timed out. (connect timeout=None)'))\n",
            "--- Entitlements Challenge Complete ---\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nChallenge Step 6: Deleting group {member2_email_challenge}\")\n",
        "try:\n",
        "    delete_response = requests.delete(\n",
        "        f\"{entitlements_endpoint}/groups/{member2_email_challenge}\",\n",
        "        headers=headers\n",
        "    )\n",
        "    delete_response.raise_for_status()\n",
        "    print(f\"   Group '{challenge_group_email}' deleted successfully ({delete_response.status_code}).\")\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"   Error deleting challenge group: {e}\")\n",
        "    if e.response is not None:\n",
        "        # A 404 might mean it was already deleted\n",
        "        print(f\"   Response Body: {e.response.text}\")\n",
        "\n",
        "print(\"--- Entitlements Challenge Complete ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQ5249BxuoXY"
      },
      "source": [
        "## OSDU Legal Service Lab\n",
        "\n",
        "This lab exercise covers the usage of the OSDU Legal Service. You will learn how to create, retrieve, list, update, validate, and delete legal tags. Legal tags are crucial for associating data records with legal compliance information (e.g., data origin, export controls, usage restrictions).\n",
        "\n",
        "**Key Concepts:**\n",
        "*   **Legal Tag:** A metadata tag containing properties related to legal compliance.\n",
        "*   **Properties:** Attributes within a legal tag defining its specific compliance details (e.g., `countryOfOrigin`, `expirationDate`, `personalData`).\n",
        "\n",
        "**Documentation:**\n",
        "*   [Legal Service Concepts](https://osdu.pages.opengroup.org/platform/security-and-compliance/legal/)\n",
        "*   [Legal Service API Usage](https://osdu.pages.opengroup.org/platform/security-and-compliance/legal/api/)\n",
        "*   [API Specification](https://community.opengroup.org/osdu/platform/security-and-compliance/legal/-/blob/master/openapi/legal_openapi.yaml)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpB6tK9I4CAw"
      },
      "source": [
        "##### 6. Delete Challenge Group"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Td48FedxuoXY"
      },
      "source": [
        "### Setup: Legal Lab\n",
        "\n",
        "This cell sets up the necessary variables for the Legal Service lab exercises.\n",
        "\n",
        "**Dependencies:**\n",
        "*   Requires the `requests` and `json` libraries (imported in the initial setup).\n",
        "*   Relies on variables defined during the initial authentication: `osdu_endpoint`, `headers`, `user_id`, `osdu_data_partition_id`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "wZE0-uMmuoXY",
        "tags": [],
        "outputId": "316323c3-94da-4afc-e7ee-4d87b375e45a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Legal API Endpoint: https://osdu.osdu-bootcamp.com/api/legal/v1\n",
            "Using Legal Tag Name: osdu-lab-tag-7073\n"
          ]
        }
      ],
      "source": [
        "# Define the base endpoint for the Legal API\n",
        "legal_endpoint = f\"{osdu_endpoint}/api/legal/v1\"\n",
        "print(f\"Using Legal API Endpoint: {legal_endpoint}\")\n",
        "\n",
        "# Define a unique tag name using the user_id to avoid conflicts\n",
        "user_tag_name = f'{osdu_data_partition_id}-lab-tag-{user_id}'\n",
        "user_tag_description = f\"Lab tag created by user {user_id}\"\n",
        "print(f\"Using Legal Tag Name: {user_tag_name}\")\n",
        "\n",
        "# This variable will store the name of the tag created in Step 1\n",
        "created_tag_name = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5tKRnU6uoXY"
      },
      "source": [
        "### 1. Create Legal Tag\n",
        "\n",
        "Create a new legal tag with specified properties.\n",
        "\n",
        "**API Endpoint:** `POST /legaltags`\n",
        "**Access needed:** `service.legal.editor`\n",
        "\n",
        "| ⚠️ A **409 Client Error (Conflict)** response usually means that the tag already exists. This is okay for the lab. |\n",
        "|-------------------------------------------------------------------------------------------------------------------|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "CW5IzLuyuoXY",
        "tags": [],
        "outputId": "f7b5c400-1319-4796-ca8b-801d4dfac880",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to create legal tag: osdu-lab-tag-7073\n",
            "Request Body: {\n",
            "  \"name\": \"osdu-lab-tag-7073\",\n",
            "  \"description\": \"Lab tag created by user 7073\",\n",
            "  \"properties\": {\n",
            "    \"contractId\": \"CID-7073-A1\",\n",
            "    \"countryOfOrigin\": [\n",
            "      \"US\"\n",
            "    ],\n",
            "    \"dataType\": \"Public Domain Data\",\n",
            "    \"expirationDate\": \"2099-12-31\",\n",
            "    \"exportClassification\": \"EAR99\",\n",
            "    \"originator\": \"LabUser-7073\",\n",
            "    \"personalData\": \"No Personal Data\",\n",
            "    \"securityClassification\": \"Public\"\n",
            "  }\n",
            "}\n",
            "Error creating legal tag 'osdu-lab-tag-7073': HTTPSConnectionPool(host='osdu.osdu-bootcamp.com', port=443): Max retries exceeded with url: /api/legal/v1/legaltags (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x79e251768fe0>, 'Connection to osdu.osdu-bootcamp.com timed out. (connect timeout=None)'))\n",
            "Failed to create or confirm existence of legal tag 'osdu-lab-tag-7073'. Subsequent steps might fail.\n"
          ]
        }
      ],
      "source": [
        "# Define the payload for the new legal tag\n",
        "create_payload = {\n",
        "    \"name\": user_tag_name,\n",
        "    \"description\": user_tag_description,\n",
        "    \"properties\": {\n",
        "        \"contractId\": f\"CID-{user_id}-A1\",\n",
        "        \"countryOfOrigin\": [\"US\"], # Must be an ISO 3166-1 alpha-2 country code\n",
        "        \"dataType\": \"Public Domain Data\", # Value must exist in reference data 'LegalTagPropertyType' for 'dataType'\n",
        "        \"expirationDate\": \"2099-12-31\", # Format YYYY-MM-DD\n",
        "        \"exportClassification\": \"EAR99\", # Value must exist in reference data 'LegalTagPropertyType' for 'exportClassification'\n",
        "        \"originator\": f\"LabUser-{user_id}\",\n",
        "        \"personalData\": \"No Personal Data\", # Value must exist in reference data 'LegalTagPropertyType' for 'personalData'\n",
        "        \"securityClassification\": \"Public\" # Value must exist in reference data 'LegalTagPropertyType' for 'securityClassification'\n",
        "    }\n",
        "}\n",
        "\n",
        "print(f\"Attempting to create legal tag: {user_tag_name}\")\n",
        "print(f\"Request Body: {json.dumps(create_payload, indent=2)}\")\n",
        "\n",
        "try:\n",
        "    # Send POST request to create the legal tag\n",
        "    create_response = requests.post(\n",
        "        f\"{legal_endpoint}/legaltags\",\n",
        "        headers=headers,\n",
        "        data=json.dumps(create_payload) # Send payload as JSON string\n",
        "    )\n",
        "\n",
        "    # Handle potential conflict (already exists)\n",
        "    if create_response.status_code == 409:\n",
        "        print(f\"Legal tag '{user_tag_name}' already exists (Status Code: 409). Proceeding...\")\n",
        "        # Attempt to retrieve the existing tag to confirm structure (optional)\n",
        "        print(f\"Response Body: {create_response.text}\")\n",
        "        created_tag_name = user_tag_name # Assume it exists with the correct name\n",
        "    else:\n",
        "        # Raise exception for other HTTP errors\n",
        "        create_response.raise_for_status()\n",
        "        print(f\"Legal tag creation successful (Status Code: {create_response.status_code}).\")\n",
        "        created_tag_data = create_response.json()\n",
        "        print(\"Response Body:\")\n",
        "        print(json.dumps(created_tag_data, indent=2))\n",
        "        # Store the name from the response (might differ if case-sensitivity rules apply)\n",
        "        created_tag_name = created_tag_data.get(\"name\")\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error creating legal tag '{user_tag_name}': {e}\")\n",
        "    if e.response is not None:\n",
        "        print(f\"Response Body: {e.response.text}\")\n",
        "finally:\n",
        "     # Ensure the variable is set if creation succeeded or conflict occurred\n",
        "    if created_tag_name:\n",
        "        print(f\"Stored created_tag_name: {created_tag_name}\")\n",
        "    else:\n",
        "        print(f\"Failed to create or confirm existence of legal tag '{user_tag_name}'. Subsequent steps might fail.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dBBACdpuoXZ"
      },
      "source": [
        "### 2. Get Legal Tag\n",
        "\n",
        "Retrieve the details of the legal tag created (or confirmed existing) in the previous step by its name.\n",
        "\n",
        "**API Endpoint:** `GET /legaltags/{tagName}`\n",
        "**Access needed:** `service.legal.user`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "IWTxG6J2uoXZ",
        "tags": [],
        "outputId": "96581ef5-518c-4ad9-c784-da097dd56d4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variable 'created_tag_name' is not defined. Cannot retrieve tag. Please ensure Step 1 ran successfully.\n"
          ]
        }
      ],
      "source": [
        "# Ensure created_tag_name has a value from the previous step\n",
        "if created_tag_name:\n",
        "    print(f\"Attempting to retrieve legal tag: {created_tag_name}\")\n",
        "    try:\n",
        "        # Send GET request to retrieve the specific tag\n",
        "        get_response = requests.get(\n",
        "            f\"{legal_endpoint}/legaltags/{created_tag_name}\",\n",
        "            headers=headers\n",
        "        )\n",
        "        get_response.raise_for_status() # Check for HTTP errors (e.g., 404 Not Found)\n",
        "\n",
        "        print(f\"Legal tag retrieval successful (Status Code: {get_response.status_code}).\")\n",
        "        print(\"Retrieved Tag Details:\")\n",
        "        print(json.dumps(get_response.json(), indent=2))\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error retrieving legal tag '{created_tag_name}': {e}\")\n",
        "        if e.response is not None:\n",
        "            print(f\"Response Body: {e.response.text}\")\n",
        "else:\n",
        "    print(\"Variable 'created_tag_name' is not defined. Cannot retrieve tag. Please ensure Step 1 ran successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GObc4hwIuoXZ"
      },
      "source": [
        "### 3. List Legal Tags\n",
        "\n",
        "List all available legal tags in the data partition. This may return many tags depending on the environment.\n",
        "\n",
        "**API Endpoint:** `GET /legaltags`\n",
        "**Access needed:** `service.legal.user`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Rju2jBt0uoXZ",
        "tags": [],
        "outputId": "0a906250-1302-4b6d-c7a6-0fb3af7b7593",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to list all legal tags...\n",
            "Error listing legal tags: HTTPSConnectionPool(host='osdu.osdu-bootcamp.com', port=443): Max retries exceeded with url: /api/legal/v1/legaltags (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x79e25176ad50>, 'Connection to osdu.osdu-bootcamp.com timed out. (connect timeout=None)'))\n"
          ]
        }
      ],
      "source": [
        "print(\"Attempting to list all legal tags...\")\n",
        "try:\n",
        "    # Send GET request to list all tags\n",
        "    list_response = requests.get(\n",
        "        f\"{legal_endpoint}/legaltags\",\n",
        "        headers=headers\n",
        "    )\n",
        "    list_response.raise_for_status()\n",
        "\n",
        "    print(f\"List legal tags successful (Status Code: {list_response.status_code}).\")\n",
        "    tag_list_data = list_response.json()\n",
        "\n",
        "    # Display the result (can be large)\n",
        "    if 'legalTags' in tag_list_data and isinstance(tag_list_data['legalTags'], list):\n",
        "        print(f\"Found {len(tag_list_data['legalTags'])} legal tags.\")\n",
        "        # Optionally print only the names or a subset if the list is too long\n",
        "        # print(\"First 5 tags:\")\n",
        "        # print(json.dumps(tag_list_data['legalTags'][:5], indent=2))\n",
        "        print(\"Full list response:\")\n",
        "        print(json.dumps(tag_list_data, indent=2))\n",
        "    else:\n",
        "        print(\"Unexpected response format:\")\n",
        "        print(json.dumps(tag_list_data, indent=2))\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error listing legal tags: {e}\")\n",
        "    if e.response is not None:\n",
        "        print(f\"Response Body: {e.response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owgKSZnAuoXZ"
      },
      "source": [
        "### 4. Update Legal Tag\n",
        "\n",
        "Update properties of the legal tag created earlier. Note that `PUT /legaltags` typically replaces the entire tag definition, so we retrieve the existing tag first, modify it, and then send the complete updated object.\n",
        "\n",
        "**API Endpoint:** `PUT /legaltags`\n",
        "**Access needed:** `service.legal.editor`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "qYevGxPGuoXZ",
        "tags": [],
        "outputId": "5b466b31-83cd-4cc9-8d1b-1912e23b2462",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to update legal tag: None\n",
            "   Attempting to PUT updated legal tag: None\n",
            "   Update Request Body: {\n",
            "  \"name\": \"osdu-lab-tag-7073\",\n",
            "  \"description\": \"Updated legal tag created for SDK lab exercise.\",\n",
            "  \"contractId\": \"A1234-updated\",\n",
            "  \"expirationDate\": \"2199-12-31\"\n",
            "}\n",
            "   Error updating legal tag 'None': HTTPSConnectionPool(host='osdu.osdu-bootcamp.com', port=443): Max retries exceeded with url: /api/legal/v1/legaltags (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x79e25176b3e0>, 'Connection to osdu.osdu-bootcamp.com timed out. (connect timeout=None)'))\n"
          ]
        }
      ],
      "source": [
        "print(f\"Attempting to update legal tag: {created_tag_name}\")\n",
        "\n",
        "current_tag_data = None\n",
        "\n",
        "# Modify the retrieved data\n",
        "current_tag_data = {\n",
        "    \"name\": user_tag_name,\n",
        "    \"description\": \"Updated legal tag created for SDK lab exercise.\",\n",
        "    \"contractId\": \"A1234-updated\",\n",
        "    \"expirationDate\": \"2199-12-31\",\n",
        "}\n",
        "\n",
        "print(f\"   Attempting to PUT updated legal tag: {created_tag_name}\")\n",
        "print(f\"   Update Request Body: {json.dumps(current_tag_data, indent=2)}\")\n",
        "\n",
        "try:\n",
        "    update_response = requests.put(\n",
        "        f\"{legal_endpoint}/legaltags\", # Note: PUT is to the base /legaltags endpoint\n",
        "        headers=headers,\n",
        "        data=json.dumps(current_tag_data) # Send the entire modified object\n",
        "    )\n",
        "    update_response.raise_for_status()\n",
        "\n",
        "    print(f\"   Legal tag update successful (Status Code: {update_response.status_code}).\")\n",
        "    print(\"   Updated Tag Details:\")\n",
        "    print(json.dumps(update_response.json(), indent=2))\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"   Error updating legal tag '{created_tag_name}': {e}\")\n",
        "    if e.response is not None:\n",
        "        print(f\"   Response Body: {e.response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rnfHkkKuoXZ"
      },
      "source": [
        "### 5. Validate Legal Tags\n",
        "\n",
        "Validate a list of tag names to check if they exist and are valid according to the Legal Service. The API returns a list containing only the *invalid* tag names from the input list. An empty `invalidLegalTags` list in the response means all provided tags were valid.\n",
        "\n",
        "**API Endpoint:** `POST /legaltags:validate`\n",
        "**Access needed:** `service.legal.user`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ePq91AKbuoXZ",
        "tags": [],
        "outputId": "1a134c05-79bb-4c0c-ac19-04a58447707e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variable 'created_tag_name' is not defined. Cannot validate tag. Please ensure Step 1 ran successfully.\n"
          ]
        }
      ],
      "source": [
        "# Ensure created_tag_name has a value\n",
        "if created_tag_name:\n",
        "    # Prepare payload with tags to validate\n",
        "    # Include the valid tag created earlier and a clearly invalid one\n",
        "    invalid_test_tag_name = f\"non-existent-tag-{user_id}\"\n",
        "    tags_to_validate_payload = {\n",
        "        \"names\": [\n",
        "            created_tag_name,\n",
        "            invalid_test_tag_name\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    print(f\"Attempting to validate tags: {tags_to_validate_payload['names']}\")\n",
        "    print(f\"Request Body: {json.dumps(tags_to_validate_payload, indent=2)}\")\n",
        "\n",
        "    try:\n",
        "        validate_response = requests.post(\n",
        "            f\"{legal_endpoint}/legaltags:validate\",\n",
        "            headers=headers,\n",
        "            data=json.dumps(tags_to_validate_payload)\n",
        "        )\n",
        "        validate_response.raise_for_status()\n",
        "\n",
        "        print(f\"Validation request successful (Status Code: {validate_response.status_code}).\")\n",
        "        validation_result = validate_response.json()\n",
        "        print(\"Validation Results:\")\n",
        "        print(json.dumps(validation_result, indent=2))\n",
        "\n",
        "        # Interpretation of results\n",
        "        if 'invalidLegalTags' in validation_result:\n",
        "            if not validation_result['invalidLegalTags']:\n",
        "                print(f\"   Interpretation: All tags in the request ({tags_to_validate_payload['names']}) are valid.\")\n",
        "            else:\n",
        "                print(f\"   Interpretation: The following tags were reported as invalid: {validation_result['invalidLegalTags']}\")\n",
        "                # Check if the expected invalid tag is present\n",
        "                if invalid_test_tag_name in validation_result['invalidLegalTags']:\n",
        "                     print(f\"      As expected, '{invalid_test_tag_name}' was found to be invalid.\")\n",
        "                # Check if the supposedly valid tag was reported as invalid (problem?)\n",
        "                if created_tag_name in validation_result['invalidLegalTags']:\n",
        "                     print(f\"      WARNING: Tag '{created_tag_name}', which should be valid, was reported as invalid!\")\n",
        "        else:\n",
        "             print(\"   Warning: 'invalidLegalTags' key not found in the response.\")\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error validating legal tags: {e}\")\n",
        "        if e.response is not None:\n",
        "            print(f\"Response Body: {e.response.text}\")\n",
        "else:\n",
        "    print(\"Variable 'created_tag_name' is not defined. Cannot validate tag. Please ensure Step 1 ran successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOD8nyDzuoXZ"
      },
      "source": [
        "### 6. Get Properties Schema\n",
        "\n",
        "Retrieve the schema definition for the `properties` object within a legal tag. This defines which properties are allowed and their expected data types or allowed values (often linked to OSDU reference data).\n",
        "\n",
        "**API Endpoint:** `GET /legaltags:properties`\n",
        "**Access needed:** `service.legal.user`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ur6cPVv9uoXZ",
        "tags": [],
        "outputId": "43693e84-1acb-4331-9742-77b987697d5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to get legal tag properties schema...\n",
            "Error getting legal tag properties schema: HTTPSConnectionPool(host='osdu.osdu-bootcamp.com', port=443): Max retries exceeded with url: /api/legal/v1/legaltags:properties (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x79e2518e3f50>, 'Connection to osdu.osdu-bootcamp.com timed out. (connect timeout=None)'))\n"
          ]
        }
      ],
      "source": [
        "print(\"Attempting to get legal tag properties schema...\")\n",
        "try:\n",
        "    properties_response = requests.get(\n",
        "        f\"{legal_endpoint}/legaltags:properties\",\n",
        "        headers=headers\n",
        "    )\n",
        "    properties_response.raise_for_status()\n",
        "\n",
        "    print(f\"Get properties schema successful (Status Code: {properties_response.status_code}).\")\n",
        "    print(\"Legal Tag Properties Schema:\")\n",
        "    print(json.dumps(properties_response.json(), indent=2))\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error getting legal tag properties schema: {e}\")\n",
        "    if e.response is not None:\n",
        "        print(f\"Response Body: {e.response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfNzSotQuoXZ"
      },
      "source": [
        "### 7. Delete Legal Tag\n",
        "\n",
        "Delete the legal tag created during this lab.\n",
        "\n",
        "**API Endpoint:** `DELETE /legaltags/{tagName}`\n",
        "**Access needed:** `service.legal.admin`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "VeSre148uoXZ",
        "tags": [],
        "outputId": "9e96769c-59d3-41ec-afab-bdb86b0cbe79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variable 'created_tag_name' is not defined. Cannot delete tag. Please ensure Step 1 ran successfully or check if it was already deleted.\n"
          ]
        }
      ],
      "source": [
        "# Ensure created_tag_name has a value\n",
        "if created_tag_name:\n",
        "    print(f\"Attempting to delete legal tag: {created_tag_name}\")\n",
        "    try:\n",
        "        # Send DELETE request\n",
        "        delete_response = requests.delete(\n",
        "            f\"{legal_endpoint}/legaltags/{created_tag_name}\",\n",
        "            headers=headers\n",
        "        )\n",
        "        # Successful deletion usually returns 204 No Content\n",
        "        delete_response.raise_for_status()\n",
        "\n",
        "        print(f\"Legal tag deletion successful (Status Code: {delete_response.status_code}).\")\n",
        "        if delete_response.text:\n",
        "            print(f\"Response Body: {delete_response.text}\") # Should ideally be empty\n",
        "\n",
        "        # --- Verification ---\n",
        "        print(f\"\\nVerifying deletion by trying to retrieve tag: {created_tag_name}...\")\n",
        "        try:\n",
        "            verify_response = requests.get(\n",
        "                f\"{legal_endpoint}/legaltags/{created_tag_name}\",\n",
        "                headers=headers\n",
        "            )\n",
        "            # We EXPECT this to fail with a 404 Not Found error\n",
        "            if verify_response.status_code == 404:\n",
        "                print(f\"   Verification successful: Received expected 404 Not Found for tag '{created_tag_name}'.\")\n",
        "            else:\n",
        "                # If it succeeds or fails with a different error, the deletion might not have worked\n",
        "                verify_response.raise_for_status() # Raise other errors\n",
        "                print(f\"   Verification Warning: Retrieval after delete returned {verify_response.status_code} instead of 404.\")\n",
        "                print(f\"   Response Body: {verify_response.text}\")\n",
        "\n",
        "        except requests.exceptions.RequestException as ve:\n",
        "            # Specifically catch the expected 404 during verification\n",
        "            if ve.response is not None and ve.response.status_code == 404:\n",
        "                 print(f\"   Verification successful: GET request failed with expected 404 Not Found for tag '{created_tag_name}'.\")\n",
        "            else:\n",
        "                 # Unexpected error during verification\n",
        "                 print(f\"   Verification Error: Unexpected error while trying to retrieve deleted tag: {ve}\")\n",
        "                 if ve.response is not None:\n",
        "                      print(f\"   Verification Response Body: {ve.response.text}\")\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error deleting legal tag '{created_tag_name}': {e}\")\n",
        "        if e.response is not None:\n",
        "            # A 404 here means it was likely already deleted\n",
        "            if e.response.status_code == 404:\n",
        "                 print(f\"   Tag '{created_tag_name}' seems to have been already deleted (received 404).\" )\n",
        "            else:\n",
        "                 print(f\"Response Body: {e.response.text}\")\n",
        "\n",
        "    # Clean up variable even if deletion failed (to prevent reuse issues)\n",
        "    print(f\"\\nDeleting variable created_tag_name ('{created_tag_name}') from notebook memory.\")\n",
        "    del created_tag_name\n",
        "\n",
        "else:\n",
        "    print(\"Variable 'created_tag_name' is not defined. Cannot delete tag. Please ensure Step 1 ran successfully or check if it was already deleted.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtBRBVtDuoXZ"
      },
      "source": [
        "### Challenge\n",
        "\n",
        "1.  Create a new legal tag named `{osdu_data_partition_id}-challenge-tag-{user_id}`.\n",
        "    *   Set `countryOfOrigin` to `['CA']` (Canada).\n",
        "    *   Set `expirationDate` to `2025-12-31`.\n",
        "    *   Include other mandatory properties required by the schema (Hint: refer to the output of Step 6 or the initial create payload in Step 1, adapting values as needed).\n",
        "2.  Retrieve this challenge tag and print its details.\n",
        "3.  Update the tag's `properties`:\n",
        "    *   Change `contractId` to `challenge-contract-999`.\n",
        "    *   Change `expirationDate` to `2026-06-30`.\n",
        "    *   Ensure other properties are preserved.\n",
        "4.  Validate that your challenge tag name is valid.\n",
        "5.  Delete the challenge tag and verify its deletion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "qUQ3h3xBuoXZ",
        "outputId": "435f063d-ef9c-4877-a98c-96e9c6318f4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Legal Service Challenge ---\n",
            "Challenge Legal Tag Name: osdu-challenge-tag-7073\n"
          ]
        }
      ],
      "source": [
        "# Code block for setting up challenge variables\n",
        "print(\"--- Starting Legal Service Challenge ---\")\n",
        "\n",
        "# Define unique name for the challenge tag\n",
        "challenge_tag_name = f'{osdu_data_partition_id}-challenge-tag-{user_id}'\n",
        "challenge_tag_description = f\"Challenge Tag for user {user_id}\"\n",
        "\n",
        "print(f\"Challenge Legal Tag Name: {challenge_tag_name}\")\n",
        "\n",
        "# Use the standard 'headers' and 'legal_endpoint' defined earlier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MzlmMYIuoXZ"
      },
      "source": [
        "#### 💡 Solution Code Cells"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rUr6pzTuoXZ"
      },
      "source": [
        "###### 1. Create Challenge Tag"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIIW2hoC8J4P"
      },
      "source": [
        "dataType and securityClassification [requirements](https://osdu.pages.opengroup.org/platform/security-and-compliance/legal/api/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "NAy70LsC7j_Y",
        "outputId": "009a463b-70c3-48b2-8ad0-fceed56327c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Challenge Step 1: Creating tag: osdu-challenge-tag-7073\n",
            "   Request Body: {\n",
            "  \"name\": \"osdu-challenge-tag-7073\",\n",
            "  \"description\": \"Challenge Tag for user 7073\",\n",
            "  \"properties\": {\n",
            "    \"contractId\": \"CID-Challenge-7073\",\n",
            "    \"countryOfOrigin\": [\n",
            "      \"CA\"\n",
            "    ],\n",
            "    \"expirationDate\": \"2025-12-31\",\n",
            "    \"dataType\": \"Third Party Data\",\n",
            "    \"originator\": \"ChallengeUser-7073\",\n",
            "    \"personalData\": \"No Personal Data\",\n",
            "    \"securityClassification\": \"Private\",\n",
            "    \"exportClassification\": \"EAR99\"\n",
            "  }\n",
            "}\n",
            "   Error creating challenge tag: HTTPSConnectionPool(host='osdu.osdu-bootcamp.com', port=443): Max retries exceeded with url: /api/legal/v1/legaltags (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x79e2517b4320>, 'Connection to osdu.osdu-bootcamp.com timed out. (connect timeout=None)'))\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nChallenge Step 1: Creating tag: {challenge_tag_name}\")\n",
        "\n",
        "# Define the payload, ensuring all required properties are included\n",
        "challenge_create_payload = {\n",
        "    \"name\": challenge_tag_name,\n",
        "    \"description\": challenge_tag_description,\n",
        "    \"properties\": {\n",
        "        \"contractId\": f\"CID-Challenge-{user_id}\", # Example value\n",
        "        \"countryOfOrigin\": [\"CA\"], # Challenge requirement\n",
        "        \"expirationDate\": \"2025-12-31\", # Challenge requirement\n",
        "        \"dataType\": \"Third Party Data\", # Example, check reference values if needed\n",
        "        \"originator\": f\"ChallengeUser-{user_id}\", # Example value\n",
        "        \"personalData\": \"No Personal Data\", # Example value\n",
        "        \"securityClassification\": \"Private\", # Example value # UPDATED - Restricted\n",
        "        \"exportClassification\": \"EAR99\" # Example value\n",
        "    }\n",
        "}\n",
        "print(f\"   Request Body: {json.dumps(challenge_create_payload, indent=2)}\")\n",
        "\n",
        "try:\n",
        "    challenge_create_response = requests.post(\n",
        "        f\"{legal_endpoint}/legaltags\",\n",
        "        headers=headers,\n",
        "        data=json.dumps(challenge_create_payload)\n",
        "    )\n",
        "\n",
        "    if challenge_create_response.status_code == 409:\n",
        "        print(f\"   Challenge tag '{challenge_tag_name}' already exists (409). Proceeding...\")\n",
        "    else:\n",
        "        challenge_create_response.raise_for_status()\n",
        "        print(f\"   Challenge tag created successfully ({challenge_create_response.status_code}).\")\n",
        "        # print(f\"   Response: {json.dumps(challenge_create_response.json(), indent=2)}\")\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"   Error creating challenge tag: {e}\")\n",
        "    if e.response is not None:\n",
        "        print(f\"   Response Body: {e.response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWkQgDkTuoXa"
      },
      "source": [
        "##### 2. Retrieve Challenge Tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "jva1OLcuuoXa",
        "outputId": "60ae30b6-8296-4eda-8b99-4ca6dec7a029",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Challenge Step 2: Retrieving tag: osdu-challenge-tag-7073\n",
            "   Error retrieving challenge tag: HTTPSConnectionPool(host='osdu.osdu-bootcamp.com', port=443): Max retries exceeded with url: /api/legal/v1/legaltags/osdu-challenge-tag-7073 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x79e25176b830>, 'Connection to osdu.osdu-bootcamp.com timed out. (connect timeout=None)'))\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nChallenge Step 2: Retrieving tag: {challenge_tag_name}\")\n",
        "retrieved_challenge_tag_data = None # Initialize variable\n",
        "try:\n",
        "    challenge_get_response = requests.get(\n",
        "        f\"{legal_endpoint}/legaltags/{challenge_tag_name}\",\n",
        "        headers=headers\n",
        "    )\n",
        "    challenge_get_response.raise_for_status()\n",
        "    retrieved_challenge_tag_data = challenge_get_response.json()\n",
        "    print(f\"   Challenge tag retrieved successfully ({challenge_get_response.status_code}).\")\n",
        "    print(\"   Retrieved Tag Details:\")\n",
        "    print(json.dumps(retrieved_challenge_tag_data, indent=2))\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"   Error retrieving challenge tag: {e}\")\n",
        "    if e.response is not None:\n",
        "        print(f\"   Response Body: {e.response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CM60FSFguoXa"
      },
      "source": [
        "##### 3. Update Challenge Tag"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpo1ImAa-lLu"
      },
      "source": [
        "update_payload['properties'] requirements.\n",
        "- [link1](https://osdu.pages.opengroup.org/platform/security-and-compliance/legal/api/#updating-a-legaltag)\n",
        "- [link2](https://community.opengroup.org/osdu/platform/security-and-compliance/legal/-/blob/master/docs/api/legal_openapi.yaml?ref_type=heads)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "cAwqHtsA-fZE",
        "outputId": "6255e87a-0eaf-4c07-a2e5-3e7561d3bbc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Challenge Step 3: Updating tag: osdu-challenge-tag-7073\n",
            "   Skipping update because challenge tag data was not retrieved successfully in Step 2.\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nChallenge Step 3: Updating tag: {challenge_tag_name}\")\n",
        "\n",
        "# Check if we successfully retrieved the tag in the previous step\n",
        "if retrieved_challenge_tag_data:\n",
        "    # Modify the retrieved data\n",
        "    update_payload = {}\n",
        "\n",
        "    if 'properties' in retrieved_challenge_tag_data:\n",
        "        update_payload['name'] = retrieved_challenge_tag_data['name']\n",
        "        update_payload['contractId'] = \"challenge-contract-999\" # Update property\n",
        "        update_payload['expirationDate'] = \"2026-06-30\" # Update property\n",
        "        update_payload['description'] = f\"{challenge_tag_description} - Updated\" # Update description too\n",
        "    # else:\n",
        "        print(\"   Warning: 'properties' key not found in retrieved challenge tag data. Cannot update properties.\")\n",
        "\n",
        "    print(f\"   Attempting to PUT updated challenge tag...\")\n",
        "    print(f\"   Update Request Body: {json.dumps(update_payload, indent=2)}\")\n",
        "    try:\n",
        "        challenge_update_response = requests.put(\n",
        "            f\"{legal_endpoint}/legaltags\",\n",
        "            headers=headers,\n",
        "            data=json.dumps(update_payload)\n",
        "        )\n",
        "        challenge_update_response.raise_for_status()\n",
        "        print(f\"   Challenge tag update successful ({challenge_update_response.status_code}).\")\n",
        "        print(\"   Updated Tag Details:\")\n",
        "        print(json.dumps(challenge_update_response.json(), indent=2))\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"   Error updating challenge tag: {e}\")\n",
        "        if e.response is not None:\n",
        "            print(f\"   Response Body: {e.response.text}\")\n",
        "else:\n",
        "    print(\"   Skipping update because challenge tag data was not retrieved successfully in Step 2.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DafdwdfeuoXa"
      },
      "source": [
        "##### 4. Validate Challenge Tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "LGcTlbeduoXa",
        "outputId": "7482738f-008e-428d-bf45-91ba24db36f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Challenge Step 4: Validating tag: osdu-challenge-tag-7073\n",
            "   Request Body: {\n",
            "  \"names\": [\n",
            "    \"osdu-challenge-tag-7073\"\n",
            "  ]\n",
            "}\n",
            "   Error validating challenge tag: HTTPSConnectionPool(host='osdu.osdu-bootcamp.com', port=443): Max retries exceeded with url: /api/legal/v1/legaltags:validate (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x79e2517b6690>, 'Connection to osdu.osdu-bootcamp.com timed out. (connect timeout=None)'))\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nChallenge Step 4: Validating tag: {challenge_tag_name}\")\n",
        "\n",
        "challenge_validate_payload = {\"names\": [challenge_tag_name]}\n",
        "print(f\"   Request Body: {json.dumps(challenge_validate_payload, indent=2)}\")\n",
        "\n",
        "try:\n",
        "    challenge_validate_response = requests.post(\n",
        "        f\"{legal_endpoint}/legaltags:validate\",\n",
        "        headers=headers,\n",
        "        data=json.dumps(challenge_validate_payload)\n",
        "    )\n",
        "    challenge_validate_response.raise_for_status()\n",
        "\n",
        "    validation_result = challenge_validate_response.json()\n",
        "    print(f\"   Validation request successful ({challenge_validate_response.status_code}).\")\n",
        "    print(\"   Validation Results:\")\n",
        "    print(json.dumps(validation_result, indent=2))\n",
        "\n",
        "    # Interpretation\n",
        "    if 'invalidLegalTags' in validation_result and not validation_result['invalidLegalTags']:\n",
        "        print(f\"   Interpretation: Tag '{challenge_tag_name}' is valid.\")\n",
        "    else:\n",
        "        print(f\"   Interpretation: Tag '{challenge_tag_name}' reported as invalid (or unexpected response format). Invalid tags: {validation_result.get('invalidLegalTags')}\")\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"   Error validating challenge tag: {e}\")\n",
        "    if e.response is not None:\n",
        "        print(f\"   Response Body: {e.response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzzPiaY3uoXa"
      },
      "source": [
        "##### 5. Delete Challenge Tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "-UVSVoHsuoXa",
        "outputId": "7bf41b75-9dde-414f-b0af-bb120a3c8b64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Challenge Step 5: Deleting tag: osdu-challenge-tag-7073\n",
            "   Error deleting challenge tag: HTTPSConnectionPool(host='osdu.osdu-bootcamp.com', port=443): Max retries exceeded with url: /api/legal/v1/legaltags/osdu-challenge-tag-7073 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x79e2519a39b0>, 'Connection to osdu.osdu-bootcamp.com timed out. (connect timeout=None)'))\n",
            "--- Legal Service Challenge Complete ---\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nChallenge Step 5: Deleting tag: {challenge_tag_name}\")\n",
        "try:\n",
        "    challenge_delete_response = requests.delete(\n",
        "        f\"{legal_endpoint}/legaltags/{challenge_tag_name}\",\n",
        "        headers=headers\n",
        "    )\n",
        "    challenge_delete_response.raise_for_status()\n",
        "    print(f\"   Challenge tag deletion successful ({challenge_delete_response.status_code}).\")\n",
        "\n",
        "    # Verification\n",
        "    print(f\"   Verifying deletion by trying to retrieve tag: {challenge_tag_name}...\")\n",
        "    try:\n",
        "        verify_response = requests.get(f\"{legal_endpoint}/legaltags/{challenge_tag_name}\", headers=headers)\n",
        "        if verify_response.status_code == 404:\n",
        "            print(\"      Verification successful: Received expected 404 Not Found.\")\n",
        "        else:\n",
        "             verify_response.raise_for_status()\n",
        "             print(f\"      Verification Warning: Retrieval after delete returned {verify_response.status_code} instead of 404.\")\n",
        "             print(f\"      Response Body: {verify_response.text}\")\n",
        "    except requests.exceptions.RequestException as ve:\n",
        "        if ve.response is not None and ve.response.status_code == 404:\n",
        "            print(\"      Verification successful: GET request failed with expected 404 Not Found.\")\n",
        "        else:\n",
        "            print(f\"      Verification Error: Unexpected error during verification GET: {ve}\")\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"   Error deleting challenge tag: {e}\")\n",
        "    if e.response is not None:\n",
        "        if e.response.status_code == 404:\n",
        "            print(f\"      Tag '{challenge_tag_name}' seems to have been already deleted (received 404 on delete attempt).\" )\n",
        "        else:\n",
        "            print(f\"   Response Body: {e.response.text}\")\n",
        "\n",
        "print(\"--- Legal Service Challenge Complete ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtDKJTkquoXa"
      },
      "source": [
        "## OSDU Schema Service Lab\n",
        "\n",
        "This lab explores the OSDU Schema Service, which is responsible for managing the definitions (schemas) of data types stored within the OSDU platform. Schemas define the structure, attributes, and data types for each kind of record (e.g., Wellbore, Log, Document).\n",
        "\n",
        "**Key Concepts:**\n",
        "*   **Schema:** A JSON document defining the structure of a specific data kind.\n",
        "*   **Kind:** A unique identifier for a schema, typically following the pattern `{authority}:{source}:{type}:{version}` (e.g., `osdu:wks:master-data--Wellbore:1.0.0`).\n",
        "*   **SchemaInfo:** Metadata about the schema itself (e.g., status, scope, author).\n",
        "\n",
        "**Objectives:**\n",
        "*   List available schemas.\n",
        "*   Retrieve a specific schema definition.\n",
        "*   *Attempt* to create a new custom schema (experimental/requires specific permissions).\n",
        "*   *Attempt* to verify the creation of the custom schema.\n",
        "\n",
        "**Documentation:**\n",
        "*   [Schema Service Concepts](https://osdu.pages.opengroup.org/platform/system/schema-service/)\n",
        "*   [API Specification](https://community.opengroup.org/osdu/platform/system/schema-service/-/blob/master/openapi/schema-service.yaml)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gNGHUJOuoXa"
      },
      "source": [
        "### Setup: Schema Lab\n",
        "\n",
        "This cell sets up the necessary variables for the Schema Service lab exercises.\n",
        "\n",
        "**Dependencies:**\n",
        "*   Requires the `requests` and `json` libraries (imported in the initial setup).\n",
        "*   Relies on variables defined during the initial authentication: `osdu_endpoint`, `headers`, `user_id`, `osdu_data_partition_id`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Eo8NAXWruoXa",
        "tags": [],
        "outputId": "8a2e80db-b56f-49bd-c7dd-3c65575a3514",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Schema API Endpoint: https://osdu.osdu-bootcamp.com/api/schema-service/v1\n",
            "Reminder - Using unique identifier: 7073\n"
          ]
        }
      ],
      "source": [
        "# Define the base endpoint for the Schema Service API\n",
        "schema_endpoint = f\"{osdu_endpoint}/api/schema-service/v1\"\n",
        "print(f\"Using Schema API Endpoint: {schema_endpoint}\")\n",
        "\n",
        "# Use the globally defined headers including Authorization and data-partition-id\n",
        "# print(f\"Using Headers: {json.dumps(headers, indent=2)}\")\n",
        "\n",
        "print(f\"Reminder - Using unique identifier: {user_id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vxcWwztGO-T"
      },
      "source": [
        "### 1. List All Schemas\n",
        "\n",
        "Retrieve a list of schemas registered in the connected OSDU instance for the current data partition.\n",
        "\n",
        "**API Endpoint:** `GET /schema`\n",
        "**Access needed:** `service.schema.viewer`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "SRfGImGGGjnI",
        "outputId": "d13951e5-d00f-43a6-b545-df7d400a9fa7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to list all schemas...\n",
            "Error listing schemas: HTTPSConnectionPool(host='osdu.osdu-bootcamp.com', port=443): Max retries exceeded with url: /api/schema-service/v1/schema?limit=1500 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x79e2517b62a0>, 'Connection to osdu.osdu-bootcamp.com timed out. (connect timeout=None)'))\n"
          ]
        }
      ],
      "source": [
        "print(\"Attempting to list all schemas...\")\n",
        "try:\n",
        "    # Send GET request to the /schemas endpoint\n",
        "    list_schemas_response = requests.get(\n",
        "        f\"{schema_endpoint}/schema?limit=1500\",\n",
        "        headers=headers\n",
        "        # No request body needed for GET\n",
        "    )\n",
        "    list_schemas_response.raise_for_status() # Check for HTTP errors\n",
        "\n",
        "    print(f\"List Schemas successful (Status Code: {list_schemas_response.status_code}).\")\n",
        "    schemas_data = list_schemas_response.json()\n",
        "\n",
        "    # The response typically contains 'schemas' (list of kinds), 'offset', 'count', 'totalCount'\n",
        "    total_count = schemas_data.get(\"totalCount\", \"N/A\")\n",
        "    returned_count = schemas_data.get(\"count\", \"N/A\")\n",
        "    print(f\"Total schemas reported: {total_count}\")\n",
        "    print(f\"Schemas returned in this response: {returned_count}\")\n",
        "\n",
        "    # Print the full response or just the list of schema kinds\n",
        "    print(\"Schema Kinds Returned:\")\n",
        "    if 'schemaInfos' in schemas_data and isinstance(schemas_data['schemaInfos'], list):\n",
        "       # Print first 10 kinds for brevity\n",
        "       print(json.dumps(schemas_data['schemaInfos'][:10], indent=2))\n",
        "       if len(schemas_data['schemaInfos']) > 10:\n",
        "           print(\"... (list truncated)\")\n",
        "    else:\n",
        "        print(\"Could not find 'schemaInfos' list in response:\")\n",
        "        print(json.dumps(schemas_data, indent=2))\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error listing schemas: {e}\")\n",
        "    if e.response is not None:\n",
        "        print(f\"Response Body: {e.response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgLCwfPuuoXa"
      },
      "source": [
        "### 2. Get a Specific Schema\n",
        "\n",
        "Retrieve the full definition (JSON structure) of a specific schema using its `kind`.\n",
        "\n",
        "**API Endpoint:** `GET /schemas/{kind}`\n",
        "**Access needed:** `service.schema.viewer`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "YvNPVDu9uoXa",
        "tags": [],
        "outputId": "209c7bc8-fd7b-421a-c6e1-c1fcb5525b3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to retrieve schema definition for kind: osdu:wks:master-data--Wellbore:1.0.0...\n",
            "Error retrieving schema 'osdu:wks:master-data--Wellbore:1.0.0': HTTPSConnectionPool(host='osdu.osdu-bootcamp.com', port=443): Max retries exceeded with url: /api/schema-service/v1/schema/osdu:wks:master-data--Wellbore:1.0.0 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x79e25176a4b0>, 'Connection to osdu.osdu-bootcamp.com timed out. (connect timeout=None)'))\n"
          ]
        }
      ],
      "source": [
        "# Specify the kind of the schema to retrieve\n",
        "schema_kind_to_get = \"osdu:wks:master-data--Wellbore:1.0.0\" # Example: Wellbore schema\n",
        "# Alternative example: \"osdu:wks:work-product-component--WellLog:1.0.0\"\n",
        "\n",
        "print(f\"Attempting to retrieve schema definition for kind: {schema_kind_to_get}...\")\n",
        "try:\n",
        "    # Send GET request to the specific schema kind endpoint\n",
        "    get_schema_response = requests.get(\n",
        "        f\"{schema_endpoint}/schema/{schema_kind_to_get}\",\n",
        "        headers=headers\n",
        "    )\n",
        "    get_schema_response.raise_for_status() # Check for errors (e.g., 404 if kind not found)\n",
        "\n",
        "    print(f\"Successfully retrieved schema (Status Code: {get_schema_response.status_code}).\")\n",
        "    print(f\"Definition for schema '{schema_kind_to_get}':\")\n",
        "    print(json.dumps(get_schema_response.json(), indent=2))\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error retrieving schema '{schema_kind_to_get}': {e}\")\n",
        "    if e.response is not None:\n",
        "        print(f\"Response Body: {e.response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Nq1ZZzDuoXb"
      },
      "source": [
        "### 3. Create a Custom Schema\n",
        "\n",
        "Define and attempt to register a new custom schema. This is typically an administrative task and requires specific permissions (`service.schema.editor`). The exact required fields in the `schema` block can vary.\n",
        "\n",
        "**This step is likely to fail without proper setup and permissions.**\n",
        "\n",
        "**API Endpoint:** `POST /schemas`\n",
        "**Access needed:** `service.schema.editor`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "TXkUeIB_uoXb",
        "tags": [],
        "outputId": "c9782ae8-3b24-4399-f474-cc4837196582",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to create custom schema with kind: osdu:lab-custom:my-custom-type-7073:1.0.0...\n",
            "Request Body: {\n",
            "  \"schemaInfo\": {\n",
            "    \"schemaIdentity\": {\n",
            "      \"authority\": \"osdu\",\n",
            "      \"source\": \"lab-custom\",\n",
            "      \"entityType\": \"my-custom-type-7073\",\n",
            "      \"schemaVersionMajor\": 1,\n",
            "      \"schemaVersionMinor\": 0,\n",
            "      \"schemaVersionPatch\": 0,\n",
            "      \"id\": \"uri:osdu:lab-custom:my-custom-type-7073:1.0.0\"\n",
            "    },\n",
            "    \"status\": \"DEVELOPMENT\",\n",
            "    \"scope\": \"INTERNAL\",\n",
            "    \"supersededBy\": null\n",
            "  },\n",
            "  \"schema\": {\n",
            "    \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n",
            "    \"title\": \"My Custom Type 7073\",\n",
            "    \"description\": \"A custom schema created for the OSDU lab.\",\n",
            "    \"type\": \"object\",\n",
            "    \"properties\": {\n",
            "      \"CustomID\": {\n",
            "        \"type\": \"string\",\n",
            "        \"description\": \"A unique identifier for this custom record.\"\n",
            "      },\n",
            "      \"CustomName\": {\n",
            "        \"type\": \"string\",\n",
            "        \"description\": \"A name for this custom record.\"\n",
            "      },\n",
            "      \"MeasurementValue\": {\n",
            "        \"type\": \"number\",\n",
            "        \"description\": \"A measurement value.\"\n",
            "      }\n",
            "    },\n",
            "    \"required\": [\n",
            "      \"CustomID\"\n",
            "    ]\n",
            "  }\n",
            "}\n",
            "\n",
            "--- NOTE: This operation requires specific permissions and may fail. ---\n",
            "Error creating custom schema 'osdu:lab-custom:my-custom-type-7073:1.0.0': HTTPSConnectionPool(host='osdu.osdu-bootcamp.com', port=443): Max retries exceeded with url: /api/schema-service/v1/schema (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x79e2517b6a50>, 'Connection to osdu.osdu-bootcamp.com timed out. (connect timeout=None)'))\n"
          ]
        }
      ],
      "source": [
        "# Define a unique kind for the custom schema using the data partition and user_id\n",
        "custom_schema_authority = osdu_data_partition_id # Using data partition as authority\n",
        "custom_schema_source = \"lab-custom\"\n",
        "custom_schema_type = f\"my-custom-type-{user_id}\"\n",
        "custom_schema_version = \"1.0.0\"\n",
        "custom_schema_kind = f\"{custom_schema_authority}:{custom_schema_source}:{custom_schema_type}:{custom_schema_version}\"\n",
        "\n",
        "# Define the schema payload (structure based on OSDU standards)\n",
        "custom_schema_payload = {\n",
        "    \"schemaInfo\": {\n",
        "        \"schemaIdentity\": {\n",
        "            \"authority\": custom_schema_authority,\n",
        "            \"source\": custom_schema_source,\n",
        "            \"entityType\": custom_schema_type,\n",
        "            \"schemaVersionMajor\": 1,\n",
        "            \"schemaVersionMinor\": 0,\n",
        "            \"schemaVersionPatch\": 0,\n",
        "            \"id\": f\"uri:{custom_schema_kind}\" # Often derived from the kind\n",
        "        },\n",
        "        \"status\": \"DEVELOPMENT\", # Common statuses: DEVELOPMENT, STABLE, OBSOLETE\n",
        "        \"scope\": \"INTERNAL\", # Or SHARED\n",
        "        \"supersededBy\": None\n",
        "        # \"createdBy\" and \"dateCreated\" are usually set by the service\n",
        "    },\n",
        "    \"schema\": { # The actual schema definition (JSON Schema format)\n",
        "        \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n",
        "        \"title\": f\"My Custom Type {user_id}\",\n",
        "        \"description\": \"A custom schema created for the OSDU lab.\",\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"CustomID\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"A unique identifier for this custom record.\"\n",
        "            },\n",
        "            \"CustomName\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"A name for this custom record.\"\n",
        "            },\n",
        "            \"MeasurementValue\": {\n",
        "                \"type\": \"number\",\n",
        "                \"description\": \"A measurement value.\"\n",
        "            }\n",
        "            # Add other properties as needed\n",
        "        },\n",
        "        \"required\": [\"CustomID\"] # Specify mandatory fields\n",
        "    }\n",
        "}\n",
        "\n",
        "print(f\"Attempting to create custom schema with kind: {custom_schema_kind}...\")\n",
        "print(f\"Request Body: {json.dumps(custom_schema_payload, indent=2)}\")\n",
        "print(\"\\n--- NOTE: This operation requires specific permissions and may fail. ---\")\n",
        "\n",
        "try:\n",
        "    # Send POST request to create the schema\n",
        "    create_custom_schema_response = requests.post(\n",
        "        f\"{schema_endpoint}/schema\",\n",
        "        headers=headers,\n",
        "        data=json.dumps(custom_schema_payload)\n",
        "    )\n",
        "    create_custom_schema_response.raise_for_status()\n",
        "\n",
        "    print(f\"Custom schema creation request successful (Status Code: {create_custom_schema_response.status_code}).\")\n",
        "    print(\"Schema creation response:\")\n",
        "    # Response might be empty or confirm the kind/details\n",
        "    if create_custom_schema_response.text:\n",
        "        print(json.dumps(create_custom_schema_response.json(), indent=2))\n",
        "    else:\n",
        "        print(\"(Empty Response Body)\")\n",
        "    print(\"Note: Schema creation might take time to become fully available.\")\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error creating custom schema '{custom_schema_kind}': {e}\")\n",
        "    if e.response is not None:\n",
        "        print(f\"Response Status Code: {e.response.status_code}\")\n",
        "        print(f\"Response Body: {e.response.text}\")\n",
        "        if e.response.status_code == 403:\n",
        "             print(\"   Hint: Status code 403 (Forbidden) usually indicates missing 'service.schema.editor' permissions.\")\n",
        "        elif e.response.status_code == 400:\n",
        "             print(\"   Hint: Status code 400 (Bad Request) often indicates an invalid payload/schema structure.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vc-baI8GuoXb"
      },
      "source": [
        "### 4. Verify Custom Schema Creation\n",
        "Attempt to retrieve the custom schema created in the previous step to verify it exists. This depends entirely on the success of Step 3.\n",
        "\n",
        "**API Endpoint:** `GET /schemas/{kind}`\n",
        "**Access needed:** `service.schema.viewer`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGs29s3uuoXb",
        "tags": [],
        "outputId": "bc865b6a-5dac-4ee8-8f9d-f4ea35a4196d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to verify custom schema creation by retrieving kind: osdu:lab-custom:my-custom-type-7073:1.0.0...\n",
            "--- NOTE: This will only succeed if Step 3 was successful. ---\n"
          ]
        }
      ],
      "source": [
        "# Use the 'custom_schema_kind' defined in the previous step\n",
        "print(f\"Attempting to verify custom schema creation by retrieving kind: {custom_schema_kind}...\")\n",
        "print(\"--- NOTE: This will only succeed if Step 3 was successful. ---\")\n",
        "\n",
        "try:\n",
        "    # Send GET request to retrieve the custom schema\n",
        "    verify_schema_response = requests.get(\n",
        "        f\"{schema_endpoint}/schema/{custom_schema_kind}\",\n",
        "        headers=headers\n",
        "    )\n",
        "    verify_schema_response.raise_for_status() # Expect 404 if Step 3 failed\n",
        "\n",
        "    print(f\"Successfully retrieved custom schema (Status Code: {verify_schema_response.status_code}). Verification PASSED.\")\n",
        "    print(f\"Definition for schema '{custom_schema_kind}':\")\n",
        "    print(json.dumps(verify_schema_response.json(), indent=2))\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error retrieving custom schema '{custom_schema_kind}' (Verification FAILED): {e}\")\n",
        "    if e.response is not None:\n",
        "        print(f\"Response Status Code: {e.response.status_code}\")\n",
        "        print(f\"Response Body: {e.response.text}\")\n",
        "        if e.response.status_code == 404:\n",
        "            print(\"   Hint: Status code 404 (Not Found) is expected if the schema was not created successfully in Step 3.\")\n",
        "    else:\n",
        "        # Handle cases where there's no response object (e.g., network error)\n",
        "        print(\"   No response received from the server.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsh6tgtBuoXb"
      },
      "source": [
        "### Challenge\n",
        "\n",
        "Retrieve all registered schema *versions* for the `master-data--Wellbore` entity type, which belongs to the `osdu:wks` authority and source. Print their kinds.\n",
        "\n",
        "**Hint:** You will need to use the results from Step 1 (List All Schemas) and filter the kinds based on the authority, source, and entity type pattern."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2Opsoe5uoXb",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Challenge: Find all versions of osdu:wks:master-data--Wellbore\n",
        "target_authority = \"osdu\"\n",
        "target_source = \"wks\"\n",
        "target_entity = \"master-data--Wellbore\"\n",
        "target_prefix = f\"{target_authority}:{target_source}:{target_entity}:\"\n",
        "\n",
        "print(f\"Challenge: Finding all schema kinds starting with prefix: '{target_prefix}'...\")\n",
        "print(\"--- NOTE: This requires Step 1 (List All Schemas) to have run successfully. ---\")\n",
        "\n",
        "# Placeholder for the results\n",
        "wellbore_schema_versions = []\n",
        "\n",
        "# --- Add your implementation below ---\n",
        "# 1. Reuse the 'list_schemas_response' from Step 1 if it was successful\n",
        "# 2. If not, optionally re-run the GET /schemas call here.\n",
        "# 3. Extract the list of schema kinds from the response.\n",
        "# 4. Iterate through the list and check if each kind starts with 'target_prefix'.\n",
        "# 5. Add matching kinds to the 'wellbore_schema_versions' list.\n",
        "\n",
        "# Example Implementation (assuming list_schemas_response from Step 1 is available):\n",
        "try:\n",
        "    # Check if the response object from Step 1 exists and was successful\n",
        "    if 'list_schemas_response' in locals() and list_schemas_response.status_code == 200:\n",
        "        print(\"   Using schema list data from Step 1.\")\n",
        "        schemas_data = list_schemas_response.json()\n",
        "        if 'schemaInfos' in schemas_data and isinstance(schemas_data['schemaInfos'], list):\n",
        "            all_schema_kinds = schemas_data['schemaInfos']\n",
        "            for kind in all_schema_kinds:\n",
        "                authority = kind['schemaIdentity']['authority']\n",
        "                source = kind['schemaIdentity']['source']\n",
        "                entityType = kind['schemaIdentity']['entityType']\n",
        "\n",
        "                if (target_authority == authority) and (target_source == source) and (target_entity == entityType):\n",
        "                    wellbore_schema_versions.append(kind)\n",
        "        else:\n",
        "            print(\"   Error: 'schemaInfos' list not found in the Step 1 response data.\")\n",
        "    else:\n",
        "        print(\"   Warning: Schema list from Step 1 not available or was unsuccessful. Cannot perform filtering.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"   An unexpected error occurred during filtering: {e}\")\n",
        "\n",
        "# --- End of implementation ---\n",
        "\n",
        "# Print the results\n",
        "print(\"\\nChallenge Results:\")\n",
        "if wellbore_schema_versions:\n",
        "    print(\"Found Wellbore Schema Versions:\")\n",
        "    # Sort for better readability\n",
        "    for kind in wellbore_schema_versions:\n",
        "        print(f\"  - {kind}\")\n",
        "else:\n",
        "    print(\"Could not find any schema versions matching the criteria, or Step 1 failed.\")\n",
        "\n",
        "print(\"--- Schema Service Challenge Complete ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZSv_lSZuoXb"
      },
      "source": [
        "## OSDU Search Service Lab\n",
        "\n",
        "This lab demonstrates how to use the OSDU Search Service to find data records within the platform using various query mechanisms, including keyword search, text search, spatial filters, sorting, and pagination.\n",
        "\n",
        "**Key Concepts:**\n",
        "*   **Kind:** Specifies the type of record to search for (e.g., `osdu:wks:master-data--Wellbore:1.0.0`). Wildcards (`*`) can be used.\n",
        "*   **Query:** The search criteria. Can be a simple wildcard (`*`) or use Apache Lucene syntax for more complex text searches (e.g., `data.FacilityName:\"MyWell\" AND data.Status:\"Active\"`).\n",
        "*   **Limit:** The maximum number of results to return in a single request.\n",
        "*   **Cursor:** A pointer used for pagination to retrieve large result sets page by page.\n",
        "*   **Spatial Filter:** Allows searching for records based on geographic location (Point/Distance, Bounding Box, Polygon).\n",
        "*   **Aggregation:** Groups results based on a specific field (e.g., count records by `kind`).\n",
        "\n",
        "**Permissions Note:** Successful searching requires the `service.search.user` permission. However, the *results returned* also depend on the user having `VIEWER` permissions (defined in the record's Access Control List - ACL) for the individual records found by the search query.\n",
        "\n",
        "**Documentation:**\n",
        "*   [Search Service Usage](https://osdu.pages.opengroup.org/platform/system/search-service/)\n",
        "*   [API Specification](https://community.opengroup.org/osdu/platform/system/search-service/-/blob/master/open-api/search_openapi.yaml)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BN3BLOfuoXb"
      },
      "source": [
        "### Setup: Search Lab\n",
        "\n",
        "This cell sets up the necessary variables and helper functions for the Search Service lab exercises.\n",
        "\n",
        "**Dependencies:**\n",
        "*   Requires the `requests`, `json`, and `pandas` libraries.\n",
        "*   Relies on variables defined during the initial authentication: `osdu_endpoint`, `headers`, `osdu_data_partition_id`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EXpI32juoXb",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import pandas as pd # Ensure pandas is imported\n",
        "import requests\n",
        "import json\n",
        "\n",
        "# Define the base endpoint for the Search API V2\n",
        "search_endpoint = f\"{osdu_endpoint}/api/search/v2\"\n",
        "print(f\"Using Search API Endpoint: {search_endpoint}\")\n",
        "\n",
        "# Use the standard 'headers' defined in the initial setup\n",
        "# print(f\"Using Headers: {json.dumps(headers, indent=2)}\")\n",
        "\n",
        "# Helper function to format and print aggregation results\n",
        "def print_agg_list_result(response: requests.Response):\n",
        "  \"\"\"Parses aggregation results from a search response and prints as a Markdown table.\"\"\"\n",
        "  try:\n",
        "    response.raise_for_status() # Check for HTTP errors first\n",
        "    data = response.json()\n",
        "    # Check if 'aggregations' key exists and is a non-empty list\n",
        "    if 'aggregations' in data and isinstance(data['aggregations'], list) and data['aggregations']:\n",
        "      aggregation = data['aggregations']\n",
        "      # Dynamically get keys from the first item assuming structure is consistent\n",
        "      columns = list(aggregation[0].keys())\n",
        "      df = pd.DataFrame(aggregation, columns=columns)\n",
        "      # Standardize column names if 'key' and 'count' are present\n",
        "      rename_map = {}\n",
        "      if 'key' in df.columns:\n",
        "        rename_map['key'] = 'Kind (or Aggregation Key)'\n",
        "      if 'count' in df.columns:\n",
        "        rename_map['count'] = 'Count'\n",
        "      if rename_map:\n",
        "          df = df.rename(columns=rename_map)\n",
        "          # Sort if 'Kind' column exists\n",
        "          if 'Kind (or Aggregation Key)' in df.columns:\n",
        "             df.sort_values(by=['Kind (or Aggregation Key)'], inplace=True)\n",
        "      # Print as Markdown table\n",
        "      print(df.to_markdown(index=False))\n",
        "    elif 'aggregations' in data and not data['aggregations']:\n",
        "        print (\"Query successful, but no aggregations returned.\")\n",
        "    else:\n",
        "        print(\"Response does not contain 'aggregations' key or it's not a list.\")\n",
        "        print(json.dumps(data, indent=2))\n",
        "\n",
        "  except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error processing aggregation request: {e}\")\n",
        "    if e.response is not None:\n",
        "        print(f\"Response Body: {e.response.text}\")\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred while processing aggregation results: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYWrT0vmuoXb"
      },
      "source": [
        "### 1. Basic Search (Query API)\n",
        "\n",
        "Perform a simple search for Wellbore records (`osdu:wks:master-data--Wellbore:*`) using the `query` endpoint. We limit the results to 10.\n",
        "\n",
        "**API Endpoint:** `POST /query`\n",
        "**Permissions:** `service.search.user` + ACL `VIEWER` access to result records."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CL03RcJkuoXb",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Define the search payload\n",
        "basic_query_payload = {\n",
        "    \"kind\": \"osdu:wks:master-data--Wellbore:*\", # Search for any version of Wellbore\n",
        "    \"query\": \"*\", # Match all records of the specified kind\n",
        "    \"limit\": 10 # Return a maximum of 10 results\n",
        "    # \"returnedFields\": [\"id\", \"data.FacilityName\"] # Optional: Specify which fields to return\n",
        "}\n",
        "\n",
        "print(f\"Attempting basic search with payload:\")\n",
        "print(json.dumps(basic_query_payload, indent=2))\n",
        "\n",
        "try:\n",
        "    # Send POST request to the /query endpoint\n",
        "    basic_search_response = requests.post(\n",
        "        f\"{search_endpoint}/query\",\n",
        "        headers=headers,\n",
        "        data=json.dumps(basic_query_payload)\n",
        "    )\n",
        "    basic_search_response.raise_for_status() # Check for HTTP errors\n",
        "\n",
        "    print(f\"\\nBasic search successful (Status Code: {basic_search_response.status_code}).\")\n",
        "    results_data = basic_search_response.json()\n",
        "    print(f\"Total results matching query (if available): {results_data.get('totalCount', 'N/A')}\")\n",
        "    print(f\"Number of results returned: {len(results_data.get('results', []))}\")\n",
        "    print(\"Query Results:\")\n",
        "    print(json.dumps(results_data, indent=2))\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"\\nError during basic search: {e}\")\n",
        "    if e.response is not None:\n",
        "        print(f\"Response Body: {e.response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C996OXiYuoXb"
      },
      "source": [
        "### 2. Cursor Search (Query With Cursor API)\n",
        "\n",
        "Use the `query_with_cursor` endpoint to retrieve large result sets page by page. The first request initiates the search and returns the first page along with a `cursor`. Subsequent requests include the `cursor` in the payload to fetch the next page.\n",
        "\n",
        "**API Endpoint:** `POST /query_with_cursor`\n",
        "**Permissions:** `service.search.user` + ACL `VIEWER` access to result records."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncOMjFB-uoXb",
        "tags": []
      },
      "outputs": [],
      "source": [
        "all_cursor_results = []\n",
        "current_cursor = None\n",
        "page_count = 0\n",
        "max_pages_to_fetch = 3  # Limit the number of pages to fetch for this lab example\n",
        "results_per_page = 5\n",
        "\n",
        "print(f\"Attempting cursor search for 'osdu:wks:master-data--Well:*' (Max {max_pages_to_fetch} pages, {results_per_page} results/page)\")\n",
        "\n",
        "try:\n",
        "    while page_count < max_pages_to_fetch:\n",
        "        page_count += 1\n",
        "        print(f\"\\nFetching page {page_count}...\")\n",
        "\n",
        "        # Construct the payload for the current page\n",
        "        cursor_payload = {\n",
        "            \"kind\": \"osdu:wks:master-data--Well:*\", # Search for Well records\n",
        "            \"query\": \"*\",\n",
        "            \"limit\": results_per_page,\n",
        "            \"returnedFields\": [\"id\", \"data.FacilityName\"] # Return only specific fields\n",
        "        }\n",
        "        # Include the cursor if it exists (for pages after the first)\n",
        "        if current_cursor:\n",
        "            cursor_payload[\"cursor\"] = current_cursor\n",
        "            print(f\"   Using cursor: {current_cursor}\")\n",
        "        else:\n",
        "            print(\"   No cursor provided (fetching first page).\")\n",
        "\n",
        "        # print(f\"   Submitting payload: {json.dumps(cursor_payload, indent=2)}\")\n",
        "\n",
        "        # Send POST request to the /query_with_cursor endpoint\n",
        "        cursor_response = requests.post(\n",
        "            f\"{search_endpoint}/query_with_cursor\",\n",
        "            headers=headers,\n",
        "            json=cursor_payload # Use json= for automatic content-type header\n",
        "        )\n",
        "        cursor_response.raise_for_status()  # Raise exception for HTTP errors\n",
        "\n",
        "        results_page_data = cursor_response.json()\n",
        "        print(f\"   Page {page_count} request successful (Status Code: {cursor_response.status_code}).\")\n",
        "        # print(f\"Page {page_count} Raw Response:\")\n",
        "        print(json.dumps(results_page_data, indent=2))\n",
        "\n",
        "        # Process results from the current page\n",
        "        page_results = results_page_data.get('results', [])\n",
        "        if page_results:\n",
        "            print(f\"   Found {len(page_results)} results on this page.\")\n",
        "            all_cursor_results.extend(page_results)\n",
        "        else:\n",
        "            print(\"   No more results found on this page.\")\n",
        "            break # Exit loop if no results are returned\n",
        "\n",
        "        # Check for and update the cursor for the next iteration\n",
        "        if 'cursor' in results_page_data and results_page_data['cursor']:\n",
        "            current_cursor = results_page_data['cursor']\n",
        "            print(f\"   Received new cursor for next page: {current_cursor}\")\n",
        "        else:\n",
        "            print(\"   No cursor returned in response. Ending search.\")\n",
        "            break # Exit loop if no cursor is provided\n",
        "\n",
        "    print(f\"\\nCursor search finished after {page_count} page(s).\")\n",
        "    print(f\"Total results fetched across all pages: {len(all_cursor_results)}\")\n",
        "    # Optionally print all fetched results\n",
        "    print(\"All Fetched Results:\")\n",
        "    print(json.dumps(all_cursor_results, indent=2))\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"\\nError during cursor search on page {page_count}: {e}\")\n",
        "    if e.response is not None:\n",
        "        print(f\"Response Body: {e.response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3T7DJz2uoXc"
      },
      "source": [
        "### 3. Text-based Search (Query API)\n",
        "\n",
        "Use the standard `query` endpoint with Lucene syntax in the `query` parameter for more advanced text searching."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQcw4OmSuoXc"
      },
      "source": [
        "#### 3.1 Basic Text Search\n",
        "\n",
        "Search across many kinds (`osdu:wks:*:*`) for records containing the text `\"wellcom\"` anywhere in their indexed fields. Text search is typically case-insensitive and matches parts of words.\n",
        "\n",
        "**API Endpoint:** `POST /query`\n",
        "**Permissions:** `service.search.user` + ACL `VIEWER` access to result records."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C00pI01auoXc",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Define the payload for a general text search\n",
        "text_query_payload = {\n",
        "    \"kind\": \"osdu:wks:*:*\",  # Search across many kinds within the 'wks' source\n",
        "    \"query\": \"D12\",  # Lucene syntax: search for the term 'wellcom' in any indexed field\n",
        "    \"limit\": 10\n",
        "}\n",
        "\n",
        "print(f\"Attempting text search with payload:\")\n",
        "print(json.dumps(text_query_payload, indent=2))\n",
        "\n",
        "try:\n",
        "    text_search_response = requests.post(\n",
        "        f\"{search_endpoint}/query\",\n",
        "        headers=headers,\n",
        "        data=json.dumps(text_query_payload)\n",
        "    )\n",
        "    text_search_response.raise_for_status()\n",
        "\n",
        "    print(f\"\\nText search successful (Status Code: {text_search_response.status_code}).\")\n",
        "    results_data = text_search_response.json()\n",
        "    print(f\"Total results matching query (if available): {results_data.get('totalCount', 'N/A')}\")\n",
        "    print(f\"Number of results returned: {len(results_data.get('results', []))}\")\n",
        "    print(\"Query Results:\")\n",
        "    print(json.dumps(results_data, indent=2))\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"\\nError during text search: {e}\")\n",
        "    if e.response is not None:\n",
        "        print(f\"Response Body: {e.response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32m98Z4XuoXc"
      },
      "source": [
        "#### 3.2 Text Search in Specific Field\n",
        "\n",
        "Search for records where the specific field `data.FacilityName` contains the text `\"D12\"`. Note the use of `FieldName:\"Value\"` Lucene syntax. This search will find records with facility names like `\"Well D12\"`, `\"D12-Platform\"`, `\"D12-02\"`, etc.\n",
        "\n",
        "**API Endpoint:** `POST /query`\n",
        "**Permissions:** `service.search.user` + ACL `VIEWER` access to result records."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZreZtBIKuoXc",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Define the payload for text search within a specific field\n",
        "field_text_query_payload = {\n",
        "    \"kind\": \"osdu:wks:*:*\",\n",
        "    # Lucene query: Search for \"D12\" within the data.FacilityName field.\n",
        "    # The backslashes escape the quotes within the JSON string.\n",
        "    \"query\": \"data.FacilityName:\\\"D12\\\"\",\n",
        "    \"limit\": 10,\n",
        "    \"returnedFields\": [\"id\", \"kind\", \"data.FacilityName\"] # Return only relevant fields\n",
        "}\n",
        "\n",
        "print(f\"Attempting field-specific text search with payload:\")\n",
        "print(json.dumps(field_text_query_payload, indent=2))\n",
        "\n",
        "try:\n",
        "    field_text_response = requests.post(\n",
        "        f\"{search_endpoint}/query\",\n",
        "        headers=headers,\n",
        "        data=json.dumps(field_text_query_payload)\n",
        "    )\n",
        "    field_text_response.raise_for_status()\n",
        "\n",
        "    print(f\"\\nField text search successful (Status Code: {field_text_response.status_code}).\")\n",
        "    results_data = field_text_response.json()\n",
        "    print(f\"Total results matching query (if available): {results_data.get('totalCount', 'N/A')}\")\n",
        "    print(f\"Number of results returned: {len(results_data.get('results', []))}\")\n",
        "    print(\"Query Results:\")\n",
        "    print(json.dumps(results_data, indent=2))\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"\\nError during field text search: {e}\")\n",
        "    if e.response is not None:\n",
        "        print(f\"Response Body: {e.response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri7MrOUyuoXc"
      },
      "source": [
        "#### 3.3 Exact Match Keyword Search\n",
        "\n",
        "Search for records where the `data.FacilityName` field *exactly* matches `\"D12\"`. This uses the `.keyword` suffix (if configured in the search mapping for that field) to bypass text analysis and perform an exact, case-sensitive match.\n",
        "\n",
        "*   Running with `\"D12\"` might return no results if records have names like `\"D12-02\"`.\n",
        "*   Try changing the query value to `\"D12-02\"` (or another exact name found in the previous step) to see the difference.\n",
        "\n",
        "**API Endpoint:** `POST /query`\n",
        "**Permissions:** `service.search.user` + ACL `VIEWER` access to result records."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujhuJXJmuoXc",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Define the EXACT value to search for (try changing this after the first run)\n",
        "exact_facility_name = \"D12\"\n",
        "# exact_facility_name = \"D12-02\" # Example to try on second run\n",
        "\n",
        "# Define the payload for keyword search (exact match)\n",
        "keyword_query_payload = {\n",
        "    \"kind\": \"osdu:wks:*:*\",\n",
        "    # Lucene query: Search for the exact term using the .keyword field.\n",
        "    # Note the triple backslashes needed: one pair for JSON string escaping of quotes,\n",
        "    # and one for Lucene's requirement to escape the inner quotes of the exact phrase.\n",
        "    \"query\": f\"data.FacilityName.keyword:\\\"{exact_facility_name}\\\"\",\n",
        "    \"limit\": 10,\n",
        "    \"returnedFields\": [\"id\", \"kind\", \"data.FacilityName\"]\n",
        "}\n",
        "\n",
        "print(f\"Attempting keyword (exact match) search for FacilityName '{exact_facility_name}' with payload:\")\n",
        "print(json.dumps(keyword_query_payload, indent=2))\n",
        "\n",
        "try:\n",
        "    keyword_response = requests.post(\n",
        "        f\"{search_endpoint}/query\",\n",
        "        headers=headers,\n",
        "        data=json.dumps(keyword_query_payload)\n",
        "    )\n",
        "    keyword_response.raise_for_status()\n",
        "\n",
        "    print(f\"\\nKeyword search successful (Status Code: {keyword_response.status_code}).\")\n",
        "    results_data = keyword_response.json()\n",
        "    print(f\"Total results matching query (if available): {results_data.get('totalCount', 'N/A')}\")\n",
        "    print(f\"Number of results returned: {len(results_data.get('results', []))}\")\n",
        "    if not results_data.get('results'):\n",
        "        print(f\"---> No records found with EXACT FacilityName '{exact_facility_name}'. This is expected.\")\n",
        "    print(\"Query Results:\")\n",
        "    print(json.dumps(results_data, indent=2))\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"\\nError during keyword search: {e}\")\n",
        "    if e.response is not None:\n",
        "        # A 400 Bad Request might occur if the .keyword field doesn't exist or the query syntax is wrong\n",
        "        print(f\"Response Body: {e.response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szw3jtHKuoXc"
      },
      "source": [
        "### 4. Advanced Search Features (Spatial)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OkawAJguoXc"
      },
      "source": [
        "#### 4.1 Spatial Search (By Distance)\n",
        "Search for Wellbores within a specified distance (radius) of a central geographic point. This uses the `byDistance` spatial filter.\n",
        "\n",
        "**API Endpoint:** `POST /query`\n",
        "**Permissions:** `service.search.user` + ACL `VIEWER` access to result records."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6k9UHU5nuoXc",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Define the spatial query payload (By Distance)\n",
        "spatial_distance_payload = {\n",
        "    \"kind\": \"osdu:wks:master-data--Wellbore:1.0.0\",\n",
        "    \"limit\": 10,\n",
        "    \"query\": \"*\", # Can be combined with other query criteria\n",
        "    \"spatialFilter\": {\n",
        "        \"field\": \"data.SpatialLocation.Wgs84Coordinates\", # The geo-point field in the schema to query against\n",
        "        \"byDistance\": {\n",
        "            \"point\": {\n",
        "                \"latitude\": 52.780083,\n",
        "                \"longitude\": 5.244389\n",
        "            },\n",
        "            \"distance\": 8000 # Distance in meters\n",
        "        }\n",
        "    },\n",
        "    \"returnedFields\": [\"id\", \"kind\", \"data.FacilityName\", \"data.SpatialLocation.Wgs84Coordinates\"]\n",
        "}\n",
        "\n",
        "print(f\"Attempting spatial search (By Distance) with payload:\")\n",
        "print(json.dumps(spatial_distance_payload, indent=2))\n",
        "\n",
        "try:\n",
        "    spatial_dist_response = requests.post(\n",
        "        f\"{search_endpoint}/query\",\n",
        "        headers=headers,\n",
        "        json=spatial_distance_payload # Use json= for automatic content-type\n",
        "    )\n",
        "    spatial_dist_response.raise_for_status()\n",
        "\n",
        "    print(f\"\\nSpatial (By Distance) search successful (Status Code: {spatial_dist_response.status_code}).\")\n",
        "    results_data = spatial_dist_response.json()\n",
        "    print(f\"Total results matching query (if available): {results_data.get('totalCount', 'N/A')}\")\n",
        "    print(f\"Number of results returned: {len(results_data.get('results', []))}\")\n",
        "    print(\"Query Results:\")\n",
        "    print(json.dumps(results_data, indent=2))\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"\\nError during spatial (By Distance) search: {e}\")\n",
        "    if e.response is not None:\n",
        "        print(f\"Response Body: {e.response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXEkp72nuoXc"
      },
      "source": [
        "#### 4.2 Spatial Search (By Bounding Box)\n",
        "\n",
        "Search for records within a rectangular area defined by top-left and bottom-right geographic coordinates using the `byBoundingBox` filter.\n",
        "\n",
        "**API Endpoint:** `POST /query`\n",
        "**Permissions:** `service.search.user` + ACL `VIEWER` access to result records."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZ1hCPeouoXc",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Define the spatial query payload (By Bounding Box)\n",
        "spatial_bbox_payload = {\n",
        "    \"kind\": \"osdu:wks:master-data--Wellbore:1.0.0\",\n",
        "    \"limit\": 30,\n",
        "    \"query\": \"*\",\n",
        "    \"spatialFilter\": {\n",
        "        \"field\": \"data.SpatialLocation.Wgs84Coordinates\",\n",
        "        \"byBoundingBox\": {\n",
        "            # Note: Ensure latitude/longitude order and range are correct for your CRS (usually WGS84)\n",
        "            \"topLeft\": {\"latitude\": 52.326016, \"longitude\": 6.780958},\n",
        "            \"bottomRight\": {\"latitude\": 51.863627, \"longitude\": 8.391779},\n",
        "        }\n",
        "    },\n",
        "    \"returnedFields\": [\"id\", \"kind\", \"data.FacilityName\", \"data.SpatialLocation.Wgs84Coordinates\"]\n",
        "}\n",
        "\n",
        "print(f\"Attempting spatial search (By Bounding Box) with payload:\")\n",
        "print(json.dumps(spatial_bbox_payload, indent=2))\n",
        "\n",
        "try:\n",
        "    spatial_bbox_response = requests.post(\n",
        "        f\"{search_endpoint}/query\",\n",
        "        headers=headers,\n",
        "        json=spatial_bbox_payload\n",
        "    )\n",
        "    spatial_bbox_response.raise_for_status()\n",
        "\n",
        "    print(f\"\\nSpatial (Bounding Box) search successful (Status Code: {spatial_bbox_response.status_code}).\")\n",
        "    results_data = spatial_bbox_response.json()\n",
        "    print(f\"Total results matching query (if available): {results_data.get('totalCount', 'N/A')}\")\n",
        "    print(f\"Number of results returned: {len(results_data.get('results', []))}\")\n",
        "    print(\"Query Results:\")\n",
        "    print(json.dumps(results_data, indent=2))\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"\\nError during spatial (Bounding Box) search: {e}\")\n",
        "    if e.response is not None:\n",
        "        print(f\"Response Body: {e.response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akRRoa3uuoXc"
      },
      "source": [
        "#### 4.3 Spatial Search (By GeoPolygon)\n",
        "\n",
        "Search for records within an arbitrary polygon defined by a list of vertex coordinates using the `byGeoPolygon` filter. The first and last points in the list must be the same to close the polygon.\n",
        "\n",
        "**API Endpoint:** `POST /query`\n",
        "**Permissions:** `service.search.user` + ACL `VIEWER` access to result records."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8Pnr1EJuoXc",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Define the spatial query payload (By GeoPolygon)\n",
        "spatial_polygon_payload = {\n",
        "  \"kind\": \"osdu:wks:master-data--Wellbore:1.0.0\",\n",
        "  \"limit\": 30,\n",
        "  \"query\": \"*\",\n",
        "  \"spatialFilter\": {\n",
        "    \"field\": \"data.SpatialLocation.Wgs84Coordinates\",\n",
        "    \"byGeoPolygon\": {\n",
        "      \"points\": [ # List of vertices defining the polygon\n",
        "        {\"latitude\": 52.326016, \"longitude\": 6.780958},\n",
        "        {\"latitude\": 51.863627, \"longitude\": 8.391779},\n",
        "        {\"latitude\": 53.123515, \"longitude\": 7.504645},\n",
        "        {\"latitude\": 52.326016, \"longitude\": 6.780958} # Close the polygon\n",
        "      ]\n",
        "    }\n",
        "  },\n",
        "  \"returnedFields\": [\"id\", \"kind\", \"data.FacilityName\", \"data.SpatialLocation.Wgs84Coordinates\"]\n",
        "}\n",
        "\n",
        "print(f\"Attempting spatial search (By GeoPolygon) with payload:\")\n",
        "print(json.dumps(spatial_polygon_payload, indent=2))\n",
        "\n",
        "try:\n",
        "    spatial_poly_response = requests.post(\n",
        "        f\"{search_endpoint}/query\",\n",
        "        headers=headers,\n",
        "        json=spatial_polygon_payload\n",
        "    )\n",
        "    spatial_poly_response.raise_for_status()\n",
        "\n",
        "    print(f\"\\nSpatial (GeoPolygon) search successful (Status Code: {spatial_poly_response.status_code}).\")\n",
        "    results_data = spatial_poly_response.json()\n",
        "    print(f\"Total results matching query (if available): {results_data.get('totalCount', 'N/A')}\")\n",
        "    print(f\"Number of results returned: {len(results_data.get('results', []))}\")\n",
        "    print(\"Query Results:\")\n",
        "    print(json.dumps(results_data, indent=2))\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"\\nError during spatial (GeoPolygon) search: {e}\")\n",
        "    if e.response is not None:\n",
        "        print(f\"Response Body: {e.response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQsWuKUPuoXc"
      },
      "source": [
        "### 5. Sorting and Field Selection\n",
        "\n",
        "Search for Well records, sort the results by their `id` (ascending), and return only the `id`, `kind`, and `data.FacilityName` fields.\n",
        "\n",
        "**API Endpoint:** `POST /query`\n",
        "**Permissions:** `service.search.user` + ACL `VIEWER` access to result records."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQIokUE3uoXc",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Define the query payload with sorting and field selection\n",
        "sorted_query_payload = {\n",
        "  \"kind\": \"osdu:wks:master-data--Well:1.0.0\",\n",
        "  \"query\": \"*\",\n",
        "  \"offset\": 0, # Start from the first result\n",
        "  \"limit\": 30,\n",
        "  \"sort\": {\n",
        "    \"field\": [\"id\"], # Field(s) to sort by (use 'id.keyword' or 'data.FacilityName.keyword' for exact string sorting if available)\n",
        "    \"order\": [\"ASC\"] # Sort order: ASC or DESC\n",
        "  },\n",
        "  \"returnedFields\": [ \"id\", \"kind\", \"data.FacilityName\" ] # Specify fields to return\n",
        "}\n",
        "\n",
        "print(f\"Attempting sorted search with payload:\")\n",
        "print(json.dumps(sorted_query_payload, indent=2))\n",
        "\n",
        "try:\n",
        "    sorted_response = requests.post(\n",
        "        f\"{search_endpoint}/query\",\n",
        "        headers=headers,\n",
        "        json=sorted_query_payload\n",
        "    )\n",
        "    sorted_response.raise_for_status()\n",
        "\n",
        "    print(f\"\\nSorted Query successful (Status Code: {sorted_response.status_code}).\")\n",
        "    results_data = sorted_response.json()\n",
        "    print(f\"Total results matching query (if available): {results_data.get('totalCount', 'N/A')}\")\n",
        "    print(f\"Number of results returned: {len(results_data.get('results', []))}\")\n",
        "    print(\"Query Results (Sorted by ID):\")\n",
        "    print(json.dumps(results_data, indent=2))\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"\\nError during sorted query: {e}\")\n",
        "    if e.response is not None:\n",
        "        # 400 Bad Request might occur if sort field doesn't exist or isn't sortable\n",
        "        print(f\"Response Body: {e.response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPNKkVLmuoXc"
      },
      "source": [
        "### 6. Aggregated Search\n",
        "\n",
        "Perform a search that aggregates results based on a specified field. This example counts the number of records for each `kind` present in the data partition.\n",
        "\n",
        "**API Endpoint:** `POST /query`\n",
        "**Permissions:** `service.search.user` (ACLs not directly relevant for aggregations, only for the base query matching)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4l0_dhv3uoXc",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Define the aggregation query payload\n",
        "aggregate_query_payload = {\n",
        "    \"kind\": \"*:*:*:*\", # Aggregate across all kinds in the partition\n",
        "    \"limit\": 0, # We don't need individual results, only the aggregation\n",
        "    \"query\": \"*\", # Match all documents\n",
        "    \"aggregateBy\": \"kind\" # Field to aggregate on\n",
        "}\n",
        "\n",
        "print(f\"Attempting aggregation search by 'kind' with payload:\")\n",
        "print(json.dumps(aggregate_query_payload, indent=2))\n",
        "\n",
        "try:\n",
        "    aggregate_response = requests.post(\n",
        "        f\"{search_endpoint}/query\",\n",
        "        json=aggregate_query_payload,\n",
        "        headers=headers\n",
        "    )\n",
        "    # Use the helper function to process and print the result\n",
        "    print(f\"\\nAggregation search status code: {aggregate_response.status_code}\")\n",
        "    print(\"Aggregation Results (Count per Kind):\")\n",
        "    print_agg_list_result(aggregate_response)\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    # Error handling specifically for the request sending part\n",
        "    print(f\"\\nError during aggregation query request: {e}\")\n",
        "    if e.response is not None:\n",
        "        print(f\"Response Body: {e.response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9_QJJ6uuoXd"
      },
      "source": [
        "### 7. Challenge\n",
        "\n",
        "**Tasks:**\n",
        "1.  **Count Wellbores:** How many `master-data--Wellbore` records (any version) exist in the data partition?\n",
        "2.  **Find Deepest Trajectory:** Find the `work-product-component--WellboreTrajectory` record with the largest measured depth (`data.BaseDepthMeasuredDepth`). Return the `id` of this trajectory record, its `data.WellboreID` (the parent wellbore it belongs to), and its `data.BaseDepthMeasuredDepth` value.\n",
        "\n",
        "**Hints:**\n",
        "*   For counting, use `limit: 0` and `trackTotalCount: true` or `aggregateBy` if appropriate.\n",
        "*   For finding the deepest, use the `sort` parameter on the `data.BaseDepthMeasuredDepth` field in descending order (`DESC`) and set `limit: 1`.\n",
        "*   Target the correct `kind` for each task (`osdu:wks:master-data--Wellbore:*` for counting, `osdu:wks:work-product-component--WellboreTrajectory:*` for deepest).\n",
        "*   Ensure you request the necessary fields using `returnedFields`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUrUm2sUuoXd",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Code block to run the challenge\n",
        "print(\"--- Starting Search Service Challenge ---\")\n",
        "\n",
        "# Use standard 'headers' and 'search_endpoint'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00KmkKrGuoXd"
      },
      "source": [
        "#### 💡 Solution Code Cells"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OecUlEZYuoXd"
      },
      "source": [
        "##### 1. Count Wellbores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NHCYjpfuoXd"
      },
      "outputs": [],
      "source": [
        "print(\"\\nChallenge Part 1: Counting Wellbores...\")\n",
        "\n",
        "count_wellbores_payload = {\n",
        "  \"kind\": \"osdu:wks:master-data--Wellbore:*\", # Target Wellbore kind\n",
        "  \"query\": \"*\",\n",
        "  \"limit\": 0,           # We only need the count, not the results themselves\n",
        "  \"trackTotalCount\": True # Explicitly request the total count\n",
        "}\n",
        "\n",
        "print(f\"   Request Body: {json.dumps(count_wellbores_payload, indent=2)}\")\n",
        "\n",
        "try:\n",
        "    count_response = requests.post(\n",
        "        f\"{search_endpoint}/query\",\n",
        "        headers=headers,\n",
        "        json=count_wellbores_payload\n",
        "    )\n",
        "    count_response.raise_for_status()\n",
        "    count_data = count_response.json()\n",
        "\n",
        "    print(f\"   Count request successful ({count_response.status_code}).\")\n",
        "    total_wellbores = count_data.get('totalCount', 'Not Available')\n",
        "    print(f\"   >>> Total number of Wellbore records found: {total_wellbores}\")\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"   Error counting wellbores: {e}\")\n",
        "    if e.response is not None:\n",
        "        print(f\"   Response Body: {e.response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBTC14lguoXd"
      },
      "source": [
        "##### 2. Find Deepest Trajectory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qQL6hUcuoXd"
      },
      "outputs": [],
      "source": [
        "print(\"\\nChallenge Part 2: Finding the deepest WellboreTrajectory...\")\n",
        "\n",
        "deepest_trajectory_payload = {\n",
        "  \"kind\": \"osdu:wks:work-product-component--WellboreTrajectory:*\", # Target Trajectory kind\n",
        "  \"query\": \"*\", # Consider adding 'data.BaseDepthMeasuredDepth:[0 TO *]' if 0 or negative depths are invalid\n",
        "  \"limit\": 1,   # We only need the top result\n",
        "  \"sort\": {\n",
        "    \"field\": [\"data.BaseDepthMeasuredDepth\"], # Field to sort by\n",
        "    \"order\": [\"DESC\"] # Descending order to get the largest value first\n",
        "  },\n",
        "  \"returnedFields\": [ \"id\", \"data.WellboreID\", \"data.BaseDepthMeasuredDepth\" ] # Fields needed\n",
        "}\n",
        "\n",
        "print(f\"   Request Body: {json.dumps(deepest_trajectory_payload, indent=2)}\")\n",
        "\n",
        "try:\n",
        "    deepest_response = requests.post(\n",
        "        f\"{search_endpoint}/query\",\n",
        "        headers=headers,\n",
        "        json=deepest_trajectory_payload\n",
        "    )\n",
        "    deepest_response.raise_for_status()\n",
        "    deepest_data = deepest_response.json()\n",
        "\n",
        "    print(f\"   Deepest trajectory search successful ({deepest_response.status_code}).\")\n",
        "\n",
        "    if 'results' in deepest_data and deepest_data['results']:\n",
        "        deepest_record = deepest_data['results'][0]\n",
        "        print(\"   >>> Deepest WellboreTrajectory Found:\")\n",
        "        print(f\"       Record ID: {deepest_record.get('id')}\")\n",
        "        print(f\"       Parent Wellbore ID: {deepest_record.get('data', {}).get('WellboreID')}\")\n",
        "        print(f\"       Base Measured Depth: {deepest_record.get('data', {}).get('BaseDepthMeasuredDepth')}\")\n",
        "        # Optionally print the whole record:\n",
        "        # print(json.dumps(deepest_record, indent=4))\n",
        "    else:\n",
        "        print(\"   >>> No WellboreTrajectory records found matching the criteria.\")\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"   Error finding deepest trajectory: {e}\")\n",
        "    if e.response is not None:\n",
        "        # 400 might occur if sort field is not sortable\n",
        "        print(f\"   Response Body: {e.response.text}\")\n",
        "\n",
        "print(\"--- Search Service Challenge Complete ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMDK4oAiuoXd"
      },
      "source": [
        "## OSDU Storage & Dataset Service Lab\n",
        "\n",
        "This lab exercise guides you through interacting with the OSDU Storage and Dataset services. You will:\n",
        "1.  Obtain instructions (like a signed URL) for uploading a file.\n",
        "2.  Upload a file (an image) to the location specified by the instructions.\n",
        "3.  Register the uploaded file as a Dataset record in OSDU, linking it to the file's location and adding metadata (like legal tags and ACLs).\n",
        "4.  Manage versions of the Dataset record.\n",
        "5.  Retrieve download instructions for the file.\n",
        "6.  Download and display the file.\n",
        "7.  Perform soft delete and purge operations on the record.\n",
        "\n",
        "**Key Concepts:**\n",
        "*   **Storage Service:** Manages metadata records (like wells, logs, documents). Handles record creation, versioning, retrieval, deletion.\n",
        "*   **Dataset Service:** Facilitates interaction with bulk data associated with OSDU records (e.g., files, datasets). Provides mechanisms to get upload/download instructions (URLs) for cloud storage.\n",
        "*   **Signed URL:** A temporary, secure URL granting time-limited access to a specific cloud storage object (e.g., for upload or download).\n",
        "*   **FileSource / Dataset Registry:** Information within an OSDU record pointing to the actual location of the associated file/data in cloud storage.\n",
        "\n",
        "**Permissions Note:** Operations typically require combinations of `service.storage.*` and `service.dataset.*` roles (creator, editor, viewer, admin), plus `service.legal.viewer` for associating legal tags.\n",
        "\n",
        "**Documentation:**\n",
        "*   [Storage API](https://osdu.pages.opengroup.org/platform/system/storage/)\n",
        "*   [Dataset API](https://osdu.pages.opengroup.org/platform/system/dataset/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ez4RAvFruoXd"
      },
      "source": [
        "### Setup: Storage & Dataset Lab\n",
        "\n",
        "This cell sets up necessary variables and performs prerequisite actions (like creating a legal tag) for the Storage & Dataset lab.\n",
        "\n",
        "**Dependencies:**\n",
        "*   Requires `requests`, `json`, `os`, `IPython.display.Image`.\n",
        "*   Relies on variables from initial authentication: `osdu_endpoint`, `headers`, `user_id`, `osdu_data_partition_id`, `entitlements_domain`, `legal_endpoint`.\n",
        "*   Requires the `./assets/osdu.png` file to exist relative to the notebook's location."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4ysbFHuuoXd",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os # Needed for path manipulation\n",
        "import requests\n",
        "import json\n",
        "# updated colab\n",
        "# from IPython.display import Image # To display the image later\n",
        "from PIL import Image\n",
        "\n",
        "# Define API Endpoints\n",
        "dataset_endpoint = f\"{osdu_endpoint}/api/dataset/v1\"\n",
        "storage_endpoint = f\"{osdu_endpoint}/api/storage/v2\"\n",
        "file_endpoint = f\"{osdu_endpoint}/api/file/v2\"\n",
        "# legal_endpoint is assumed to be defined from the Legal Lab setup\n",
        "if 'legal_endpoint' not in locals():\n",
        "    legal_endpoint = f\"{osdu_endpoint}/api/legal/v1\"\n",
        "print(f\"Using Dataset API Endpoint: {dataset_endpoint}\")\n",
        "print(f\"Using Storage API Endpoint: {storage_endpoint}\")\n",
        "\n",
        "# updated / commented for Colab\n",
        "# Define the file to be uploaded\n",
        "# file_path = \"./assets/osdu.png\" # Relative path to assets directory\n",
        "# file_name = os.path.basename(file_path) # Extract the file name from the path\n",
        "# print(f\"Using file path: {file_path}\")\n",
        "# if not os.path.exists(file_path):\n",
        "#      print(f\"\\n*** WARNING: File '{file_path}' not found. Please ensure it exists. ***\\n\")\n",
        "file_name = \"osdu.png\" # Extract the file name from the path\n",
        "\n",
        "# --- Action: Create a Legal Tag for this Lab ---\n",
        "# This tag is needed to associate with the record we create.\n",
        "lab_legal_tag_name = f'{osdu_data_partition_id}-storage-lab-tag-{user_id}'\n",
        "lab_legal_tag_description = f\"Storage/Dataset Lab tag for user {user_id}\"\n",
        "lab_legal_tag_payload = {\n",
        "    \"name\": lab_legal_tag_name,\n",
        "    \"description\": lab_legal_tag_description,\n",
        "    \"properties\": { # Ensure these match required fields and reference values\n",
        "        \"contractId\": f\"LabContract-{user_id}\",\n",
        "        \"countryOfOrigin\": [\"US\"],\n",
        "        \"expirationDate\": \"2099-12-31\",\n",
        "        \"originator\": f\"StorageLab-{user_id}\",\n",
        "        \"dataType\": \"Public Domain Data\",\n",
        "        \"securityClassification\": \"Public\",\n",
        "        \"personalData\": \"No Personal Data\",\n",
        "        \"exportClassification\": \"EAR99\"\n",
        "    }\n",
        "}\n",
        "tag_name_for_record = None # Initialize variable\n",
        "try:\n",
        "    print(f\"Attempting to create/ensure legal tag: {lab_legal_tag_name}\")\n",
        "    tag_create_response = requests.post(\n",
        "        f\"{legal_endpoint}/legaltags\",\n",
        "        headers=headers,\n",
        "        data=json.dumps(lab_legal_tag_payload)\n",
        "    )\n",
        "    if tag_create_response.status_code == 409:\n",
        "        print(f\"   Legal tag '{lab_legal_tag_name}' already exists (409). Using existing tag.\")\n",
        "        tag_name_for_record = lab_legal_tag_name\n",
        "    else:\n",
        "        tag_create_response.raise_for_status()\n",
        "        tag_name_for_record = tag_create_response.json().get(\"name\", lab_legal_tag_name)\n",
        "        print(f\"   Legal tag '{tag_name_for_record}' created successfully ({tag_create_response.status_code}).\")\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"   Error creating/ensuring legal tag: {e}\")\n",
        "    if e.response is not None:\n",
        "        print(f\"   Response Body: {e.response.text}\")\n",
        "    print(\"   *** WARNING: Failed to create/find legal tag. Record creation in Step 3 might fail. ***\")\n",
        "\n",
        "# Variables to store results from steps\n",
        "upload_signed_url = None\n",
        "upload_file_source = None\n",
        "created_record_id = None\n",
        "created_record_version = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyFVb3qguoXd"
      },
      "source": [
        "### 1. Get Upload Instructions (Signed URL)\n",
        "\n",
        "Request instructions from the Dataset service for uploading a file. This typically returns provider-specific information, including a temporary, secure URL (`signedUrl`) where the file can be uploaded and a `fileSource` identifier to be stored in the OSDU record.\n",
        "\n",
        "**API Endpoint:** `POST /storageInstructions`\n",
        "**Permissions:** `service.dataset.creator`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H05jCCByuoXd",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Define the kindSubtype for the file we intend to upload\n",
        "# This helps the service determine appropriate storage, but is often generic\n",
        "kind_subtype = \"dataset--File.Generic\" # Or more specific like \"dataset--File.Image\"\n",
        "expiry_time = \"2h\"  # How long the upload URL should be valid (e.g., 2 hours)\n",
        "\n",
        "print(f\"Requesting upload instructions for kindSubtype: {kind_subtype}\")\n",
        "\n",
        "try:\n",
        "    # Send POST request to get storage instructions\n",
        "    instructions_response = requests.post(\n",
        "        f\"{dataset_endpoint}/storageInstructions?kindSubType={kind_subtype}&expiryTime={expiry_time}\",\n",
        "        headers=headers\n",
        "        # No request body needed for this endpoint\n",
        "    )\n",
        "    instructions_response.raise_for_status() # Check for HTTP errors\n",
        "\n",
        "    instructions_data = instructions_response.json()\n",
        "    print(f\"Upload instructions received successfully (Status Code: {instructions_response.status_code}).\")\n",
        "    print(\"Instructions Response:\")\n",
        "    print(json.dumps(instructions_data, indent=2))\n",
        "\n",
        "    # Extract the signedUrl and fileSource from the response\n",
        "    # Structure might vary slightly by provider ('providerKey' vs 'fileSource')\n",
        "    storage_location = instructions_data.get(\"storageLocation\", {})\n",
        "    upload_signed_url = storage_location.get(\"signedUrl\")\n",
        "    upload_file_source = storage_location.get(\"fileSource\", storage_location.get(\"providerKey\")) # Adapt as needed\n",
        "\n",
        "    if upload_signed_url and upload_file_source:\n",
        "        print(f\"\\nExtracted Signed URL: {upload_signed_url[:100]}...\") # Print beginning of URL\n",
        "        print(f\"Extracted File Source/Provider Key: {upload_file_source}\")\n",
        "    else:\n",
        "        print(\"\\n*** WARNING: Could not extract 'signedUrl' or 'fileSource'/'providerKey' from the response. ***\")\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"\\nError getting upload instructions: {e}\")\n",
        "    if e.response is not None:\n",
        "        print(f\"Response Body: {e.response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LM6gFzpKuoXd"
      },
      "source": [
        "### 2. Upload File Data\n",
        "\n",
        "Upload the actual file content (`osdu.png`) to the `signedUrl` obtained in the previous step.\n",
        "\n",
        "**API Endpoint:** The `signedUrl` itself (external cloud provider endpoint)\n",
        "**Permissions:** Granted by the temporary token embedded in the `signedUrl`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gMUgjQmK8em"
      },
      "outputs": [],
      "source": [
        "# Check if we have the signed URL and the file exists\n",
        "#commented for Colab\n",
        "# if upload_signed_url and os.path.exists(file_path):\n",
        "#     print(f\"Attempting to upload file '{file_path}' to the signed URL...\")\n",
        "\n",
        "# Prepare headers for the PUT request to the cloud storage URL\n",
        "# Content-Type is important for how the file is stored and later retrieved\n",
        "upload_headers = {\n",
        "    \"Content-Type\": \"text/plain\", # Specific content type\n",
        "    \"x-ms-blob-type\": \"BlockBlob\",  # Adjust based on the file type\n",
        "    \"data-partition-id\": osdu_data_partition_id  # Get the file size\n",
        "}\n",
        "print(f\"   Upload Headers: {upload_headers}\")\n",
        "\n",
        "try:\n",
        "    # # Open the file in binary read mode ('rb')\n",
        "    # with open(file_path, \"rb\") as file_data:\n",
        "    #     # Send PUT request with file data as the body\n",
        "    #     upload_response = requests.put(\n",
        "    #         upload_signed_url,\n",
        "    #         headers=upload_headers,\n",
        "    #         data=file_data\n",
        "    #     )\n",
        "\n",
        "    # Colab version\n",
        "    file_data = get_bytes(\"osdu.png\")\n",
        "    # Send PUT request with file data as the body\n",
        "    upload_response = requests.put(\n",
        "        upload_signed_url,\n",
        "        headers=upload_headers,\n",
        "        data=file_data\n",
        "    )\n",
        "\n",
        "    # Check for success (usually 201 Created for Azure Blob, might be 200 OK for others)\n",
        "    if upload_response.status_code == 201 or upload_response.status_code == 200:\n",
        "        print(\"Upload Response:\")\n",
        "        print(\"The file is uploaded.\")\n",
        "    else:\n",
        "        # Raise an exception for other non-successful statuses\n",
        "        upload_response.raise_for_status()\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"\\nError uploading file: {e}\")\n",
        "    # The response body from the cloud provider might contain useful error details\n",
        "    if e.response is not None:\n",
        "        print(f\"Response Status Code: {e.response.status_code}\")\n",
        "        print(f\"Response Body: {e.response.text}\")\n",
        "\n",
        "#commented for Colab\n",
        "# elif not upload_signed_url:\n",
        "#     print(\"Skipping file upload because 'upload_signed_url' was not obtained in Step 1.\")\n",
        "# else:\n",
        "#      print(f\"Skipping file upload because file '{file_path}' does not exist.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSq6lSsHuoXd"
      },
      "source": [
        "### 3. Create Dataset Record\n",
        "\n",
        "Register the uploaded file in OSDU by creating a `dataset` record. This record includes:\n",
        "*   A unique OSDU ID.\n",
        "*   The `kind` specifying the type of dataset.\n",
        "*   ACLs defining access permissions.\n",
        "*   Legal tags for compliance.\n",
        "*   Crucially, the `DatasetProperties.FileSourceInfo` section containing the `FileSource` (or `providerKey`) obtained in Step 1, linking this OSDU record to the actual file in cloud storage.\n",
        "\n",
        "**API Endpoint:** `PUT /registerDataset`\n",
        "**Permissions:** `service.dataset.creator`, `service.storage.creator`, `service.legal.viewer`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aI0VaiX6uoXd",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Check if prerequisite steps were successful\n",
        "if upload_file_source and tag_name_for_record:\n",
        "    # Define the record ID (must be unique)\n",
        "    record_id = f\"{osdu_data_partition_id}:dataset--File.Generic:{user_id}\"\n",
        "    print(f\"Attempting to register dataset with ID: {record_id}\")\n",
        "\n",
        "    # Define the payload for the dataset record\n",
        "    # Note: The endpoint expects a list of records\n",
        "    record_registration_payload = {\n",
        "      \"datasetRegistries\": [\n",
        "        {\n",
        "            \"id\": record_id,\n",
        "            \"kind\": \"osdu:wks:dataset--File.Generic:1.0.0\", # Match the schema kind\n",
        "            \"acl\": {\n",
        "                \"owners\": [f\"data.default.owners@{entitlements_domain}\"],\n",
        "                \"viewers\": [f\"data.default.viewers@{entitlements_domain}\"],\n",
        "            },\n",
        "            \"legal\": {\n",
        "                \"legaltags\": [tag_name_for_record], # Use the tag created in setup\n",
        "                \"otherRelevantDataCountries\": [\"US\"], # Example\n",
        "            },\n",
        "            \"data\": {\n",
        "                \"Name\": file_name, # Original file name\n",
        "                \"Description\": f\"OSDU PNG Image uploaded by user {user_id}\",\n",
        "                \"DatasetProperties\": {\n",
        "                    \"FileSourceInfo\": {\n",
        "                        \"FileSource\": upload_file_source, # The crucial link from Step 1\n",
        "                        \"Name\": file_name # Can be repeated here\n",
        "                        # \"PreloadFilePath\": \"...\" # Optional, may be needed by some DDMS\n",
        "                    }\n",
        "                },\n",
        "                \"SchemaFormatTypeID\": f\"{osdu_data_partition_id}:reference-data--SchemaFormatType:Image.PNG:\" # Optional: Ref data link for file format\n",
        "            }\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "\n",
        "    print(f\"   Registration Payload: {json.dumps(record_registration_payload, indent=2)}\")\n",
        "\n",
        "    try:\n",
        "        # Send PUT request to register the dataset\n",
        "        register_response = requests.put(\n",
        "            f\"{dataset_endpoint}/registerDataset\",\n",
        "            headers=headers,\n",
        "            json=record_registration_payload # Use json= for automatic content-type\n",
        "        )\n",
        "        register_response.raise_for_status() # Check for HTTP errors\n",
        "\n",
        "        print(f\"Dataset registration successful (Status Code: {register_response.status_code}).\")\n",
        "        record_response_data = register_response.json()\n",
        "        print(\"Registration Response:\")\n",
        "        print(json.dumps(record_response_data, indent=2))\n",
        "\n",
        "        # Extract the created record ID and version (important for later steps)\n",
        "        if record_response_data.get(\"datasetRegistries\"):\n",
        "             created_record_id = record_response_data[\"datasetRegistries\"][0][\"id\"]\n",
        "             print(f\"   Stored created_record_id: {created_record_id}\")\n",
        "        else:\n",
        "             # Fallback if recordIds isn't present but request succeeded\n",
        "             created_record_id = record_id\n",
        "             print(f\"   Could not find 'recordIds' in response, using provided ID: {created_record_id}\")\n",
        "\n",
        "        if record_response_data.get(\"datasetRegistries\"):\n",
        "             created_record_version = record_response_data[\"datasetRegistries\"][0][\"version\"]\n",
        "             print(f\"   Stored created_record_version: {created_record_version}\")\n",
        "        else:\n",
        "             print(\"   Could not find 'version' in response.\")\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"\\nError registering dataset record: {e}\")\n",
        "        if e.response is not None:\n",
        "            print(f\"Response Body: {e.response.text}\")\n",
        "else:\n",
        "    print(\"Skipping dataset registration because 'upload_file_source' or 'tag_name_for_record' was not set in previous steps.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZS1K7tQuoXd"
      },
      "source": [
        "### 4. Get All Record Versions\n",
        "\n",
        "List all available versions for the dataset record created in the previous step.\n",
        "\n",
        "**API Endpoint:** `GET /records/versions/{recordId}`\n",
        "**Permissions:** `service.storage.viewer`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9hBHohZuoXe",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Ensure created_record_id is set\n",
        "if created_record_id:\n",
        "    print(f\"Attempting to get all versions for record: {created_record_id}\")\n",
        "    try:\n",
        "        # Send GET request to the record versions endpoint\n",
        "        versions_response = requests.get(\n",
        "             f\"{storage_endpoint}/records/versions/{created_record_id}\",\n",
        "             headers=headers\n",
        "        )\n",
        "        versions_response.raise_for_status() # Check for HTTP errors (e.g., 404 if record not found)\n",
        "\n",
        "        print(f\"Get versions successful (Status Code: {versions_response.status_code}).\")\n",
        "        versions_data = versions_response.json()\n",
        "        print(\"Available Versions:\")\n",
        "        print(json.dumps(versions_data, indent=2))\n",
        "\n",
        "        # Optionally, store the latest version number if needed elsewhere\n",
        "        # latest_version = versions_data.get(\"versions\", [None])[-1]\n",
        "        # print(f\"Latest version number: {latest_version}\")\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"\\nError getting record versions: {e}\")\n",
        "        if e.response is not None:\n",
        "            print(f\"Response Body: {e.response.text}\")\n",
        "else:\n",
        "    print(\"Skipping get versions because 'created_record_id' was not set in Step 3.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqf3hUc3uoXe"
      },
      "source": [
        "### 5. Get Specific Record Version\n",
        "\n",
        "Retrieve the specific version of the record that was created in Step 3, using the `created_record_version` variable captured then.\n",
        "\n",
        "**API Endpoint:** `GET /records/{recordId}/{version}`\n",
        "**Permissions:** `service.storage.viewer`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2w0fWj3vuoXe",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Ensure we have both the record ID and the specific version number\n",
        "if created_record_id and created_record_version:\n",
        "    print(f\"Attempting to get specific version {created_record_version} for record: {created_record_id}\")\n",
        "    try:\n",
        "        # Send GET request for the specific record version\n",
        "        specific_version_response = requests.get(\n",
        "            f\"{storage_endpoint}/records/{created_record_id}/{created_record_version}\",\n",
        "            headers=headers\n",
        "        )\n",
        "        specific_version_response.raise_for_status() # Check for errors\n",
        "\n",
        "        print(f\"Get specific version successful (Status Code: {specific_version_response.status_code}).\")\n",
        "        print(\"Record Version Data:\")\n",
        "        print(json.dumps(specific_version_response.json(), indent=2))\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"\\nError getting specific record version: {e}\")\n",
        "        if e.response is not None:\n",
        "            print(f\"Response Body: {e.response.text}\")\n",
        "elif not created_record_id:\n",
        "    print(\"Skipping get specific version because 'created_record_id' was not set in Step 3.\")\n",
        "else:\n",
        "     print(\"Skipping get specific version because 'created_record_version' was not captured in Step 3.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xr4qgm71uoXe"
      },
      "source": [
        "### 6. Get Latest Record Version\n",
        "\n",
        "Retrieve the *latest* version of the record. This is done by omitting the version number from the URL. The Storage service returns the version with the highest version number.\n",
        "\n",
        "**API Endpoint:** `GET /records/{recordId}`\n",
        "**Permissions:** `service.storage.viewer`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpjWwNmCuoXe",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Ensure created_record_id is set\n",
        "if created_record_id:\n",
        "    print(f\"Attempting to get the LATEST version for record: {created_record_id}\")\n",
        "    try:\n",
        "        # Send GET request without a version number\n",
        "        latest_version_response = requests.get(\n",
        "            f\"{storage_endpoint}/records/{created_record_id}\",\n",
        "            headers=headers\n",
        "        )\n",
        "        latest_version_response.raise_for_status() # Check for errors\n",
        "\n",
        "        print(f\"Get latest version successful (Status Code: {latest_version_response.status_code}).\")\n",
        "        print(\"Latest Record Version Data:\")\n",
        "        latest_data = latest_version_response.json()\n",
        "        print(json.dumps(latest_data, indent=2))\n",
        "        # You can compare latest_data['version'] with created_record_version\n",
        "        # print(f\"Latest version found: {latest_data.get('version')}\")\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"\\nError getting latest record version: {e}\")\n",
        "        if e.response is not None:\n",
        "            print(f\"Response Body: {e.response.text}\")\n",
        "else:\n",
        "    print(\"Skipping get latest version because 'created_record_id' was not set in Step 3.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlaqroIbuoXe"
      },
      "source": [
        "### 7. Get Download Instructions & Display Image\n",
        "\n",
        "Request download instructions (another signed URL) for the dataset record, then use that URL to fetch the image data and display it.\n",
        "\n",
        "**API Endpoint:** `GET /retrievalInstructions`\n",
        "**Permissions:** `service.dataset.viewer`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "katYxa9UZCiQ",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from io import BytesIO\n",
        "from IPython.display import display\n",
        "\n",
        "# Ensure created_record_id is set\n",
        "if created_record_id:\n",
        "    print(f\"Requesting download instructions for record: {created_record_id}\")\n",
        "    download_signed_url = None # Initialize variable\n",
        "    try:\n",
        "        # Send GET request for retrieval instructions\n",
        "        download_instructions_response = requests.get(\n",
        "            f\"{dataset_endpoint}/retrievalInstructions?id={created_record_id}&expiryTime={expiry_time}\", # Pass record ID as query parameter\n",
        "            headers=headers\n",
        "        )\n",
        "        download_instructions_response.raise_for_status()\n",
        "\n",
        "        download_instructions_data = download_instructions_response.json()\n",
        "        print(f\"Download instructions received successfully (Status Code: {download_instructions_response.status_code}).\")\n",
        "        print(\"Instructions Response:\")\n",
        "        print(json.dumps(download_instructions_data, indent=2))\n",
        "\n",
        "        # Extract the signed URL (structure can be nested)\n",
        "        datasets_list = download_instructions_data.get(\"datasets\", [])\n",
        "        if datasets_list and isinstance(datasets_list, list):\n",
        "            # Assuming we want the URL for the first (and likely only) dataset in the list\n",
        "            first_dataset = datasets_list[0]\n",
        "            retrieval_properties = first_dataset.get(\"retrievalProperties\", {})\n",
        "            download_signed_url = retrieval_properties.get(\"signedUrl\")\n",
        "\n",
        "        if download_signed_url:\n",
        "            print(f\"\\nExtracted Download Signed URL: {download_signed_url[:100]}...\")\n",
        "\n",
        "            # --- Download and Display Image ---\n",
        "            print(f\"\\nAttempting to download image from signed URL...\")\n",
        "            try:\n",
        "                # Send GET request to the download URL itself\n",
        "                image_download_response = requests.get(download_signed_url)\n",
        "                image_download_response.raise_for_status()\n",
        "                print(f\"   Image download successful (Status Code: {image_download_response.status_code}).\")\n",
        "\n",
        "                # Display the image directly using IPython.display.Image\n",
        "                # This fetches the image data using the URL provided\n",
        "                print(\"   Displaying image:\")\n",
        "\n",
        "                # updated colab\n",
        "                #display(Image(url=download_signed_url))\n",
        "                response = requests.get(download_signed_url)\n",
        "                # print(response.content)\n",
        "\n",
        "                display(Image.open(BytesIO(response.content)))\n",
        "\n",
        "            except requests.exceptions.RequestException as img_e:\n",
        "                print(f\"   Error downloading image from signed URL: {img_e}\")\n",
        "                if img_e.response is not None:\n",
        "                    print(f\"   Response Status Code: {img_e.response.status_code}\")\n",
        "                    # Avoid printing large binary content for image errors\n",
        "                    print(f\"   Response Headers: {img_e.response.headers}\")\n",
        "            except Exception as display_e:\n",
        "                 print(f\"   Error displaying image: {display_e}\")\n",
        "        else:\n",
        "            print(\"\\n*** WARNING: Could not extract download 'signedUrl' from the retrieval instructions. ***\")\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"\\nError getting download instructions: {e}\")\n",
        "        if e.response is not None:\n",
        "            print(f\"Response Body: {e.response.text}\")\n",
        "else:\n",
        "    print(\"Skipping download because 'created_record_id' was not set in Step 3.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h52SOIkauoXe"
      },
      "source": [
        "### 8. Soft Delete Record\n",
        "\n",
        "Mark the record for deletion. The record still exists in the system and can potentially be recovered (e.g., by creating a new version), but it will typically be excluded from standard search results.\n",
        "\n",
        "**API Endpoint:** `DELETE /records/{recordId}`\n",
        "**Permissions:** `service.storage.editor`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUajMUdluoXe",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from io import BytesIO\n",
        "from IPython.display import display\n",
        "\n",
        "# Ensure created_record_id is set\n",
        "if created_record_id:\n",
        "    print(f\"Attempting to SOFT delete record: {created_record_id}\")\n",
        "    try:\n",
        "        # Send DELETE request to the record ID endpoint\n",
        "        soft_delete_response = requests.delete(\n",
        "            f\"{storage_endpoint}/records/{created_record_id}\",\n",
        "            headers=headers\n",
        "        )\n",
        "        soft_delete_response.raise_for_status() # Should return 204 No Content on success\n",
        "\n",
        "        print(f\"Record soft deleted successfully (Status Code: {soft_delete_response.status_code}).\")\n",
        "        # Response body is typically empty\n",
        "        if soft_delete_response.text:\n",
        "             print(f\"Response Body: {soft_delete_response.text}\")\n",
        "\n",
        "        # Optional: Verify soft delete by trying to get the latest version (should fail or return specific status)\n",
        "        # Some systems might return 404, others might return the record with a 'deleted' status marker.\n",
        "        print(\"\\n   Verifying soft delete by attempting to get latest record...\")\n",
        "        try:\n",
        "            verify_get = requests.get(f\"{storage_endpoint}/records/{created_record_id}\", headers=headers)\n",
        "            if verify_get.status_code == 404:\n",
        "                print(\"   Verification: Get request failed with 404 Not Found (expected after soft delete).\" )\n",
        "            else:\n",
        "                verify_get.raise_for_status()\n",
        "                print(f\"   Verification Warning: Get request returned {verify_get.status_code}. Record might still be accessible or marked differently.\")\n",
        "                print(f\"   Response: {json.dumps(verify_get.json(), indent=2)}\")\n",
        "        except requests.exceptions.RequestException as ve:\n",
        "             if ve.response is not None and ve.response.status_code == 404:\n",
        "                  print(\"   Verification: Get request failed with 404 Not Found (expected after soft delete).\" )\n",
        "             else:\n",
        "                  print(f\"   Verification Error: {ve}\")\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"\\nError soft deleting record: {e}\")\n",
        "        if e.response is not None:\n",
        "             # 404 here might mean it was already deleted\n",
        "            print(f\"Response Body: {e.response.text}\")\n",
        "else:\n",
        "    print(\"Skipping soft delete because 'created_record_id' was not set.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Txtwr73xuoXe"
      },
      "source": [
        "### 9. Create New Version (Undelete)\n",
        "\n",
        "Creating a new version of a soft-deleted record effectively undeletes it. We use the same `registerDataset` endpoint as in Step 3, providing the same record ID. This creates a new version entry and makes the record active again.\n",
        "\n",
        "**API Endpoint:** `PUT /registerDataset`\n",
        "**Permissions:** `service.dataset.creator`, `service.storage.creator`, `service.legal.viewer`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejUjZ-fPuoXe",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Check if we have the necessary information to re-create the record\n",
        "if created_record_id and upload_file_source and tag_name_for_record:\n",
        "    print(f\"Attempting to create a new version (undelete) for record: {created_record_id}\")\n",
        "\n",
        "    # Reuse or reconstruct the payload from Step 3\n",
        "    # (Could modify description, etc., to indicate it's a new version)\n",
        "    undelete_payload = {\n",
        "      \"datasetRegistries\": [\n",
        "        {\n",
        "            \"id\": created_record_id, # Use the SAME ID\n",
        "            \"kind\": \"osdu:wks:dataset--File.Generic:1.0.0\",\n",
        "            \"acl\": {\n",
        "                \"owners\": [f\"data.default.owners@{entitlements_domain}\"],\n",
        "                \"viewers\": [f\"data.default.viewers@{entitlements_domain}\"],\n",
        "            },\n",
        "            \"legal\": {\n",
        "                \"legaltags\": [tag_name_for_record],\n",
        "                \"otherRelevantDataCountries\": [\"US\"],\n",
        "            },\n",
        "            \"data\": {\n",
        "                \"Name\": file_name,\n",
        "                \"Description\": f\"OSDU PNG Image - Restored Version by user {user_id}\", # Updated description\n",
        "                \"DatasetProperties\": {\n",
        "                    \"FileSourceInfo\": {\n",
        "                        \"FileSource\": upload_file_source,\n",
        "                        \"Name\": file_name\n",
        "                    }\n",
        "                },\n",
        "                \"SchemaFormatTypeID\": f\"{osdu_data_partition_id}:reference-data--SchemaFormatType:Image.PNG:\",\n",
        "            }\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "\n",
        "    print(f\"   Update/Undelete Payload: {json.dumps(undelete_payload, indent=2)}\")\n",
        "\n",
        "    try:\n",
        "        # Send PUT request to registerDataset again with the same ID\n",
        "        undelete_response = requests.put(\n",
        "            f\"{dataset_endpoint}/registerDataset\",\n",
        "            headers=headers,\n",
        "            json=undelete_payload\n",
        "        )\n",
        "        undelete_response.raise_for_status()\n",
        "\n",
        "        print(f\"New version creation (undelete) successful (Status Code: {undelete_response.status_code}).\")\n",
        "        undelete_response_data = undelete_response.json()\n",
        "        print(\"Response:\")\n",
        "        print(json.dumps(undelete_response_data, indent=2))\n",
        "\n",
        "        # Capture the NEW version number\n",
        "        if undelete_response_data.get(\"recordVersions\"):\n",
        "             new_version = undelete_response_data[\"recordVersions\"][0]\n",
        "             print(f\"   New record version created: {new_version}\")\n",
        "             # Update the global variable if needed for subsequent steps\n",
        "             created_record_version = new_version\n",
        "        else:\n",
        "             print(\"   Could not find new version number in response.\")\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"\\nError creating new version (undeleting) record: {e}\")\n",
        "        if e.response is not None:\n",
        "            print(f\"Response Body: {e.response.text}\")\n",
        "else:\n",
        "    print(\"Skipping undelete because necessary information (record ID, file source, tag name) is missing.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aIEnMPVL5UZ"
      },
      "source": [
        "### 10. Purge Record\n",
        "\n",
        "Permanently delete the record and all its versions. This action is irreversible and typically requires administrative privileges. The associated physical file in cloud storage may or may not be deleted depending on the platform's configuration.\n",
        "\n",
        "**API Endpoint:** `POST /records:delete` (Note: V2 endpoint)\n",
        "**Permissions:** `service.storage.admin`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PU5a5AoMKqK"
      },
      "source": [
        "Links:\n",
        "- [Swagger](https://community.opengroup.org/osdu/platform/system/storage/-/blob/master/docs/api/storage_openapi.yaml?ref_type=heads)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DInifLMTMAvX"
      },
      "outputs": [],
      "source": [
        "# Ensure created_record_id is set\n",
        "if created_record_id:\n",
        "    print(f\"Attempting to PURGE record (irreversible): {created_record_id}\")\n",
        "\n",
        "    # Attempt to delete the dataset record using the registeredDataset endpoint.\n",
        "    if created_record_id:\n",
        "        print(f\"\\nAttempting to delete dataset using 'registeredDataset' API for record: {created_record_id}\")\n",
        "        try:\n",
        "            delete_url = f\"{file_endpoint}/files/{created_record_id}/metadata\"\n",
        "            # No additional payload is required for this request.\n",
        "            response = requests.delete(delete_url, headers=headers)\n",
        "            response.raise_for_status()\n",
        "            print(f\"Dataset delete successful (Status Code: {response.status_code}).\")\n",
        "            if response.text:\n",
        "                print(\"Response Body:\")\n",
        "                print(response.text)\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error during dataset delete: {e}\")\n",
        "            if e.response is not None:\n",
        "                print(f\"Response Body: {e.response.text}\")\n",
        "    else:\n",
        "        print(\"No dataset record ID found, skipping dataset soft delete.\")\n",
        "\n",
        "    # The V2 purge endpoint expects a POST request with the record ID(s) in the body\n",
        "    purge_payload = {\n",
        "        \"recordIds\": [created_record_id]\n",
        "    }\n",
        "    print(f\"   Purge Request Body: {json.dumps(purge_payload)}\")\n",
        "    print(\"   --- NOTE: This operation requires admin permissions and is permanent. ---\")\n",
        "\n",
        "    try:\n",
        "        # Send POST request to the :delete endpoint\n",
        "        purge_response = requests.post(\n",
        "            f\"{storage_endpoint}/records/delete\", # Note the :delete action endpoint\n",
        "            headers=headers,\n",
        "            json=[created_record_id]\n",
        "        )\n",
        "        purge_response.raise_for_status() # Check for HTTP errors (e.g., 403 Forbidden)\n",
        "\n",
        "        # Successful purge might return 200 OK or 204 No Content depending on implementation\n",
        "        print(f\"Record purge request successful (Status Code: {purge_response.status_code}).\")\n",
        "        # Response body might be empty or confirm deletion\n",
        "        if purge_response.text and purge_response.status_code != 204:\n",
        "             print(f\"Response Body: {json.dumps(purge_response.json(), indent=2)}\")\n",
        "        else:\n",
        "             print(\"Response Body: (empty or No Content)\")\n",
        "\n",
        "        # Clean up the variable as the record is gone\n",
        "        print(f\"\\nDeleting variable created_record_id ('{created_record_id}') from notebook memory.\")\n",
        "        del created_record_id\n",
        "        if 'created_record_version' in locals(): del created_record_version\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"\\nError purging record: {e}\")\n",
        "        if e.response is not None:\n",
        "            print(f\"Response Status Code: {e.response.status_code}\")\n",
        "            print(f\"Response Body: {e.response.text}\")\n",
        "            if e.response.status_code == 403:\n",
        "                 print(\"   Hint: Status code 403 (Forbidden) usually indicates missing 'service.storage.admin' permissions for purge.\")\n",
        "            elif e.response.status_code == 404:\n",
        "                 print(\"   Hint: Status code 404 (Not Found) might indicate the record was already purged.\")\n",
        "\n",
        "    except NameError:\n",
        "         # Handle case where variable was already deleted\n",
        "        print(\"Variable 'created_record_id' no longer exists (likely already purged). \")\n",
        "else:\n",
        "    print(\"Skipping purge because 'created_record_id' was not set or already deleted.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sE_O6KEuoXe"
      },
      "source": [
        "### Challenge\n",
        "\n",
        "1.  **Modify Step 3 (Create Dataset Record):**\n",
        "    *   Run the code cell for Step 3 once to create the initial record and capture its `id` and `version` (let's call this `version1`).\n",
        "    *   Modify the `Description` field in the payload within the Step 3 code cell (e.g., add \" - Second Version\" to the description).\n",
        "    *   Run the Step 3 code cell *again* with the modified payload (using the *same* `record_id`). This will create a second version. Capture the new version number returned in the response (let's call this `version2`).\n",
        "2.  **Verify Versions:** Run Step 4 (Get All Record Versions) to confirm that the record now has two versions listed.\n",
        "3.  **Retrieve First Version:** Use the `recordId` and the *first* version number (`version1`) you captured to run Step 5 (Get Specific Record Version) and display the details of the original record.\n",
        "4.  **(Optional Cleanup):** Run Steps 8 (Soft Delete) and 10 (Purge Record) to remove the record created during the challenge."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69BY9mi_uoXe"
      },
      "source": [
        "# Lab 2: Wellbore DDMS Operations\n",
        "\n",
        "**Goal:** Interact with the OSDU Wellbore Domain Data Management Services (DDMS) to manage wellbore trajectory data.\n",
        "\n",
        "**Concepts Covered:**\n",
        "*   Creating prerequisite resources (Legal Tag, Wellbore master record).\n",
        "*   Creating a WellboreTrajectory Work Product Component (WPC).\n",
        "*   Uploading trajectory data (Parquet format) via the Wellbore DDMS.\n",
        "*   Retrieving trajectory metadata and data.\n",
        "*   Visualizing trajectory data.\n",
        "*   Cleaning up created resources."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RZZfvE7NmQK"
      },
      "source": [
        "## Setup for Lab 2\n",
        "\n",
        "This section imports necessary libraries and sets up resources required for the Wellbore DDMS exercises:\n",
        "*   **API Endpoints:** Defines the URLs for Wellbore DDMS, Storage, and Legal services.\n",
        "*   **Unique Names:** Creates unique names for the Wellbore and Legal Tag using the `user_id`.\n",
        "*   **Legal Tag:** Creates a legal tag required for associating with OSDU records.\n",
        "*   **Placeholder Wellbore:** Creates a master-data Wellbore record. DDMS objects (like Trajectory) need to reference an existing Wellbore record."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzcobWbZN4TB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from io import BytesIO\n",
        "import os # For path manipulation\n",
        "\n",
        "# Ensure setup ran correctly\n",
        "if not all([osdu_endpoint, osdu_data_partition_id, user_id, headers, entitlements_domain]):\n",
        "     raise ValueError(\"Initial setup failed or variables are missing. Cannot proceed with Lab 2.\")\n",
        "\n",
        "# --- API Endpoints ---\n",
        "wellbore_dms_endpoint = f\"{osdu_endpoint}/api/os-wellbore-ddms/ddms/v3\"\n",
        "storage_endpoint = f\"{osdu_endpoint}/api/storage/v2\"\n",
        "legal_endpoint = f\"{osdu_endpoint}/api/legal/v1\"\n",
        "print(f\"Wellbore DMS Endpoint: {wellbore_dms_endpoint}\")\n",
        "print(f\"Storage Endpoint: {storage_endpoint}\")\n",
        "print(f\"Legal Endpoint: {legal_endpoint}\")\n",
        "\n",
        "# --- Unique Resource Identifiers ---\n",
        "legal_tag_name = f'osdu-lab-tag-{user_id}'\n",
        "wellbore_name = f\"LabWellbore-{user_id}\"\n",
        "# Construct the preliminary Wellbore ID (the final ID might be slightly different after creation)\n",
        "wellbore_id_prefix = f\"{osdu_data_partition_id}:master-data--Wellbore\"\n",
        "wellbore_id_initial = f\"{wellbore_id_prefix}:{wellbore_name}:\"\n",
        "wellbore_id = None # Will be set after successful creation\n",
        "print(f\"Will attempt to use Legal Tag: {legal_tag_name}\")\n",
        "print(f\"Will attempt to create Wellbore: {wellbore_id_initial}\")\n",
        "\n",
        "# --- Create Legal Tag ---\n",
        "# Define the legal tag payload\n",
        "legal_tag_payload = {\n",
        "    \"name\": legal_tag_name,\n",
        "    \"description\": f\"Legal tag created for OSDU lab session user {user_id}\",\n",
        "    \"properties\": {\n",
        "        \"contractId\": f\"LabContract-{user_id}\",\n",
        "        \"countryOfOrigin\": [\"US\"], # Example value\n",
        "        \"expirationDate\": \"2099-12-31\",\n",
        "        \"originator\": f\"LabUser-{user_id}\",\n",
        "        \"dataType\": \"Public Domain Data\", # Example value\n",
        "        \"securityClassification\": \"Public\", # Example value\n",
        "        \"personalData\": \"No Personal Data\",\n",
        "        \"exportClassification\": \"EAR99\" # Example value\n",
        "    }\n",
        "}\n",
        "\n",
        "try:\n",
        "    print(f\"\\nAttempting to create Legal Tag: {legal_tag_name}...\")\n",
        "    tag_response = requests.post(\n",
        "        f\"{legal_endpoint}/legaltags\",\n",
        "        headers=headers,\n",
        "        data=json.dumps(legal_tag_payload)\n",
        "    )\n",
        "\n",
        "    if tag_response.status_code == 201:\n",
        "        created_tag_name = tag_response.json().get(\"name\")\n",
        "        print(f\"Successfully created Legal Tag: {created_tag_name}\")\n",
        "    elif tag_response.status_code == 409:\n",
        "        print(f\"Legal Tag '{legal_tag_name}' already exists. Proceeding.\")\n",
        "    else:\n",
        "        tag_response.raise_for_status() # Raise an exception for other errors\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error creating/checking Legal Tag: {e}\")\n",
        "    if e.response is not None:\n",
        "        print(f\"Response: {e.response.text}\")\n",
        "    # Stop lab if legal tag creation fails and it doesn't already exist\n",
        "    if not (e.response is not None and e.response.status_code == 409):\n",
        "        raise\n",
        "\n",
        "# --- Create Placeholder Wellbore Record ---\n",
        "# Define the Wellbore payload using the initial ID\n",
        "wellbore_payload = {\n",
        "    \"kind\": \"osdu:wks:master-data--Wellbore:1.0.0\",\n",
        "    \"id\": wellbore_id_initial,\n",
        "    \"acl\": {\n",
        "        \"owners\": [f\"data.default.owners@{entitlements_domain}\"],\n",
        "        \"viewers\": [f\"data.default.viewers@{entitlements_domain}\"]\n",
        "    },\n",
        "    \"legal\": {\n",
        "        \"legaltags\": [legal_tag_name],\n",
        "        \"otherRelevantDataCountries\": [\"US\"] # Example value\n",
        "    },\n",
        "    \"data\": {\n",
        "        \"FacilityName\": wellbore_name,\n",
        "        \"FacilityTypeID\": \"osdu:reference-data--FacilityType:Wellbore:\", # Example reference value\n",
        "        \"WellboreIdentity\": [\n",
        "            {\n",
        "                \"AliasName\": wellbore_name,\n",
        "                \"AliasNameTypeID\": \"osdu:reference-data--AliasNameType:Name:\" # Example reference value\n",
        "            }\n",
        "        ]\n",
        "        # Add other required/optional Wellbore properties as needed\n",
        "    }\n",
        "}\n",
        "\n",
        "try:\n",
        "    print(f\"\\nAttempting to create placeholder Wellbore: {wellbore_id_initial}...\")\n",
        "    # Use PUT request for record creation (idempotent)\n",
        "    wb_response = requests.put(\n",
        "        f\"{storage_endpoint}/records\",\n",
        "        headers=headers,\n",
        "        json=[wellbore_payload] # Storage API expects a list of records\n",
        "    )\n",
        "\n",
        "    wb_response.raise_for_status() # Raise an exception for bad status codes (4xx or 5xx)\n",
        "\n",
        "    print(f\"Wellbore creation/update response: {wb_response.status_code}\")\n",
        "    response_data = wb_response.json()\n",
        "    # print(json.dumps(response_data, indent=2)) # Optional: print full response\n",
        "\n",
        "    if wb_response.status_code in [200, 201] and response_data.get('recordIds'):\n",
        "        # Get the canonical ID returned by the platform\n",
        "        wellbore_id = response_data['recordIds'][0]\n",
        "        print(f\"Successfully created/verified Wellbore. Using ID: {wellbore_id}\")\n",
        "    else:\n",
        "        # Fallback to using the initial ID if the response format is unexpected, but log a warning\n",
        "        wellbore_id = wellbore_id_initial\n",
        "        print(f\"Warning: Could not extract canonical Wellbore ID from response. Proceeding with initial ID: {wellbore_id}\")\n",
        "        print(f\"Response Body: {wb_response.text}\")\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    # A 409 Conflict might occur if the wellbore with that ID already exists from a previous run\n",
        "    # In this case, we can try to retrieve it to confirm and proceed.\n",
        "    # However, PUT is idempotent, so a 200/201 should handle exists/created cases.\n",
        "    # We'll log other errors and stop.\n",
        "    print(f\"Error creating/updating Wellbore: {e}\")\n",
        "    if e.response is not None:\n",
        "        print(f\"Response Status Code: {e.response.status_code}\")\n",
        "        print(f\"Response Body: {e.response.text}\")\n",
        "    # Stop lab if wellbore creation fails\n",
        "    raise\n",
        "\n",
        "# --- Define path to trajectory data file ---\n",
        "# This assumes a directory named 'assets' exists in the same location as the notebook\n",
        "# and contains the 'trajectory.parquet' file.\n",
        "# On Windows, Python typically handles forward slashes in paths correctly.\n",
        "### 1.3 Google Colab Functions\n",
        "\n",
        "# get a file from the bucket\n",
        "download_blob_to_file('trajectory.parquet', 'trajectory.parquet')\n",
        "trajectory_file_path = './assets/trajectory.parquet'\n",
        "print(f\"\\nUsing trajectory data file: {trajectory_file_path}\")\n",
        "\n",
        "# Check if the file exists\n",
        "if not os.path.exists(trajectory_file_path):\n",
        "    print(f\"Error: Trajectory data file not found at '{trajectory_file_path}'. Please ensure the file exists.\")\n",
        "    # Stop the lab if the data file is missing\n",
        "    raise FileNotFoundError(f\"Required data file not found: {trajectory_file_path}\")\n",
        "else:\n",
        "    print(\"Trajectory data file found.\")\n",
        "\n",
        "print(\"\\nLab 2 Setup Complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbtNQLu6uoXf"
      },
      "source": [
        "## 1. Wellbore Trajectory Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FokYDZBuoXf"
      },
      "source": [
        "### 1.1 Create WellboreTrajectory Record\n",
        "\n",
        "This step creates the metadata record (Work Product Component - WPC) for the wellbore trajectory. This record doesn't contain the actual trajectory points yet, but describes the trajectory and links it to the Wellbore created in the setup."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypYNxDTnHVzO"
      },
      "source": [
        "UPDATES:\n",
        "- \"TopDepthMeasuredDepth\": 0 instead of an object\n",
        "- \"BaseDepthMeasuredDepth\": 2.0 instead of an object\n",
        "- \"VerticalMeasurement\": {\n",
        "            \"EffectiveDateTime\": \"2021-08-17T14:13:08.174Z\",\n",
        "            \"VerticalMeasurement\": 0\n",
        "        }, instead of \"VerticalMeasurement\": {\n",
        "            \"VerticalMeasurementPathID\": \"osdu:reference-data--VerticalMeasurementPath:Kelly Bushing:\", # Example reference value\n",
        "            \"VerticalMeasurementTypeID\": \"osdu:reference-data--VerticalMeasurementType:Measured Depth:\", # Example reference value\n",
        "            \"VerticalMeasurementSourceID\": \"osdu:reference-data--VerticalMeasurementSource:Estimated:\" # Example reference value\n",
        "        },\n",
        "- ProjectedBottomHoleLocation was removed,\n",
        "- AvailableTrajectoryStationProperties.UnitOfMeasuredId was replaced by StationPropertyUnitID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-JO64rouoXf",
        "tags": [
          "lab1-step"
        ]
      },
      "outputs": [],
      "source": [
        "# Define a unique ID for the trajectory record\n",
        "trajectory_record_id_initial = f\"{osdu_data_partition_id}:work-product-component--WellboreTrajectory:labtrajectory-{user_id}\"\n",
        "trajectory_record_id = None # Will be set after creation\n",
        "\n",
        "# Trajectory WPC Payload\n",
        "trajectory_payload = {\n",
        "    \"kind\": \"osdu:wks:work-product-component--WellboreTrajectory:1.1.0\", # Using 1.1.0 as an example, check your platform's schema version\n",
        "    \"id\": trajectory_record_id_initial,\n",
        "    \"acl\": {\n",
        "        \"owners\": [f\"data.default.owners@{entitlements_domain}\"],\n",
        "        \"viewers\": [f\"data.default.viewers@{entitlements_domain}\"]\n",
        "    },\n",
        "    \"legal\": {\n",
        "        \"legaltags\": [legal_tag_name],\n",
        "        \"otherRelevantDataCountries\": [\"US\"]\n",
        "    },\n",
        "    \"data\": {\n",
        "        \"Name\": f\"Trajectory_{wellbore_name}\",\n",
        "        \"Description\": f\"Wellbore trajectory for {wellbore_name} generated during lab session {user_id}\",\n",
        "        \"WellboreID\": f\"{wellbore_id}\", # Reference the created Wellbore ID\n",
        "        \"TopDepthMeasuredDepth\": 0,\n",
        "        \"BaseDepthMeasuredDepth\": 2.0,\n",
        "        \"VerticalMeasurement\": {\n",
        "            \"EffectiveDateTime\": \"2021-08-17T14:13:08.174Z\",\n",
        "            \"VerticalMeasurement\": 0\n",
        "        },\n",
        "        # \"ProjectedBottomHoleLocation\": { # Added example for completeness\n",
        "        #     \"Latitude\": {\"value\": 0.0, \"uom\": \"dega\"},\n",
        "        #     \"Longitude\": {\"value\": 0.0, \"uom\": \"dega\"},\n",
        "        #     \"CoordinateReferenceSystemID\": \"osdu:reference-data--CoordinateReferenceSystem:WGS 84:\"\n",
        "        # },\n",
        "        # Define available station properties based on the data to be uploaded\n",
        "        \"AvailableTrajectoryStationProperties\": [\n",
        "            {\n",
        "                \"TrajectoryStationPropertyTypeID\": \"osdu:reference-data--TrajectoryStationPropertyType:MeasuredDepth:\",\n",
        "                \"StationPropertyUnitID\": \"osdu:reference-data--UnitOfMeasure:m:\", # Ensure UoM matches reference data\n",
        "                \"Name\": \"Measured Depth\"\n",
        "            },\n",
        "            {\n",
        "                \"TrajectoryStationPropertyTypeID\": \"osdu:reference-data--TrajectoryStationPropertyType:Inclination:\",\n",
        "                \"StationPropertyUnitID\": \"osdu:reference-data--UnitOfMeasure:rad:\", # Ensure UoM matches reference data\n",
        "                \"Name\": \"Inclination\"\n",
        "            },\n",
        "            {\n",
        "                \"TrajectoryStationPropertyTypeID\": \"osdu:reference-data--TrajectoryStationPropertyType:AzimuthTrueNorth:\",\n",
        "                \"StationPropertyUnitID\": \"osdu:reference-data--UnitOfMeasure:rad:\", # Ensure UoM matches reference data\n",
        "                \"Name\": \"Azimuth\"\n",
        "            },\n",
        "            {\n",
        "                \"TrajectoryStationPropertyTypeID\": \"osdu:reference-data--TrajectoryStationPropertyType:TVD:\",\n",
        "                \"StationPropertyUnitID\": \"osdu:reference-data--UnitOfMeasure:m:\", # Ensure UoM matches reference data\n",
        "                \"Name\": \"True Vertical Depth\"\n",
        "            }\n",
        "            # Add other properties like DX, DY if present in the data\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "print(f\"Creating WellboreTrajectory record: {trajectory_record_id_initial}...\")\n",
        "try:\n",
        "    response = requests.put(\n",
        "        f\"{storage_endpoint}/records\",\n",
        "        headers=headers,\n",
        "        json=[trajectory_payload]\n",
        "    )\n",
        "    response.raise_for_status()\n",
        "    print(f\"WellboreTrajectory creation/update response: {response.status_code}\")\n",
        "\n",
        "    response_data = response.json()\n",
        "    if response.status_code in [200, 201] and response_data.get('recordIds'):\n",
        "        trajectory_record_id = response_data['recordIds'][0]\n",
        "        print(f\"Successfully created/verified WellboreTrajectory. Using ID: {trajectory_record_id}\")\n",
        "    else:\n",
        "        trajectory_record_id = trajectory_record_id_initial # Fallback\n",
        "        print(f\"Warning: Could not extract canonical Trajectory ID. Using initial ID: {trajectory_record_id}\")\n",
        "        print(f\"Response Body: {response.text}\")\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error creating WellboreTrajectory record: {e}\")\n",
        "    if e.response is not None:\n",
        "        print(f\"Response Status Code: {e.response.status_code}\")\n",
        "        print(f\"Response Body: {e.response.text}\")\n",
        "    # Stop if creation fails\n",
        "    raise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPRwhazNuoXf"
      },
      "source": [
        "### 1.2 Get WellboreTrajectory Metadata\n",
        "\n",
        "This step retrieves the metadata for the WellboreTrajectory record created previously using the Wellbore DDMS API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtz_RP9duoXf",
        "tags": [
          "lab1-step"
        ]
      },
      "outputs": [],
      "source": [
        "if trajectory_record_id:\n",
        "    print(f\"Getting WellboreTrajectory metadata for: {trajectory_record_id}\")\n",
        "    try:\n",
        "        # DDMS endpoint requires URL encoding for the record ID\n",
        "        encoded_trajectory_id = urllib.parse.quote(trajectory_record_id)\n",
        "        url = f\"{wellbore_dms_endpoint}/wellboretrajectories/{encoded_trajectory_id}\"\n",
        "        print(f\"Request URL: {url}\")\n",
        "\n",
        "        response = requests.get(url, headers=headers)\n",
        "        response.raise_for_status()\n",
        "        print(f\"Get WellboreTrajectory metadata response status: {response.status_code}\")\n",
        "        print(\"--- WellboreTrajectory Metadata ---\")\n",
        "        print(json.dumps(response.json(), indent=2))\n",
        "        print(\"-----------------------------------\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error getting WellboreTrajectory metadata: {e}\")\n",
        "        if e.response is not None:\n",
        "            print(f\"Response Body: {e.response.text}\")\n",
        "else:\n",
        "    print(\"WellboreTrajectory record ID not available. Skipping Get Metadata step.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlcM7g-FuoXf"
      },
      "source": [
        "### 1.3 Upload WellboreTrajectory Data (Parquet)\n",
        "\n",
        "This step uploads the actual trajectory station data (MD, Inclination, Azimuth, etc.) from the local Parquet file to the OSDU platform via the Wellbore DDMS. The DDMS handles storing this data efficiently, often linking it to the metadata record."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJd6OJUZuoXf",
        "tags": [
          "lab1-step"
        ]
      },
      "outputs": [],
      "source": [
        "if trajectory_record_id and os.path.exists(trajectory_file_path):\n",
        "    print(f\"Uploading trajectory data from '{trajectory_file_path}' to record: {trajectory_record_id}\")\n",
        "    try:\n",
        "        # Open the Parquet file in binary read mode\n",
        "        with open(trajectory_file_path, \"rb\") as file_content:\n",
        "            # Use the DDMS endpoint for uploading data, passing the record ID\n",
        "            encoded_trajectory_id = urllib.parse.quote(trajectory_record_id)\n",
        "            upload_url = f\"{wellbore_dms_endpoint}/wellboretrajectories/{encoded_trajectory_id}/data\"\n",
        "            print(f\"Upload URL: {upload_url}\")\n",
        "\n",
        "            # Use parquet_headers which sets 'Content-Type': 'application/x-parquet'\n",
        "            response = requests.post(upload_url, headers=parquet_headers, data=file_content)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            print(f\"Trajectory data uploaded successfully. Response status: {response.status_code}\")\n",
        "            # Check if the response contains JSON data (e.g., dataset info)\n",
        "            try:\n",
        "                print(\"--- Upload Response Body ---\")\n",
        "                print(json.dumps(response.json(), indent=2))\n",
        "                print(\"--------------------------\")\n",
        "            except json.JSONDecodeError:\n",
        "                print(\"(Response body is not JSON)\")\n",
        "                print(response.text)\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error uploading Parquet file: {e}\")\n",
        "        if e.response is not None:\n",
        "            print(f\"Response Status Code: {e.response.status_code}\")\n",
        "            print(f\"Response Body: {e.response.text}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found at '{trajectory_file_path}'\")\n",
        "    except Exception as e:\n",
        "         print(f\"An unexpected error occurred during upload: {e}\")\n",
        "else:\n",
        "    print(\"Skipping data upload: Trajectory record ID is not available or data file is missing.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1J3QSJduoXf"
      },
      "source": [
        "### 1.4 Get WellboreTrajectory Data (as JSON)\n",
        "\n",
        "This step retrieves the previously uploaded trajectory data using the Wellbore DDMS API, requesting it in JSON format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYjmAJfOuoXf",
        "tags": [
          "lab1-step"
        ]
      },
      "outputs": [],
      "source": [
        "if trajectory_record_id:\n",
        "    try:\n",
        "        # Prepare headers to accept JSON\n",
        "        get_headers = headers.copy()\n",
        "        get_headers[\"Accept\"] = \"application/json\"\n",
        "\n",
        "        encoded_trajectory_id = urllib.parse.quote(trajectory_record_id)\n",
        "        url = f\"{wellbore_dms_endpoint}/wellboretrajectories/{encoded_trajectory_id}/data\"\n",
        "        print(f\"Retrieving WellboreTrajectory data as JSON from: {url}\")\n",
        "\n",
        "        response = requests.get(url, headers=get_headers)\n",
        "        response.raise_for_status()\n",
        "        print(f\"Get WellboreTrajectory data (JSON) response status: {response.status_code}\")\n",
        "\n",
        "        # Process the response\n",
        "        print(f\"Response Content-Type: {response.headers.get('Content-Type')}\")\n",
        "        if 'application/json' in response.headers.get('Content-Type', ''):\n",
        "            print(\"--- Trajectory Data (JSON) ---\")\n",
        "            trajectory_data_json = response.json()\n",
        "            # Print only the first few stations for brevity\n",
        "            if isinstance(trajectory_data_json, list) and len(trajectory_data_json) > 5:\n",
        "                 print(json.dumps(trajectory_data_json[:5], indent=2))\n",
        "                 print(\"...\")\n",
        "                 print(f\"(Total: {len(trajectory_data_json)} stations)\")\n",
        "            else:\n",
        "                 print(json.dumps(trajectory_data_json, indent=2))\n",
        "            print(\"----------------------------\")\n",
        "        else:\n",
        "            print(f\"Received unexpected content type: {response.headers.get('Content-Type')}\")\n",
        "            print(response.text[:1000] + \"...\") # Print beginning of response\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error getting WellboreTrajectory data as JSON: {e}\")\n",
        "        if e.response is not None:\n",
        "            print(f\"Response body: {e.response.text}\")\n",
        "else:\n",
        "    print(\"WellboreTrajectory record ID not available. Skipping Get Data (JSON) step.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b49BQU6WuoXf"
      },
      "source": [
        "### 1.5 Get WellboreTrajectory Data (as Parquet)\n",
        "\n",
        "This step retrieves the trajectory data again, but requests it in the original Parquet format. It then uses `pandas` and `pyarrow` (installed earlier) to read the binary Parquet data directly into a DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhalusH2uoXf",
        "tags": [
          "lab1-step"
        ]
      },
      "outputs": [],
      "source": [
        "trajectory_data_parquet_content = None # Initialize variable to store content\n",
        "\n",
        "if trajectory_record_id:\n",
        "    try:\n",
        "        # Prepare headers to accept Parquet\n",
        "        get_headers = headers.copy()\n",
        "        # Common MIME types for Parquet, adjust if your instance uses a different one\n",
        "        get_headers[\"Accept\"] = \"application/x-parquet, application/octet-stream\"\n",
        "\n",
        "        encoded_trajectory_id = urllib.parse.quote(trajectory_record_id)\n",
        "        url = f\"{wellbore_dms_endpoint}/wellboretrajectories/{encoded_trajectory_id}/data\"\n",
        "        print(f\"Retrieving WellboreTrajectory data as Parquet from: {url}\")\n",
        "\n",
        "        response = requests.get(url, headers=get_headers)\n",
        "        response.raise_for_status()\n",
        "        print(f\"Get WellboreTrajectory data (Parquet) response status: {response.status_code}\")\n",
        "\n",
        "        # Check content type before attempting to read Parquet\n",
        "        content_type = response.headers.get('Content-Type', '').lower()\n",
        "        print(f\"Response Content-Type: {content_type}\")\n",
        "\n",
        "        if 'parquet' in content_type or 'octet-stream' in content_type:\n",
        "            print(\"Received Parquet or binary stream. Reading into DataFrame...\")\n",
        "            # Store the binary content for potential later use (like visualization)\n",
        "            trajectory_data_parquet_content = response.content\n",
        "\n",
        "            # Read the binary content directly into a Pandas DataFrame\n",
        "            # BytesIO creates an in-memory binary file from the response content\n",
        "            trajectory_df = pd.read_parquet(BytesIO(trajectory_data_parquet_content))\n",
        "\n",
        "            print(\"--- Trajectory Data (DataFrame from Parquet) ---\")\n",
        "            # Display the first few rows of the DataFrame\n",
        "            display(trajectory_df.head())\n",
        "            print(f\"(Total: {len(trajectory_df)} rows)\")\n",
        "            print(\"----------------------------------------------\")\n",
        "\n",
        "        elif 'application/json' in content_type:\n",
        "            print(\"Received JSON instead of Parquet. Displaying JSON:\")\n",
        "            print(json.dumps(response.json(), indent=2))\n",
        "        else:\n",
        "            print(f\"Received unexpected Content-Type: {content_type}. Cannot process as Parquet.\")\n",
        "            # Optionally save the binary content to a file for inspection\n",
        "            # with open(f\"trajectory_download_{user_id}.bin\", \"wb\") as f:\n",
        "            #    f.write(response.content)\n",
        "            # print(\"Binary content saved to file.\")\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error getting WellboreTrajectory data as Parquet: {e}\")\n",
        "        if e.response is not None:\n",
        "            print(f\"Response body: {e.response.text}\")\n",
        "    except ImportError:\n",
        "         print(\"Error: pyarrow library not found. Cannot read Parquet. Make sure it was installed.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred processing the Parquet data: {e}\")\n",
        "else:\n",
        "    print(\"WellboreTrajectory record ID not available. Skipping Get Data (Parquet) step.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZUL_Fkpcd1_"
      },
      "source": [
        "### 1.6 Visualize Wellbore Trajectory\n",
        "\n",
        "This step uses the trajectory data (retrieved as Parquet in the previous step) and the `matplotlib` library to create a simple 3D plot of the wellbore path."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncWtAf8gcvS8"
      },
      "source": [
        "UPDATED:\n",
        "- ['MeasuredDepth', 'Inclination', 'AzimuthTrueNorth'] replaced with ['Measured Depth', 'Inclination', 'Azimuth']\n",
        "- azimuth_rad = trajectory_df['Azimuth']\n",
        "- md = trajectory_df['Measured Depth']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MV6eFKC4ctXV"
      },
      "outputs": [],
      "source": [
        "if trajectory_data_parquet_content:\n",
        "    try:\n",
        "        print(\"Visualizing trajectory data...\")\n",
        "        # Read the stored Parquet content into a DataFrame again\n",
        "        trajectory_df = pd.read_parquet(BytesIO(trajectory_data_parquet_content))\n",
        "\n",
        "        # --- Trajectory Calculation (Minimum Curvature Method - Simplified) ---\n",
        "        # Ensure required columns exist (adjust names if different in your Parquet file)\n",
        "        required_cols = ['Measured Depth', 'Inclination', 'Azimuth']\n",
        "        if not all(col in trajectory_df.columns for col in required_cols):\n",
        "             raise ValueError(f\"Missing required columns for visualization: {required_cols}. Found: {trajectory_df.columns.tolist()}\")\n",
        "\n",
        "        # Convert Azimuth and Inclination from Radians (as per schema) to Degrees for easier understanding if needed,\n",
        "        # but calculations often use radians. Assuming input is in Radians based on sample payload.\n",
        "        # If your data is in degrees, convert here:\n",
        "        # inclination_rad = np.radians(trajectory_df['Inclination'])\n",
        "        # azimuth_rad = np.radians(trajectory_df['AzimuthTrueNorth'])\n",
        "        inclination_rad = trajectory_df['Inclination']\n",
        "        azimuth_rad = trajectory_df['Azimuth']\n",
        "        md = trajectory_df['Measured Depth']\n",
        "\n",
        "        # Initialize arrays for coordinates\n",
        "        x = np.zeros_like(md)\n",
        "        y = np.zeros_like(md)\n",
        "        z = np.zeros_like(md) # TVD\n",
        "\n",
        "        # Calculate coordinates iteratively\n",
        "        for i in range(1, len(md)):\n",
        "            delta_md = md[i] - md[i-1]\n",
        "\n",
        "            # Average angles between stations\n",
        "            avg_incl = (inclination_rad[i] + inclination_rad[i-1]) / 2\n",
        "            avg_azim = (azimuth_rad[i] + azimuth_rad[i-1]) / 2\n",
        "\n",
        "            # Dog Leg Severity (angle change rate)\n",
        "            # More accurate methods exist, this is simplified\n",
        "            # Using basic trig for displacement components\n",
        "            delta_x = delta_md * np.sin(avg_incl) * np.sin(avg_azim) # Easting\n",
        "            delta_y = delta_md * np.sin(avg_incl) * np.cos(avg_azim) # Northing\n",
        "            delta_z = delta_md * np.cos(avg_incl) # True Vertical Depth change\n",
        "\n",
        "            x[i] = x[i-1] + delta_x\n",
        "            y[i] = y[i-1] + delta_y\n",
        "            z[i] = z[i-1] + delta_z\n",
        "\n",
        "        # If TVD is directly available in the data, prefer using it:\n",
        "        if 'TVD' in trajectory_df.columns:\n",
        "            print(\"Using 'TVD' column from data for Z-axis.\")\n",
        "            z = trajectory_df['TVD']\n",
        "        else:\n",
        "             print(\"Calculating TVD (Z-axis) from MD, Inclination.\")\n",
        "\n",
        "        # --- Plotting ---\n",
        "        fig = plt.figure(figsize=(10, 8))\n",
        "        ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "        # Plot the 3D trajectory\n",
        "        ax.plot(x, y, z, label=f'Wellbore Trajectory ({wellbore_name})', marker='.')\n",
        "\n",
        "        # Set labels and title\n",
        "        ax.set_xlabel('East Offset (m)')\n",
        "        ax.set_ylabel('North Offset (m)')\n",
        "        ax.set_zlabel('True Vertical Depth (m)')\n",
        "        ax.set_title('Wellbore Trajectory 3D Visualization')\n",
        "\n",
        "        # Invert Z-axis so depth increases downwards\n",
        "        ax.invert_zaxis()\n",
        "\n",
        "        # Set aspect ratio to be equal for better spatial representation\n",
        "        # ax.set_aspect('equal') # Matplotlib 3D doesn't always support 'equal' directly\n",
        "        # Auto-scaling usually works well enough for demonstration\n",
        "        ax.autoscale_view()\n",
        "\n",
        "        ax.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"Error: Matplotlib or NumPy not found. Cannot visualize. Make sure they were installed.\")\n",
        "    except KeyError as e:\n",
        "        print(f\"Error visualizing: Missing column in trajectory data: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during visualization: {e}\")\n",
        "else:\n",
        "    print(\"Trajectory data (Parquet content) not available. Skipping visualization.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ocfd-1eruoXf"
      },
      "source": [
        "## Cleanup for Lab 2\n",
        "\n",
        "This section deletes the resources created during Lab 2 to keep the OSDU instance clean. It attempts to delete:\n",
        "*   The WellboreTrajectory record.\n",
        "*   The placeholder Wellbore record.\n",
        "*   The Legal Tag.\n",
        "\n",
        "**Note:** Deleting DDMS data associated with a record (like the trajectory points uploaded in step 1.3) typically happens automatically when the metadata record (WellboreTrajectory WPC) is deleted via the Storage API, but this behavior might depend on the specific DDMS implementation and platform configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5Ew7KNbuoXf",
        "tags": [
          "lab1-cleanup"
        ]
      },
      "outputs": [],
      "source": [
        "print(\"--- Starting Lab 2 Cleanup ---\")\n",
        "\n",
        "# 1. Delete the WellboreTrajectory record\n",
        "if 'trajectory_record_id' in locals() and trajectory_record_id:\n",
        "    print(f\"\\nAttempting to delete WellboreTrajectory record: {trajectory_record_id}\")\n",
        "    try:\n",
        "        delete_url = f\"{storage_endpoint}/records/{urllib.parse.quote(trajectory_record_id)}\"\n",
        "        # Storage API V2 delete returns 204 No Content on success\n",
        "        response = requests.delete(delete_url, headers=headers)\n",
        "        if response.status_code == 204:\n",
        "            print(f\"Successfully deleted WellboreTrajectory record: {trajectory_record_id}\")\n",
        "        elif response.status_code == 404:\n",
        "             print(f\"WellboreTrajectory record {trajectory_record_id} already deleted or not found.\")\n",
        "        else:\n",
        "            response.raise_for_status() # Raise error for other statuses\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error deleting WellboreTrajectory record {trajectory_record_id}: {e}\")\n",
        "        if e.response is not None:\n",
        "            print(f\"Response: {e.response.text}\")\n",
        "else:\n",
        "    print(\"\\nWellboreTrajectory record ID not available. Skipping deletion.\")\n",
        "\n",
        "# 2. Delete the placeholder Wellbore record\n",
        "if 'wellbore_id' in locals() and wellbore_id:\n",
        "    print(f\"\\nAttempting to delete Wellbore record: {wellbore_id}\")\n",
        "    try:\n",
        "        delete_url = f\"{storage_endpoint}/records/{urllib.parse.quote(wellbore_id)}\"\n",
        "        response = requests.delete(delete_url, headers=headers)\n",
        "        if response.status_code == 204:\n",
        "            print(f\"Successfully deleted Wellbore record: {wellbore_id}\")\n",
        "        elif response.status_code == 404:\n",
        "             print(f\"Wellbore record {wellbore_id} already deleted or not found.\")\n",
        "        else:\n",
        "            response.raise_for_status()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error deleting Wellbore record {wellbore_id}: {e}\")\n",
        "        # Check if it failed because it's referenced by other records (like the trajectory if deletion failed)\n",
        "        if e.response is not None:\n",
        "            print(f\"Response: {e.response.text}\")\n",
        "else:\n",
        "    print(\"\\nWellbore record ID not available. Skipping deletion.\")\n",
        "\n",
        "# 3. Delete the Legal Tag\n",
        "if 'legal_tag_name' in locals() and legal_tag_name:\n",
        "    print(f\"\\nAttempting to delete Legal Tag: {legal_tag_name}\")\n",
        "    try:\n",
        "        delete_url = f\"{legal_endpoint}/legaltags/{urllib.parse.quote(legal_tag_name)}\"\n",
        "        # Legal API delete also typically returns 204 No Content\n",
        "        response = requests.delete(delete_url, headers=headers)\n",
        "        if response.status_code == 204:\n",
        "            print(f\"Successfully deleted Legal Tag: {legal_tag_name}\")\n",
        "        elif response.status_code == 404:\n",
        "             print(f\"Legal Tag {legal_tag_name} already deleted or not found.\")\n",
        "        else:\n",
        "            response.raise_for_status()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error deleting Legal Tag {legal_tag_name}: {e}\")\n",
        "        # Check if it failed because it's still in use by records\n",
        "        if e.response is not None:\n",
        "            print(f\"Response: {e.response.text}\")\n",
        "else:\n",
        "    print(\"\\nLegal Tag name not available. Skipping deletion.\")\n",
        "\n",
        "print(\"\\n--- Lab 2 Cleanup Complete ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XyT3YZsuoXf"
      },
      "source": [
        "## Challenge (Optional)\n",
        "\n",
        "**Task:** Modify the lab to work with Well Logs instead of Wellbore Trajectories.\n",
        "\n",
        "1.  **Adapt Setup:** Keep the Legal Tag and Wellbore creation.\n",
        "2.  **Create WellLog Record:** Create a `work-product-component--WellLog` record instead of a `WellboreTrajectory`. Populate its metadata appropriately (e.g., `Name`, `WellboreID`, `Curves`). You'll need to define which curves the log contains (e.g., GR, CALI, DEPTH). Find a sample WellLog Parquet/CSV/LAS file or create a small dummy one.\n",
        "3.  **Upload Log Data:** Use the Wellbore DDMS endpoint for WellLogs (`/welllogs/{record_id}/data`) to upload your sample log data (e.g., in Parquet format).\n",
        "4.  **Retrieve Log Data:** Use the corresponding GET endpoint (`/welllogs/{record_id}/data`) to retrieve the log data, potentially requesting specific curves or a depth range.\n",
        "5.  **Visualize:** Plot one or two curves (e.g., GR vs. DEPTH) using Matplotlib.\n",
        "6.  **Cleanup:** Ensure the WellLog record is deleted in the cleanup section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pE4sBQZuyja"
      },
      "source": [
        "# Lab 3: Reservoir DMS Operations\n",
        "\n",
        "This tutorial focuses on understanding the components of the RDDMS and how to use the ETP and REST API.\n",
        "\n",
        "In the following diagram representing a typical OSDU deployment, you will notice that:\n",
        "- The ETP server and REST API service will be running alongside OSDU services within a Kubernetes cluster.\n",
        "- The RDDMS services interact with other OSDU services, such as entitlements, records, and more.\n",
        "- The ETP server can connect to multiple OSDU partitions.\n",
        "- The ETP and REST endpoints are exposed via secured protocols (HTTPS and WSS).\n",
        "- Authentication and authorization are enabled.\n",
        "\n",
        "The API documentation should be available on the [Swagger page](https://preship.gcp.gnrg-osdu.projects.epam.com/api/reservoir-ddms/v2/).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATroHkeSuyja"
      },
      "source": [
        "## Setup for Lab 3\n",
        "\n",
        "The following sections at the top of this workbook must be executed prior starting this lab.\n",
        "\n",
        "- [OSDU Hands-on Lab Environment Setup](OSDU_Bootcamp_Labs.ipynb#osdu-hands-on-lab-environment-setup)\n",
        "  - [1 Initial Setup](OSDU_Bootcamp_Labs.ipynb#1-initial-setup)\n",
        "    - [1.2 Configure Connection and Authentication](OSDU_Bootcamp_Labs.ipynb#12-configure-connection-and-authentication)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSWd7OcLuyja"
      },
      "source": [
        "### Auth in Google Cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAMKlPNruyja"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()\n",
        "\n",
        "    osdu_endpoint = \"https://osdu-bootcamp.com\"\n",
        "    osdu_data_partition_id= \"osdu\"\n",
        "    osdu_group_domain = \"group\"\n",
        "\n",
        "\n",
        "    def get_token():\n",
        "        output = !gcloud auth print-access-token\n",
        "        token = output[0]\n",
        "        return token\n",
        "else:\n",
        "    # clear previous token and set up new environment\n",
        "    _token_context = {\n",
        "        \"token\": None,\n",
        "        \"expires_at\": 0\n",
        "    }\n",
        "\n",
        "    # Configure and authenticate to OSDU instance with RDDMS\n",
        "    dotenv_file = \".env.osdu-bootcamp\"\n",
        "    initialize_from_env_file(dotenv_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hel7CYuuyja"
      },
      "outputs": [],
      "source": [
        "# Generate Personal Identifier\n",
        "if( 'user_id' not in locals() or not user_id):\n",
        "    import random\n",
        "    user_id = f\"{random.randint(1000, 9999)}\"\n",
        "    print(f\"Generated user_id for this session: {user_id}\")\n",
        "\n",
        "# Functions to display a banner message\n",
        "def green_banner(msg, detail_msg=None):\n",
        "    if detail_msg:\n",
        "        text = f\"{msg}<br><span style='font-size: 12pt;'>{detail_msg}</span>\"\n",
        "    else:\n",
        "        text = msg\n",
        "    return display_banner(text, color='green')\n",
        "\n",
        "def red_banner(msg, detail_msg=None):\n",
        "    if detail_msg:\n",
        "        text = f\"{msg}<br><span style='font-size: 12pt;'>{detail_msg}</span>\"\n",
        "    else:\n",
        "        text = msg\n",
        "    return display_banner(text, color='red')\n",
        "\n",
        "# Ensure osdu_data_partition_id is defined\n",
        "if 'osdu_data_partition_id' not in locals() or not osdu_data_partition_id:\n",
        "    red_banner(\"osdu_data_partition_id is not defined.<br>Please run \\\"1.2 Configure Connection and Authentication\\\" before running this code.\")\n",
        "    raise SystemExit(\"osdu_data_partition_id is not defined. Please set osdu_data_partition_id before running this code.\")\n",
        "\n",
        "# Ensure osdu_endpoint is defined\n",
        "if 'osdu_endpoint' not in locals() or not osdu_endpoint:\n",
        "    red_banner(\"osdu_endpoint is not defined.<br>Please run \\\"1.2 Configure Connection and Authentication\\\" before running this code.\")\n",
        "    raise SystemExit(\"osdu_endpoint is not defined. Please set osdu_endpoint before running this code.\")\n",
        "\n",
        "green_banner(\"You are now pointing to a new OSDU instance.\", f\"{osdu_endpoint}\")\n",
        "print(osdu_endpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ukj1U8huyjb"
      },
      "outputs": [],
      "source": [
        "# Installing Libs needed\n",
        "%pip install plotly numpy pandas requests --quiet\n",
        "\n",
        "# importing python modules used in this notebook\n",
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from IPython.display import display\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "\n",
        "# Define the endpoints that will be used in the lab\n",
        "entitlements_endpoint = f\"{osdu_endpoint}/api/entitlements/v2\"\n",
        "legal_endpoint = f\"{osdu_endpoint}/api/legal/v1\"\n",
        "search_endpoint = f\"{osdu_endpoint}/api/search/v2\"\n",
        "\n",
        "# Define  the group domain for the entitlements\n",
        "entitlements_domain = f\"{osdu_data_partition_id}.{osdu_group_domain}\"\n",
        "\n",
        "# function to display a pandas dataframe in a pretty format\n",
        "def pretty_print_panda_frame(df, title=None, transpose=False, show_index=False, show_header=True):\n",
        "    styled = (df.transpose() if transpose else df).style.set_properties(**{'text-align': 'left'})\n",
        "    if title: display(HTML(f\"<h3 style='margin-bottom: 0px'>{title}</h3>\"))\n",
        "    if not show_index: styled = styled.hide(axis='index')\n",
        "    if not show_header: styled = styled.set_table_styles([{'selector': 'thead', 'props': [('display', 'none')]}])\n",
        "    else: styled = styled.set_table_styles([{'selector': 'th', 'props': [('text-align', 'left')]}])\n",
        "    display(styled)\n",
        "\n",
        "\n",
        "# preparing standard REST headers\n",
        "def get_rddms_header():\n",
        "    return {\n",
        "        \"Authorization\": f\"Bearer {get_token()}\",\n",
        "        \"data-partition-id\": osdu_data_partition_id,\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "def find_all_group_memberships():\n",
        "    try:\n",
        "        # Send a GET request to the entitlements endpoint to retrieve all groups\n",
        "        get_groups_response = requests.get(\n",
        "            f\"{entitlements_endpoint}/groups\",\n",
        "            headers=get_rddms_header()\n",
        "        )\n",
        "\n",
        "        get_groups_response.raise_for_status()\n",
        "        if get_groups_response.status_code == 200:\n",
        "            get_all_groups_response = get_groups_response.json()\n",
        "            group_names = [group.get('name') for group in get_all_groups_response.get('groups', [])]\n",
        "\n",
        "            return group_names\n",
        "        else:\n",
        "            return []\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return []\n",
        "\n",
        "# Check if the group name is in the list of all group names\n",
        "def check_group_membership(group_name, all_group_names):\n",
        "    if group_name in all_group_names:\n",
        "        return True, f\"User is member of '{group_name}'\"\n",
        "    else:\n",
        "        return False, f\"User is not member of '{group_name}'\"\n",
        "\n",
        "# Check if the legal tag exists\n",
        "def check_legal_tag_exists(tag_name):\n",
        "    try:\n",
        "        legal_tag_check_response = requests.get(\n",
        "            f\"{legal_endpoint}/legaltags/{tag_name}\",\n",
        "            headers=get_rddms_header()\n",
        "        )\n",
        "        legal_tag_check_response.raise_for_status()\n",
        "        if legal_tag_check_response.status_code == 200:\n",
        "            return True, f\"Legal tag exists: {tag_name}\"\n",
        "        else:\n",
        "            return False, f\"Legal tag does not exist: {tag_name}\"\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return False, f\"Legal tag does not exist: {tag_name}\"\n",
        "\n",
        "def create_legal_tag(tag_name, tag_description):\n",
        "    legal_tag_payload = {\n",
        "        \"name\": tag_name,\n",
        "        \"description\": tag_description,\n",
        "        \"properties\": {\n",
        "            \"contractId\": f\"CID-{user_id}-A1\",\n",
        "            \"countryOfOrigin\": [\"US\"], # Must be an ISO 3166-1 alpha-2 country code\n",
        "            \"dataType\": \"Public Domain Data\", # Value must exist in reference data 'LegalTagPropertyType' for 'dataType'\n",
        "            \"expirationDate\": \"2099-12-31\", # Format YYYY-MM-DD\n",
        "            \"exportClassification\": \"EAR99\", # Value must exist in reference data 'LegalTagPropertyType' for 'exportClassification'\n",
        "            \"originator\": f\"LabUser-{user_id}\",\n",
        "            \"personalData\": \"No Personal Data\", # Value must exist in reference data 'LegalTagPropertyType' for 'personalData'\n",
        "            \"securityClassification\": \"Public\" # Value must exist in reference data 'LegalTagPropertyType' for 'securityClassification'\n",
        "        }\n",
        "    }\n",
        "    try:\n",
        "        tag_response = requests.post(\n",
        "            f\"{legal_endpoint}/legaltags\",\n",
        "            headers=get_rddms_header(),\n",
        "            data=json.dumps(legal_tag_payload)\n",
        "        )\n",
        "        if tag_response.status_code == 201:\n",
        "            created_tag_name = tag_response.json().get(\"name\")\n",
        "            msg = f\"Successfully created legal tag: {created_tag_name}\"\n",
        "        elif tag_response.status_code == 409:\n",
        "            created_tag_name = tag_name\n",
        "            msg = f\"Legal tag '{tag_name}' already exists. Proceeding.\"\n",
        "        else:\n",
        "            created_tag_name = None\n",
        "            msg = f\"Error: {tag_response.status_code} - {tag_response.text}\"\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        created_tag_name = None\n",
        "        if e.response is not None:\n",
        "            msg = f\"Response: {e.response.text}\"\n",
        "        else:\n",
        "            msg = f\"Error: {e}\"\n",
        "    return created_tag_name, msg\n",
        "\n",
        "# Create a Legal Tag\n",
        "user_tag_name = f'{osdu_data_partition_id}-lab-rddms-tag-{user_id}'\n",
        "user_tag_description = f\"Lab tag created by user {user_id}\"\n",
        "created_tag_name, msg = create_legal_tag(user_tag_name, user_tag_description)\n",
        "if not created_tag_name:\n",
        "    red_banner(f\"Failed to create legal tag '{user_tag_name}'.\", msg)\n",
        "    raise SystemExit(\"Failed to create legal tag.\")\n",
        "\n",
        "green_banner(\"Lab 3 - Reservoir DDMS is setup and ready to go.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YT9ZVlfuyjb"
      },
      "source": [
        "## 1. Reading Data from RDDMS with REST\n",
        "\n",
        "In this section we will:\n",
        "1. Explore all dataspace(s) available on the RDDMS.\n",
        "2. Select the `demo/Volve` dataspace.\n",
        "3. Find information about horizon interpretations present in the dataspace.\n",
        "4. Retrieve detailed information about the first horizon.\n",
        "5. Use NumPy and Plotly to display the depth values of that horizon.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj9LEwp4uyjb"
      },
      "source": [
        "### 1.1 Locating the RDDMS\n",
        "\n",
        "We define a variable `RDDMS_REST_API` that points to the REST API endpoint of the RDDMS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8IxDv0Ouyjb"
      },
      "outputs": [],
      "source": [
        "RDDMS_REST_API = f\"{osdu_endpoint}/api/reservoir-ddms/v2\"\n",
        "RDDMS_ETP_API = f\"{osdu_endpoint.replace('http', 'ws')}/api/reservoir-ddms-etp/v2/\"\n",
        "\n",
        "try:\n",
        "    response = requests.get(f\"{RDDMS_REST_API}/\")\n",
        "    response.raise_for_status()\n",
        "    green_banner(\"RDDMS REST API is responding.\")\n",
        "except requests.exceptions.RequestException as e:\n",
        "    red_banner(\"Error connecting to RDDMS REST API.\")\n",
        "    print(f\"Error connecting to RDDMS REST API: {e}\")\n",
        "    if e.response is not None:\n",
        "        print(f\"Response Body: {e.response.text}\")\n",
        "\n",
        "print(f\"RDDMS REST API at: {RDDMS_REST_API}/\")\n",
        "print(f\"RDDMS ETP API at: {RDDMS_ETP_API}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqYiM9pQuyjb"
      },
      "source": [
        "### 1.2 Listing All available Dataspaces\n",
        "\n",
        "Retrieve a list of available dataspace(s) in the RDDMS instance.\n",
        "\n",
        "You must be a member of the `service.reservoir-dms.viewers`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2LWQSLmuyjb"
      },
      "outputs": [],
      "source": [
        "# Pre-requisite check\n",
        "all_groups = find_all_group_memberships()\n",
        "rddms_service_viewers = 'service.reservoir-dms.viewers'\n",
        "ok, msg = check_group_membership(rddms_service_viewers, all_groups)\n",
        "if not ok:\n",
        "    detail_text = f\"Please contact your administrator to add you to the group.\"\n",
        "    red_banner(msg, detail_text)\n",
        "\n",
        "# use the GET '/dataspaces' API to list all dataspaces\n",
        "all_dataspaces_response = requests.get(f\"{RDDMS_REST_API}/dataspaces\", headers=get_rddms_header())\n",
        "# print(json.dumps(all_dataspaces_response.json(),indent=4))\n",
        "if all_dataspaces_response.status_code != 200:\n",
        "    detail_text = f\"Error: {all_dataspaces_response.status_code} - {all_dataspaces_response.text}\"\n",
        "    red_banner(f\"Failed to retrieve dataspaces.\", detail_text)\n",
        "\n",
        "# transforming the json array into a pandas dataframe.\n",
        "data_list = all_dataspaces_response.json()\n",
        "\n",
        "if all_dataspaces_response.status_code == 200 :\n",
        "    # Step 1: Extract relevant fields from data_list\n",
        "    data_list_processed = [\n",
        "        {\"Path\": item[\"path\"], \"URI\": item[\"uri\"], \"Created\": item[\"storeCreated\"], \"Updated\": item[\"storeLastWrite\"], \"Locked\" : item[\"customData\"][\"locked\"]}\n",
        "        for item in data_list\n",
        "    ]\n",
        "\n",
        "    # Step 2: Create a DataFrame with the extracted fields\n",
        "    df = pd.DataFrame(data_list_processed )\n",
        "\n",
        "    # Print Dataspaces as a table\n",
        "    pretty_print_panda_frame(df, title=f\"All Dataspaces (Total: {len(df)})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XswoGJ1uyjb"
      },
      "source": [
        "### 1.3 Searching and Selecting `demo/Volve`\n",
        "\n",
        "Search for the `demo/Volve` dataspace and select it for further operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYQF4cJ2uyjb"
      },
      "outputs": [],
      "source": [
        "RDDMS_DATASPACE = 'demo/Volve'\n",
        "try:\n",
        "    SelectedDataspace = next(item for item in all_dataspaces_response.json() if item[\"path\"] == RDDMS_DATASPACE)\n",
        "    dataspace_name = urllib.parse.quote(SelectedDataspace['path'], safe=\"\")\n",
        "    green_banner(f\"DATASPACE '{SelectedDataspace['path']}' SELECTED SUCCESSFULLY\")\n",
        "\n",
        "except:\n",
        "    red_banner(f\"DATASPACE '{RDDMS_DATASPACE}' NOT FOUND\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbFd6pSXuyjb"
      },
      "source": [
        "### 1.4 Printing Data Type Statistics for the Dataspace\n",
        "\n",
        "Display statistics on the data types contained within the `demo/Volve` dataspace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlRC7wHiuyjb"
      },
      "outputs": [],
      "source": [
        "# use the GET 'dataspaces/{dataspace_name}/resources' API to list all resources in the dataspace\n",
        "resources_response = requests.get(f'{RDDMS_REST_API}/dataspaces/{dataspace_name}/resources', headers=get_rddms_header())\n",
        "\n",
        "if resources_response.status_code != 200:\n",
        "    red_banner(f\"Failed to read data from the dataspace '{RDDMS_DATASPACE}'\")\n",
        "\n",
        "#print(json.dumps(response.json(),indent=4))\n",
        "\n",
        "# print all the datatypes in the dataspace\n",
        "response_flat = pd.json_normalize(resources_response.json()).to_dict(orient='records')\n",
        "response_df = pd.DataFrame.from_dict(response_flat)\n",
        "pretty_print_panda_frame(response_df, title=\"All datatypes in the dataspace\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrqB6MJ3uyjb"
      },
      "source": [
        "### 1.5 Listing All Seismic Horizons\n",
        "\n",
        "Retrieve and list all objects of type `resqml20.obj_Grid2dRepresentation`, which is used to represent interpreted Seismic horizons."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGHjJX-xuyjb"
      },
      "outputs": [],
      "source": [
        "# use the GET 'dataspaces/{dataspace_name}/resources/{datatype}' API to list all object of the given datatype\n",
        "resqml_datatype = 'resqml20.obj_Grid2dRepresentation'\n",
        "horizons_response = requests.get(\n",
        "    f'{RDDMS_REST_API}/dataspaces/{dataspace_name}/resources/{resqml_datatype}',\n",
        "    headers=get_rddms_header()\n",
        ")\n",
        "if horizons_response.status_code != 200:\n",
        "    red_banner(f\"Failed to retrieve Interpreted Horizons\")\n",
        "\n",
        "# Extract relevant information from the JSON response\n",
        "horizon_data = horizons_response.json()\n",
        "horizon_table = [\n",
        "    {\n",
        "        \"Horizon Name\": item.get(\"name\", \"N/A\"),\n",
        "        \"Creator Name\": item.get(\"customData\", {}).get(\"creator\", \"N/A\"),\n",
        "        \"Created Date\": item.get(\"customData\", {}).get(\"created\", \"N/A\").split(\"T\")[0],  # Extract only the date part (YYYY-MM-DD)\n",
        "        \"URI\": item.get(\"uri\", \"N/A\")\n",
        "    }\n",
        "    for item in horizon_data\n",
        "]\n",
        "\n",
        "# Convert to a pandas DataFrame for better visualization\n",
        "horizon_df = pd.DataFrame(horizon_table)\n",
        "pretty_print_panda_frame(horizon_df, title=\"All Interpreted Horizons in the dataspace\")\n",
        "\n",
        "# Raw JSon response\n",
        "# print(json.dumps(response.json(),indent=4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxOfS1Ktuyjb"
      },
      "source": [
        "### 1.6 Selecting the First Horizon Interpretation\n",
        "\n",
        "Choose the first horizon interpretation from the available data in the dataspace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imgDwswzuyjb"
      },
      "outputs": [],
      "source": [
        "### Selecting the First Horizon Interpretation\n",
        "# Choose the first horizon interpretation from the available data in the dataspace.\n",
        "################################################\n",
        "\n",
        "SelectedSurface =  1 # first object in dataspace object list\n",
        "horizon_uuid = urllib.parse.quote(horizons_response.json()[SelectedSurface]['uri'].split('(')[-1].replace(')',''))\n",
        "\n",
        "print('First Horizon uuid:', horizon_uuid)\n",
        "#print('Detail record of the first horizon')\n",
        "#print(json.dumps(horizons_response.json()[SelectedSurface],indent=4))\n",
        "\n",
        "def process_horizon_metadata(RDDMS_REST_API, dataspace_name, resqml_datatype, horizon_uuid, headers):\n",
        "    params = {\n",
        "        '$format': 'json',\n",
        "        'arrayMetadata': 'false',\n",
        "        'arrayValues': 'false',\n",
        "        'referencedContent': 'true',\n",
        "    }\n",
        "\n",
        "    # Retrieve metadata for the first horizon\n",
        "    first_horizon_response = requests.get(\n",
        "        f'{RDDMS_REST_API}/dataspaces/{dataspace_name}/resources/{resqml_datatype}/{horizon_uuid}',\n",
        "        params=params,\n",
        "        headers=headers\n",
        "    )\n",
        "    if first_horizon_response.status_code != 200:\n",
        "        red_banner(f\"Failed to retrieve metadata for the first horizon\")\n",
        "        return None, None\n",
        "\n",
        "    def extract_grid_geometry(json_data):\n",
        "        try:\n",
        "            grid_patch = json_data[0][\"Grid2dPatch\"]\n",
        "            # print(f\"Grid2dPatch: {json.dumps(grid_patch, indent=4)}\")\n",
        "            if grid_patch[\"Geometry\"][\"Points\"][\"$type\"] == \"resqml20.Point3dLatticeArray\":\n",
        "                geometry = grid_patch[\"Geometry\"][\"Points\"]\n",
        "            elif grid_patch[\"Geometry\"][\"Points\"][\"$type\"] == \"resqml20.Point3dZValueArray\":\n",
        "                geometry = grid_patch[\"Geometry\"][\"Points\"][\"SupportingGeometry\"][\"SupportingRepresentation\"][\"_data\"][\"Grid2dPatch\"][\"Geometry\"][\"Points\"]\n",
        "            else :\n",
        "                return None\n",
        "\n",
        "            origin = [geometry[\"Origin\"][\"Coordinate1\"], geometry[\"Origin\"][\"Coordinate2\"]]\n",
        "            spacing = [\n",
        "                offset[\"Spacing\"][\"Value\"] for offset in geometry.get(\"Offset\", [])\n",
        "            ]\n",
        "            vectors =[\n",
        "                [offset[\"Offset\"][\"Coordinate1\"], offset[\"Offset\"][\"Coordinate2\"]] for offset in geometry.get(\"Offset\", [])\n",
        "            ]\n",
        "            sizes = [grid_patch[\"FastestAxisCount\"], grid_patch[\"SlowestAxisCount\"]]\n",
        "\n",
        "            u_vector, v_vector = np.array(vectors) * spacing\n",
        "            # Check if the two vectors are orthogonal\n",
        "            dot_product = np.dot(vectors[0], vectors[1])\n",
        "            is_orthogonal = np.isclose(dot_product, 0, atol=1e-6)\n",
        "            print(f\"Are the vectors orthogonal? {'Yes' if is_orthogonal else 'No'}\")\n",
        "\n",
        "            return {\n",
        "                \"Origin\": origin,\n",
        "                \"Vector\": [u_vector, v_vector],\n",
        "                \"Size\": sizes\n",
        "            }\n",
        "        except (KeyError, IndexError, TypeError) as e:\n",
        "            print(f\"Error extracting grid origin: {e}\")\n",
        "            return None\n",
        "\n",
        "    # Extract grid geometry details\n",
        "    horizon_geometry = extract_grid_geometry(first_horizon_response.json())\n",
        "    if not horizon_geometry:\n",
        "        red_banner(f\"Failed to extract grid geometry details\")\n",
        "        return None, None\n",
        "\n",
        "    # Retrieve data arrays for the horizon\n",
        "    arrays_response = requests.get(\n",
        "        f'{RDDMS_REST_API}/dataspaces/{dataspace_name}/resources/{resqml_datatype}/{horizon_uuid}/arrays',\n",
        "        params=params,\n",
        "        headers=headers\n",
        "    )\n",
        "    if arrays_response.status_code != 200:\n",
        "        red_banner(f\"Failed to retrieve data arrays for the horizon\")\n",
        "        return None, None\n",
        "\n",
        "    return horizon_geometry, arrays_response\n",
        "\n",
        "horizon_geometry, arrays_response = process_horizon_metadata(RDDMS_REST_API, dataspace_name, resqml_datatype, horizon_uuid, headers = get_rddms_header())\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(horizon_geometry)\n",
        "pretty_print_panda_frame(df, title=\"Horizon Geometry\", transpose=True, show_index=True, show_header=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKpQcKuOuyjb"
      },
      "source": [
        "### 1.7 Reading the Depth Array values\n",
        "\n",
        "Extract the depth array data from the RDDMS for the selected horizon."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NsWQBMOuyjb"
      },
      "outputs": [],
      "source": [
        "# This code processes the depth array for the selected horizon and calculates statistics.\n",
        "# It retrieves the depth array data, reshapes it, and calculates statistics such as min, max, mean, and standard deviation.\n",
        "# The results are then displayed in a pandas DataFrame for better visualization.\n",
        "\n",
        "def process_horizon_depth_array(RDDMS_REST_API, dataspace_name, resqml_datatype, horizon_uuid, arrays_response, headers):\n",
        "    # Getting the URL encoded of the path to the array.\n",
        "    array_uuid_url = urllib.parse.quote(arrays_response.json()[0]['uid']['pathInResource'], safe=\"\")\n",
        "\n",
        "    params = {\n",
        "        'format': 'json'\n",
        "    }\n",
        "\n",
        "    # use the REST API to return the depth array as a JSON array\n",
        "    array_response = requests.get(\n",
        "        f'{RDDMS_REST_API}/dataspaces/{dataspace_name}/resources/{resqml_datatype}/{horizon_uuid}/arrays/{array_uuid_url}',\n",
        "        params=params,\n",
        "        headers=headers\n",
        "    )\n",
        "\n",
        "    if array_response.status_code != 200:\n",
        "        red_banner(\"Failed to retrieve the depth array\")\n",
        "        return None\n",
        "    return array_response\n",
        "\n",
        "if not arrays_response.json():\n",
        "    red_banner(\"No arrays found for the selected horizon\")\n",
        "else:\n",
        "    array_response = process_horizon_depth_array(RDDMS_REST_API, dataspace_name, resqml_datatype, horizon_uuid, arrays_response, headers=get_rddms_header())\n",
        "    if array_response.status_code != 200:\n",
        "        red_banner(\"Failed to retrieve the depth array\")\n",
        "\n",
        "    # extract the data array size\n",
        "    print('Data length:',len(array_response.json()['data']['data']))\n",
        "    print('Dimensions:',array_response.json()['data']['dimensions'])\n",
        "    if len(array_response.json()['data']['data']) != (int(array_response.json()['data']['dimensions'][0]) * int(array_response.json()['data']['dimensions'][1])):\n",
        "        red_banner(\"Data length does not match the expected dimensions!\")\n",
        "\n",
        "    z_data = np.array(array_response.json()['data']['data'], dtype=np.float32)\n",
        "    # Reshape z_data to match the dimensions and create a DataFrame\n",
        "    z_data_reshaped = z_data.reshape(array_response.json()['data']['dimensions'])\n",
        "    # Calculate statistics for the reshaped data\n",
        "    z_stats = {\n",
        "        \"Min\": [np.min(z_data_reshaped)],\n",
        "        \"Max\": [np.max(z_data_reshaped)],\n",
        "        \"Mean\": [np.mean(z_data_reshaped)],\n",
        "        \"Std Dev\": [np.std(z_data_reshaped)]\n",
        "    }\n",
        "\n",
        "    # Create a DataFrame with the statistics\n",
        "    z_df = pd.DataFrame(z_stats)\n",
        "\n",
        "    # Display the DataFrame with pretty formatting\n",
        "    pretty_print_panda_frame(z_df, title=\"Depth Array Statistics\", transpose=True, show_index=True, show_header=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwdqPHrOuyjb"
      },
      "source": [
        "### 1.8 Using Plotly to Display the Depth Array\n",
        "\n",
        "Visualize the depth array using Plotly to have a 3D representation of the horizon."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MF03ou5Kuyjb"
      },
      "outputs": [],
      "source": [
        "# Returns the X, Y and Z arrays for a given horizon URI\n",
        "def get_horizon_arrays(RDDMS_REST_API, dataspace_name, horizon_uuid, headers):\n",
        "    # Get the metadata for the horizon\n",
        "    geometry, arrays_response = process_horizon_metadata(RDDMS_REST_API, dataspace_name, resqml_datatype, horizon_uuid, headers)\n",
        "\n",
        "    # Build the grid geometry as X and Y 2D arrays\n",
        "    sizes = geometry['Size']\n",
        "    origin = geometry['Origin']\n",
        "    vectors = geometry['Vector']\n",
        "    u_vector, v_vector = np.array(vectors).T\n",
        "    i, j = np.meshgrid(np.arange(sizes[1]), np.arange(sizes[0]), indexing='ij')\n",
        "    X = origin[0] + i * u_vector[0] + j * v_vector[0]\n",
        "    Y = origin[1] + i * u_vector[1] + j * v_vector[1]\n",
        "\n",
        "    if not arrays_response.json():\n",
        "        Z = np.zeros((sizes[1], sizes[0]))\n",
        "    else:\n",
        "        array_response = process_horizon_depth_array(RDDMS_REST_API, dataspace_name, resqml_datatype, horizon_uuid, arrays_response, headers)\n",
        "        z_data = np.array(array_response.json()['data']['data'], dtype=np.float32)\n",
        "        Z = np.reshape(z_data, (int(array_response.json()['data']['dimensions'][0]), int(array_response.json()['data']['dimensions'][1])))\n",
        "\n",
        "    return X, Y, Z\n",
        "\n",
        "\n",
        "horizon_uuid1 = urllib.parse.quote(horizons_response.json()[1]['uri'].split('(')[-1].replace(')',''))\n",
        "\n",
        "X1, Y1, Z1 = get_horizon_arrays(RDDMS_REST_API, dataspace_name, horizon_uuid1, headers=get_rddms_header());\n",
        "\n",
        "# Get the minimum and maximum depth values\n",
        "z_min, z_max = Z1.min(), Z1.max()\n",
        "\n",
        "# Create an interactive 3D surface plot using Plotly\n",
        "fig = go.Figure(data=[\n",
        "    go.Surface(z=Z1, x=X1, y=Y1, colorscale='Viridis', cmin=z_min, cmax=z_max),\n",
        "    ])\n",
        "\n",
        "# Set Z range limits and camera view\n",
        "fig.update_layout(\n",
        "    title='3D Plot of Seismic Horizon',\n",
        "    scene=dict(\n",
        "        xaxis_title='X (m)',\n",
        "        yaxis_title='Y (m)',\n",
        "        zaxis_title='Depth (m)',\n",
        "        zaxis=dict(range=[3200, 2000]),\n",
        "        aspectmode='manual',\n",
        "    ),\n",
        "    width=600,\n",
        "    height=600,\n",
        ")\n",
        "\n",
        "# Show the interactive plot\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joIZGD-uuyjc"
      },
      "source": [
        "## 2. Reading several horizons (2d grid) with FETPAPI\n",
        "FETPAPI is a multilanguages (C++, Java, C# and obviously Python) ETP1.2 client library. It is used with FESAPI which is a multilanguages (C++, Java, C# and obviously Python) RESQML2 client library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdHL32fIuyjc"
      },
      "source": [
        "### 2.1 Setup for FETAPI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WwuSl4euyjc"
      },
      "outputs": [],
      "source": [
        "# Installing Libs needed\n",
        "%pip install fetpapi --quiet\n",
        "\n",
        "# importing python modules used in this notebook\n",
        "import fesapi\n",
        "import fetpapi\n",
        "import uuid\n",
        "import re\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deyC6aR_uyjc"
      },
      "source": [
        "### 2.2 Open an ETP websocket (persisted) session\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApU-Eip9uyjc"
      },
      "outputs": [],
      "source": [
        "initialization_params = fetpapi.InitializationParameters(str(uuid.uuid4()), RDDMS_ETP_API)\n",
        "\n",
        "additionalHeaderField = fetpapi.MapStringString()\n",
        "additionalHeaderField[\"data-partition-id\"] = osdu_data_partition_id\n",
        "initialization_params.setAdditionalHandshakeHeaderFields(additionalHeaderField)\n",
        "\n",
        "client_session = fetpapi.createClientSession(initialization_params, f\"Bearer {get_token()}\")\n",
        "\n",
        "# Run the session in parallel not to block the main thread\n",
        "def start_etp_server(client_session):\n",
        "    client_session.run()\n",
        "\n",
        "from threading import Thread\n",
        "t = Thread(target=start_etp_server, args=(client_session,), daemon=True)\n",
        "t.start()\n",
        "\n",
        "# Wait for the connection to be effective\n",
        "from time import sleep, perf_counter\n",
        "start_time = perf_counter()\n",
        "while client_session.isEtpSessionClosed() and perf_counter() - start_time < 5:\n",
        "    sleep(0.25)\n",
        "if client_session.isEtpSessionClosed():\n",
        "    red_banner(\"The ETP session could not be established in 5 seconds.\")\n",
        "    if not RDDMS_ETP_API.endswith(\"/\"):\n",
        "        print(\"You may try adding an ending slash to OSDU RDDMS URL.\")\n",
        "else:\n",
        "    green_banner(f\"Now connected to OSDU RDDMS at {RDDMS_ETP_API}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXwZodVBuyjc"
      },
      "source": [
        "### 2.3 Create a FESAPI DataObject Repository to store in memory the OSDU horizon\n",
        "We also set it up to deal with the ETP DataArray subprotocol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCUA-edGuyjc"
      },
      "outputs": [],
      "source": [
        "repo = fesapi.DataObjectRepository()\n",
        "# Create a specialized HdfProxy to deal with ETP DataArray subprotocol\n",
        "hdf_proxy_factory = fetpapi.FesapiHdfProxyFactory(client_session)\n",
        "repo.setHdfProxyFactory(hdf_proxy_factory)\n",
        "green_banner(\"FESAPI DataObjectRepository created\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSbIFCO2uyjc"
      },
      "source": [
        "### 2.4 Load all dataobjects from OSDU RDDMS relevant dataspace into the DataObjectRepository\n",
        "Data Arrays are not loaded yet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceu79V4fuyjc"
      },
      "outputs": [],
      "source": [
        "# ETP uri arrays should be given from the catalog search instead\n",
        "etp_uris = [entry['URI'] for entry in horizon_table]\n",
        "\n",
        "# Identifity the dataspace where the data are stored\n",
        "dataspace_uri = re.search(r\"(eml:///dataspace\\('[^']+'\\))\", etp_uris[0]).group(1)\n",
        "if not all(entry['URI'].startswith(dataspace_uri) for entry in horizon_table):\n",
        "    red_banner(f\"All etp uris must be in the same dataspace.\")\n",
        "else :\n",
        "    # Discover all resources from the dataspace\n",
        "    etp_context = fetpapi.ContextInfo()\n",
        "    etp_context.uri = dataspace_uri\n",
        "    etp_context.depth = 1\n",
        "    etp_context.navigableEdges = fetpapi.RelationshipKind_Both\n",
        "    etp_context.includeSecondaryTargets = False\n",
        "    etp_context.includeSecondarySources = False\n",
        "    all_resources = client_session.getResources(etp_context, fetpapi.ContextScopeKind__self)\n",
        "    if all_resources.empty() :\n",
        "        red_banner(f\"There is no resource in dataspace {dataspace_uri}\")\n",
        "    else :\n",
        "        green_banner(f\"There are {str(len(all_resources))} resources in dataspace {dataspace_uri}\")\n",
        "\n",
        "        # Get all data objects from the resources\n",
        "        uriMap = fetpapi.MapStringString();\n",
        "        for index, resource in enumerate(all_resources):\n",
        "            uriMap[str(index)] = resource.uri\n",
        "        all_resources = client_session.getDataObjects(uriMap);\n",
        "        for dataObject in all_resources.values():\n",
        "            repo.addOrReplaceGsoapProxy(dataObject.data, fetpapi.getDataObjectType(dataObject.resource.uri), fetpapi.getDataspaceUri(dataObject.resource.uri))\n",
        "        green_banner(\"Dataspace loaded in memory.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDMRbd2Yuyjc"
      },
      "source": [
        "### 2.5 Reading the Depth Array values\n",
        "\n",
        "Extract the depth array data from the RDDMS for the selected horizons."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4U2VaOu5uyjc"
      },
      "outputs": [],
      "source": [
        "z_data = {}\n",
        "# Loop through the ETP URIs and process each horizon\n",
        "for etp_uri in etp_uris:\n",
        "    horizon_uuid = urllib.parse.quote(etp_uri.split('(')[-1].replace(')',''))\n",
        "    horizon = repo.getDataObjectByUuid(horizon_uuid)\n",
        "\n",
        "    grid2dNodeCount = horizon.getXyzPointCountOfAllPatches()\n",
        "    if isinstance(horizon, fesapi.Resqml2_Grid2dRepresentation):\n",
        "        z_values = fesapi.DoubleArray(grid2dNodeCount)\n",
        "        horizon.getZValues(z_values)\n",
        "\n",
        "        z_data[horizon] = np.empty(grid2dNodeCount, dtype=np.float64)\n",
        "        for i in range(grid2dNodeCount):\n",
        "            z_data[horizon][i] = z_values.getitem(i)\n",
        "\n",
        "        # Calculate statistics for the reshaped data\n",
        "        z_stats = {\n",
        "            \"Min\": [np.nanmin(z_data[horizon])],\n",
        "            \"Max\": [np.nanmax(z_data[horizon])],\n",
        "            \"Mean\": [np.nanmean(z_data[horizon])],\n",
        "            \"Std Dev\": [np.nanstd(z_data[horizon])]\n",
        "        }\n",
        "\n",
        "        # Create a DataFrame with the statistics\n",
        "        z_df = pd.DataFrame(z_stats)\n",
        "\n",
        "        # Display the DataFrame with pretty formatting\n",
        "        pretty_print_panda_frame(z_df, title=f\"Depth Array Statistics of {horizon.getTitle()}\", transpose=True, show_index=True, show_header=False)\n",
        "    else :\n",
        "        red_banner(f\"The UUID {horizon_uuid} does not correspond to a horizon 2d grid.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk5BzpEAuyjc"
      },
      "source": [
        "### 2.6 Reading the first 5 faults of the dataspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YtvM0tiuyjc"
      },
      "outputs": [],
      "source": [
        "fault_x_data = {}\n",
        "fault_y_data = {}\n",
        "fault_z_data = {}\n",
        "\n",
        "all_faults_count = repo.getFaultPolylineSetRepresentationCount()\n",
        "for fault_index in range(min(5, all_faults_count)):\n",
        "    fault = repo.getFaultPolylineSetRepresentation(fault_index)\n",
        "\n",
        "    fault_x_data[fault] = []\n",
        "    fault_y_data[fault] = []\n",
        "    fault_z_data[fault] = []\n",
        "\n",
        "    node_count = fault.getXyzPointCountOfAllPatches()\n",
        "    xyz_values = fesapi.DoubleArray(node_count * 3)\n",
        "    fault.getXyzPointsOfAllPatches(xyz_values)\n",
        "\n",
        "    # Count of polylines in the fault\n",
        "    polyline_count = fault.getPolylineCountOfAllPatches()\n",
        "    # Count of nodes per polyline in the fault\n",
        "    node_count_per_polyline = fesapi.UInt32Array(polyline_count)\n",
        "    fault.getNodeCountPerPolylineOfAllPatches(node_count_per_polyline.cast())\n",
        "\n",
        "    node_index = 0\n",
        "    for polyline_index in range(polyline_count):\n",
        "        # Get the number of nodes in the current polyline\n",
        "        polyline_node_count = node_count_per_polyline.getitem(polyline_index)\n",
        "\n",
        "        fault_x_data[fault].append(np.empty(polyline_node_count, dtype=np.float64))\n",
        "        fault_y_data[fault].append(np.empty(polyline_node_count, dtype=np.float64))\n",
        "        fault_z_data[fault].append(np.empty(polyline_node_count, dtype=np.float64))\n",
        "\n",
        "        for polyline_node_index in range(polyline_node_count):\n",
        "            fault_x_data[fault][polyline_index][polyline_node_index] = xyz_values.getitem(node_index*3)\n",
        "            fault_y_data[fault][polyline_index][polyline_node_index] = xyz_values.getitem(node_index*3+1)\n",
        "            fault_z_data[fault][polyline_index][polyline_node_index] = xyz_values.getitem(node_index*3+2)\n",
        "            node_index += 1\n",
        "\n",
        "    green_banner(f\"Fault {fault.getTitle()} has {polyline_count} polylines\")\n",
        "\n",
        "green_banner(f\"All faults have been loaded in memory.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7nKOqiuuyjc"
      },
      "source": [
        "### 2.7 Close the ETP websocket session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BjrKXiguyjc"
      },
      "outputs": [],
      "source": [
        "client_session.close()\n",
        "green_banner(\"ETP session is now closed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GPcqiBTuyjc"
      },
      "source": [
        "### 2.8 Using Plotly to Display the Depth Arrays\n",
        "\n",
        "Visualize the depth arrays using Plotly to have a 3D representation of the horizons."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhWKLjCYuyjc"
      },
      "outputs": [],
      "source": [
        "surfaces = []\n",
        "\n",
        "global_z_min = float('inf')\n",
        "global_z_max = float('-inf')\n",
        "\n",
        "# Horizons\n",
        "for horizon, z_array in z_data.items():\n",
        "    # Get the minimum and maximum depth values\n",
        "    Z = z_array.reshape(horizon.getNodeCountAlongJAxis(), horizon.getNodeCountAlongIAxis()).transpose()\n",
        "    z_min, z_max = np.nanmin(Z), np.nanmax(Z)\n",
        "    if z_min == z_max and z_min == 0:\n",
        "        print(f\"Skipping horizon {horizon.getTitle()} as all values are the same (zero).\")\n",
        "        continue  # Skip if all values are the same\n",
        "\n",
        "    global_z_min = min(global_z_min, z_min)\n",
        "    global_z_max = max(global_z_max, z_max)\n",
        "\n",
        "show_scale = True\n",
        "for horizon, z_array in z_data.items():\n",
        "    i, j = np.meshgrid(np.arange(horizon.getNodeCountAlongIAxis()), np.arange(horizon.getNodeCountAlongJAxis()), indexing='ij')\n",
        "    X = horizon.getXOrigin() + i * horizon.getXIOffset() + j * horizon.getXJOffset()\n",
        "    Y = horizon.getYOrigin() + i * horizon.getYIOffset() + j * horizon.getYJOffset()\n",
        "    Z = z_array.reshape(horizon.getNodeCountAlongJAxis(), horizon.getNodeCountAlongIAxis()).transpose()\n",
        "\n",
        "    surfaces.append(go.Surface(z=Z, x=X, y=Y, colorscale='Viridis', cmin=global_z_min, cmax=global_z_max, showscale=show_scale, colorbar=dict(title=\"Depth\")))\n",
        "    show_scale = False  # Show color scale only with the first surface\n",
        "\n",
        "# Faults\n",
        "for fault, polyline_set in fault_z_data.items():\n",
        "    random_color = f'rgb({random.randint(0, 255)}, {random.randint(0, 255)}, {random.randint(0, 255)})'\n",
        "    for polyline_index, z_array in enumerate(polyline_set):\n",
        "        # Get the minimum and maximum depth values\n",
        "        z_min, z_max = np.nanmin(z_array), np.nanmax(z_array)\n",
        "\n",
        "        global_z_min = min(global_z_min, z_min)\n",
        "        global_z_max = max(global_z_max, z_max)\n",
        "\n",
        "        surfaces.append(go.Scatter3d(\n",
        "            z=z_array,\n",
        "            x=fault_x_data[fault][polyline_index],\n",
        "            y=fault_y_data[fault][polyline_index],\n",
        "            mode='lines',\n",
        "            line=dict(color=random_color, width=2),\n",
        "            showlegend=False\n",
        "        ))\n",
        "\n",
        "# Create an interactive 3D surface plot using Plotly\n",
        "fig = go.Figure(data=surfaces)\n",
        "\n",
        "# Set Z range limits and camera view\n",
        "fig.update_layout(\n",
        "    title='3D Plot of Seismic Horizons and Faults',\n",
        "    scene=dict(\n",
        "        xaxis_title='X (m)',\n",
        "        yaxis_title='Y (m)',\n",
        "        zaxis_title='Depth (m)',\n",
        "        zaxis=dict(range=[global_z_max, global_z_min]),  # Flip the Z-axis by reversing the range\n",
        "        aspectmode='manual',\n",
        "    ),\n",
        "    width=1200,\n",
        "    height=600\n",
        ")\n",
        "\n",
        "# Show the interactive plot\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuvMGAZyuyjc"
      },
      "source": [
        "## 3. Managing Dataspace\n",
        "Note the user must be  in the `service.reservoir-dms.owners` service group in order to create or delete dataspaces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJ5K2sx_uyjc"
      },
      "source": [
        "### 3.1 Checking Prerequisite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQw5qg2xuyjc"
      },
      "outputs": [],
      "source": [
        "# Define the new dataspace payload\n",
        "rddms_service_owners = f\"service.reservoir-dms.owners\"\n",
        "rddms_service_viewers = f\"service.reservoir-dms.viewers\"\n",
        "data_owners = f\"data.default.owners\"\n",
        "data_viewers = f\"data.default.viewers\"\n",
        "group_names = find_all_group_memberships()\n",
        "ok1, msg1 = check_group_membership(rddms_service_owners, group_names)\n",
        "ok2, msg2 = check_group_membership(rddms_service_viewers, group_names)\n",
        "ok3, msg3 = check_group_membership(data_owners, group_names)\n",
        "ok4, msg4 = check_group_membership(data_viewers, group_names)\n",
        "\n",
        "if ok1 and ok2 and ok3 and ok4:\n",
        "    detail_text = f\"{data_owners},<br> {data_viewers}, <br>{rddms_service_owners} <br>{rddms_service_viewers}\"\n",
        "    green_banner(\"You are member of all required groups.\", detail_text)\n",
        "else:\n",
        "    red_banner(\"You are NOT member of all required groups.\")\n",
        "    print(msg1)\n",
        "    print(msg2)\n",
        "    print(msg3)\n",
        "    print(msg4)\n",
        "\n",
        "if not created_tag_name:\n",
        "    red_banner(f\"Legal  tag'{created_tag_name}' does not exist.\", \"Please create it before proceeding.\")\n",
        "    SystemExit(\"Legal tag does not exist. Please create it before proceeding.\")\n",
        "\n",
        "\n",
        "legal_tag_name = created_tag_name\n",
        "ok4, msg4 = check_legal_tag_exists(legal_tag_name)\n",
        "if ok4:\n",
        "    green_banner(f\"Legal tag `{legal_tag_name}` exists.\")\n",
        "else:\n",
        "    red_banner(f\"Legal  tag'{legal_tag_name}' does not exist.\", \"Please create it before proceeding.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoQ-9t8Auyjc"
      },
      "source": [
        "### 3.2 Creating a new Dataspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZA0qz3E9uyjd"
      },
      "outputs": [],
      "source": [
        "# Define the new dataspace payload\n",
        "user_dataspace_name = f\"rddms_lab/Test_Dataspace_{user_id}\"\n",
        "new_dataspace_payload = [\n",
        "    {\n",
        "        \"DataspaceId\": user_dataspace_name,\n",
        "        \"Path\": user_dataspace_name,\n",
        "        \"CustomData\": {\n",
        "            \"legaltags\": [f\"{legal_tag_name}\"],\n",
        "            \"otherRelevantDataCountries\":[\"US\"],\n",
        "            \"owners\":[f\"data.default.owners@{entitlements_domain}\"],\n",
        "            \"viewers\":[f\"data.default.viewers@{entitlements_domain}\"]\n",
        "        }\n",
        "    }\n",
        "]\n",
        "print(f\"Creating new dataspace: {user_dataspace_name}\")\n",
        "body = json.dumps(new_dataspace_payload)\n",
        "\n",
        "# Make the POST request to create the new dataspace\n",
        "try:\n",
        "    create_dataspace_response = requests.post(\n",
        "        f\"{RDDMS_REST_API}/dataspaces\",\n",
        "        headers=get_rddms_header(),\n",
        "        data=body\n",
        "    )\n",
        "    if create_dataspace_response.status_code == 201:\n",
        "        green_banner(f\"Dataspace '{user_dataspace_name}' created successfully.\")\n",
        "    elif create_dataspace_response.status_code == 400:\n",
        "        green_banner(f\"Dataspace '{user_dataspace_name}' already exists.\")\n",
        "    else:\n",
        "        red_banner(f\"Failed to create dataspace. Status code: {create_dataspace_response.status_code}\")\n",
        "except requests.exceptions.RequestException as e:\n",
        "    red_banner(f\"Error creating dataspace: {e}\")\n",
        "\n",
        "encoded_dataspace_name = urllib.parse.quote(user_dataspace_name, safe=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnx65rZxuyjd"
      },
      "source": [
        "### 3.3 Search the Dataspace using OSDU Search API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Klwuv9i7uyjd"
      },
      "outputs": [],
      "source": [
        "#search by legal tag\n",
        "search_query = {\n",
        "  \"kind\": \"*:wks:dataset--ETPDataspace:*\",\n",
        "  \"query\": f\"legal.legaltags: {legal_tag_name}\",\n",
        "  \"returnedFields\": [ \"id\", \"data.DatasetProperties.URI\", \"legal\" ],\n",
        "  \"trackTotalCount\": True\n",
        "}\n",
        "\n",
        "try:\n",
        "    results = requests.post(f\"{search_endpoint}/query\", headers=get_rddms_header(), json=search_query)\n",
        "    if results.status_code == 200:\n",
        "      if results.json().get('totalCount', 0) == 0:\n",
        "        red_banner(\"No records found for the given legal tag.\")\n",
        "      else:\n",
        "        first_result_id = results.json().get('results', [])[0].get('id', 'N/A')\n",
        "        detail_text = f\"{first_result_id}\"\n",
        "        green_banner(f\"Found {results.json().get('totalCount', 0)} record(s) for the given legal tag.\", detail_text)\n",
        "      for item in results.json().get('results', []):\n",
        "        print(f\"Dataspace URI: {item.get('data', {}).get('DatasetProperties.URI', 'N/A')}\")\n",
        "    else:\n",
        "      red_banner(f\"Search query failed with status code: {results.status_code}\")\n",
        "except Exception as e:\n",
        "    red_banner(f\"Error during search query: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-iuu_4kuyjd"
      },
      "source": [
        "### 3.4 Deleting the Dataspace\n",
        "\n",
        "This part will be covered in the last \"Cleanup for Lab 3\" section since we are going to use the newly generated Dataspace in the following sections.\n",
        "\n",
        "By deferring the deletion to the cleanup phase, we ensure that the Dataspace remains available for all subsequent operations and tests, avoiding any interruptions or errors caused by premature deletion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F2Mz1sEuyjd"
      },
      "source": [
        "## 4. Writting Data to RDDMS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bi1-EYRGuyjd"
      },
      "source": [
        "### 4.1 Starting a Transaction\n",
        "\n",
        "To ensure data integrity, the RDDMS requires all write operations to be performed within a transaction.\n",
        "\n",
        "This approach allows you to prepare the data for the dataspace and ensures that the data is safely pushed when the transaction is committed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZelbDyyYuyjd"
      },
      "outputs": [],
      "source": [
        "response = requests.post(\n",
        "    f\"{RDDMS_REST_API}/dataspaces/{encoded_dataspace_name}/transactions\",\n",
        "    headers=get_rddms_header(),\n",
        ")\n",
        "if response.status_code == 201:\n",
        "    rddms_transaction_id = response.text\n",
        "    green_banner(f\"Transaction created successfully in dataspace '{user_dataspace_name}'.\")\n",
        "else:\n",
        "    red_banner(f\"Failed to create transaction. Status code: {response.status_code}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PkEK8sjuyjd"
      },
      "source": [
        "### 4.2 Pushing PointSet Meta-Data (JSON RESQML Object)\n",
        "\n",
        "Upload a JSON RESQML object to the dataspace by using a transaction ID."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTDs4Fwtuyjd"
      },
      "outputs": [],
      "source": [
        "# this contains a new Points object with 6 XYZ points with the associated CoordinateSystem definition\n",
        "# The array value of XYZ points are stored in an external part.\n",
        "payload = json.dumps([\n",
        "  {\n",
        "    \"Citation\": {\n",
        "      \"Title\": \"CustomTestCrs\",\n",
        "      \"Originator\": \"dalsaab\",\n",
        "      \"Creation\": \"2021-09-02T07:57:28.000Z\",\n",
        "      \"Format\": \"Paradigm SKUA-GOCAD 22 Alpha 1 Build:20210830-0200 (id: origin/master|56050|1fb1cf919c2|20210827-1108) for Linux_x64_2.17_gcc91\",\n",
        "      \"Editor\": \"dalsaab\",\n",
        "      \"LastUpdate\": \"2021-09-06T13:30:24.000Z\"\n",
        "    },\n",
        "    \"YOffset\": 6470000,\n",
        "    \"ZOffset\": 0,\n",
        "    \"ArealRotation\": {\n",
        "      \"_\": 0,\n",
        "      \"$type\": \"eml20.PlaneAngleMeasure\",\n",
        "      \"Uom\": \"rad\"\n",
        "    },\n",
        "    \"ProjectedAxisOrder\": \"easting northing\",\n",
        "    \"ProjectedUom\": \"m\",\n",
        "    \"VerticalUom\": \"m\",\n",
        "    \"XOffset\": 420000,\n",
        "    \"ZIncreasingDownward\": True,\n",
        "    \"VerticalCrs\": {\n",
        "      \"EpsgCode\": 6230,\n",
        "      \"$type\": \"eml20.VerticalCrsEpsgCode\"\n",
        "    },\n",
        "    \"ProjectedCrs\": {\n",
        "      \"EpsgCode\": 23031,\n",
        "      \"$type\": \"eml20.ProjectedCrsEpsgCode\"\n",
        "    },\n",
        "    \"$type\": \"resqml20.obj_LocalDepth3dCrs\",\n",
        "    \"SchemaVersion\": \"2.0\",\n",
        "    \"Uuid\": \"7c7d7987-b7b9-4215-9014-cb7d6fb62173\"\n",
        "  },\n",
        "  {\n",
        "    \"Citation\": {\n",
        "      \"$type\": \"eml20.Citation\",\n",
        "      \"Title\": \"Hdf Proxy\",\n",
        "      \"Originator\": \"Mathieu\",\n",
        "      \"Creation\": \"2014-09-09T15:33:25Z\",\n",
        "      \"Format\": \"[F2I-CONSULTING:resqml2CppApi]\"\n",
        "    },\n",
        "    \"MimeType\": \"application/x-hdf5\",\n",
        "    \"$type\": \"eml20.obj_EpcExternalPartReference\",\n",
        "    \"SchemaVersion\": \"2.0.0.20140822\",\n",
        "    \"Uuid\": \"68f2a7d4-f7c1-4a75-95e9-3c6a7029fb23\"\n",
        "  },\n",
        "  {\n",
        "    \"Citation\": {\n",
        "      \"Title\": \"Pointset 1\",\n",
        "      \"Originator\": \"user1\",\n",
        "      \"Creation\": \"2019-01-08T13:41:25.000Z\",\n",
        "      \"Format\": \"Paradigm SKUA-GOCAD 22 Alpha 1 Build:20210830-0200 (id: origin/master|56050|1fb1cf919c2|20210827-1108) for Linux_x64_2.17_gcc91\",\n",
        "      \"$type\": \"eml20.Citation\"\n",
        "    },\n",
        "    \"ExtraMetadata\": [\n",
        "      {\n",
        "        \"Name\": \"pdgm/dx/resqml/creatorGroup\",\n",
        "        \"Value\": \"Interpreters\",\n",
        "        \"$type\": \"resqml20.NameValuePair\"\n",
        "      }\n",
        "    ],\n",
        "    \"NodePatch\": [\n",
        "      {\n",
        "        \"PatchIndex\": 0,\n",
        "        \"Count\": 6,\n",
        "        \"Geometry\": {\n",
        "          \"$type\": \"resqml20.PointGeometry\",\n",
        "          \"LocalCrs\": {\n",
        "            \"$type\": \"eml20.DataObjectReference\",\n",
        "            \"ContentType\": \"application/x-resqml+xml;version=2.0;type=obj_LocalDepth3dCrs\",\n",
        "            \"Title\": \"CustomTestCrs\",\n",
        "            \"UUID\": \"7c7d7987-b7b9-4215-9014-cb7d6fb62173\"\n",
        "          },\n",
        "          \"Points\": {\n",
        "            \"$type\": \"resqml20.Point3dHdf5Array\",\n",
        "            \"Coordinates\": {\n",
        "              \"$type\": \"eml20.Hdf5Dataset\",\n",
        "              \"PathInHdfFile\": \"/RESQML/5d27775e-5c7f-4786-a048-9a303fa1165a/points_patch0\",\n",
        "              \"HdfProxy\": {\n",
        "                \"$type\": \"eml20.DataObjectReference\",\n",
        "                \"ContentType\": \"application/x-resqml+xml;version=2.0;type=obj_EpcExternalPartReference\",\n",
        "                \"UUID\": \"68f2a7d4-f7c1-4a75-95e9-3c6a7029fb23\",\n",
        "                \"DescriptionString\": \"Hdf Proxy\",\n",
        "                \"VersionString\": \"1410276805\"\n",
        "              }\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    ],\n",
        "    \"$type\": \"resqml20.obj_PointSetRepresentation\",\n",
        "    \"SchemaVersion\": \"2.0.0.20140822\",\n",
        "    \"Uuid\": \"5d27775e-5c7f-4786-a048-9a303fa1165a\"\n",
        "  }\n",
        "])\n",
        "\n",
        "response = requests.put(\n",
        "    f\"{RDDMS_REST_API}/dataspaces/{encoded_dataspace_name}/resources?transactionId={rddms_transaction_id}\",\n",
        "    headers=get_rddms_header(),\n",
        "    data=payload\n",
        ")\n",
        "if response.status_code == 200:\n",
        "    green_banner(\"Resource created successfully.\")\n",
        "else:\n",
        "    red_banner(f\"Failed to create resource. Status code: {response.status_code}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhxS3vH_uyjd"
      },
      "source": [
        "### 4.3 Pushing the PoinSet Data Arrays containing the geometry\n",
        "\n",
        "Upload the missing array data, which contains the XYZ points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQOW9hJkuyjd"
      },
      "outputs": [],
      "source": [
        "# Now push the missing array in the External part containing the XYZ points\n",
        "payload = json.dumps([\n",
        "  {\n",
        "    \"ContainerType\": \"eml20.obj_EpcExternalPartReference\",\n",
        "    \"ContainerUuid\": \"68f2a7d4-f7c1-4a75-95e9-3c6a7029fb23\",\n",
        "    \"PathInResource\": \"/RESQML/5d27775e-5c7f-4786-a048-9a303fa1165a/points_patch0\",\n",
        "    \"Dimensions\": [\n",
        "      3, 6\n",
        "    ],\n",
        "    \"PreferredSubarrayDimensions\": [\n",
        "      3, 1\n",
        "    ],\n",
        "    \"Data\": [\n",
        "      0, 0, 0,\n",
        "      1, 0, 0,\n",
        "      0, 1, 2,\n",
        "      1, 1, 2,\n",
        "      1, 0, 2,\n",
        "      1, 1, 1\n",
        "    ],\n",
        "    \"ArrayType\": \"Float32Array\"\n",
        "  }\n",
        "])\n",
        "\n",
        "response = requests.put(\n",
        "    f\"{RDDMS_REST_API}/dataspaces/{encoded_dataspace_name}/resources/arrays?transactionId={rddms_transaction_id}\",\n",
        "    headers=get_rddms_header(),\n",
        "    data=payload\n",
        ")\n",
        "if response.status_code == 200 :\n",
        "    green_banner(\"Array created successfully.\")\n",
        "else:\n",
        "    red_banner(f\"Failed to create array. Status code: {response.status_code}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyTMGS_2uyjd"
      },
      "source": [
        "### 4.4 Committing to Finalize the Transaction\n",
        "\n",
        "When the commit operation is performed, the dataspace will be temporarily locked for editing.\n",
        "\n",
        "This ensures that no data corruption occurs if two users attempt to push data simultaneously. Any subsequent transactions will be queued and executed only after the first transaction is finalized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZpeiCQDuyjd"
      },
      "outputs": [],
      "source": [
        "response = requests.put(\n",
        "    f\"{RDDMS_REST_API}/dataspaces/{encoded_dataspace_name}/transactions/{rddms_transaction_id}\",\n",
        "    headers=get_rddms_header()\n",
        ")\n",
        "if response.status_code == 200:\n",
        "    green_banner(\"Transaction committed successfully.\")\n",
        "else:\n",
        "    red_banner(f\"Failed to commit transaction. Status code: {response.status_code}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TnyK0wEuyjd"
      },
      "source": [
        "### 4.5 Verifying Data Objects\n",
        "\n",
        "Check that objects and activity have been successfully added to the dataspace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54-UKQ7tuyjd"
      },
      "outputs": [],
      "source": [
        "response = requests.get(\n",
        "    f\"{RDDMS_REST_API}/dataspaces/{encoded_dataspace_name}/resources\",\n",
        "    headers=get_rddms_header()\n",
        ")\n",
        "\n",
        "response_flat = pd.json_normalize(response.json()).to_dict(orient='records')\n",
        "response_df = pd.DataFrame.from_dict(response_flat)\n",
        "pretty_print_panda_frame(response_df, title=f\"All resources in the dataspace \\\"{user_dataspace_name}\\\"\", show_index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRoBgllEuyjd"
      },
      "source": [
        "### 4.6 Optionally Cancelling the Transaction\n",
        "\n",
        "You can cancel the transaction at any time after it has been created.\n",
        "\n",
        "When a transaction is cancelled, all temporary changes prepared during the transaction will be rolled back, and no changes will be submitted to the dataspace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZ6mZXDvuyjd"
      },
      "outputs": [],
      "source": [
        "response = requests.delete(\n",
        "    f\"{RDDMS_REST_API}/dataspaces/{encoded_dataspace_name}/transactions/{rddms_transaction_id}\",\n",
        "    headers=get_rddms_header()\n",
        ")\n",
        "if response.status_code == 200:\n",
        "    green_banner(f\"Transaction deleted successfully in dataspace '{user_dataspace_name}'.\")\n",
        "else:\n",
        "    red_banner(f\"Failed to delete transaction. Status code: {response.status_code}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WaX-doBuyje"
      },
      "source": [
        "## 5. Using the OSDU ETP client docker image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ct78Jtf7uyje"
      },
      "source": [
        "### 5.1 Downloading the Docker image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6Oxcg04uyje"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    # use udocker to run docker commands in Google Colab\n",
        "    #\n",
        "    !pip install --quiet udocker\n",
        "    !adduser --disabled-password --gecos '' udockerrunner\n",
        "    docker_cmd = \"sudo -u udockerrunner udocker\"\n",
        "\n",
        "    # Pull the latest version of the ETP Client from the Open Group registry\n",
        "    !{docker_cmd} pull --registry=https://community.opengroup.org:5555 osdu/platform/domain-data-mgmt-services/reservoir/open-etp-server/open-etp-sslclient-main\n",
        "    !{docker_cmd} tag osdu/platform/domain-data-mgmt-services/reservoir/open-etp-server/open-etp-sslclient-main open-etp-sslclient\n",
        "else:\n",
        "    # use docker to run docker commands in Jupyter Notebook\n",
        "    !pip install --quiet docker\n",
        "    docker_cmd = \"docker\"\n",
        "\n",
        "    # Pull the latest version of the ETP Client from the Open Group registry\n",
        "    !{docker_cmd} pull --quiet community.opengroup.org:5555/osdu/platform/domain-data-mgmt-services/reservoir/open-etp-server/open-etp-sslclient-main\n",
        "    !{docker_cmd} tag community.opengroup.org:5555/osdu/platform/domain-data-mgmt-services/reservoir/open-etp-server/open-etp-sslclient-main open-etp-sslclient\n",
        "\n",
        "# Set the variables to be use for the ETP connection\n",
        "etp_credentials = f\"--server-url {RDDMS_ETP_API} --data-partition-id {osdu_data_partition_id} --auth bearer --jwt-token {get_token()}\"\n",
        "space_root_cmd = f\"/bin/openETPServer space {etp_credentials}\"\n",
        "\n",
        "# List all dataspaces\n",
        "#list_dataspace_cmd = f\"{space_root_cmd} space --list\"\n",
        "#!{docker_cmd} run --rm  --entrypoint=sh open-etp-sslclient -c \"{list_dataspace_cmd}\"\n",
        "\n",
        "green_banner(\"Docker image is ready to be used.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CzRhDYhuyje"
      },
      "outputs": [],
      "source": [
        "# List all dataspaces\n",
        "list_dataspace_cmd = f\"{space_root_cmd} space --list\"\n",
        "!{docker_cmd} run --rm  --entrypoint=sh open-etp-sslclient -c \"{list_dataspace_cmd}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6na0_o1Puyje"
      },
      "source": [
        "### 5.2 Creating the Dataspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pkm_W-Auyje"
      },
      "outputs": [],
      "source": [
        "xdata_acl = {\n",
        "    \"legaltags\": [f\"{legal_tag_name}\"],\n",
        "    \"otherRelevantDataCountries\":[\"US\"],\n",
        "    \"owners\":[f\"data.default.owners@{entitlements_domain}\"],\n",
        "    \"viewers\":[f\"data.default.viewers@{entitlements_domain}\"]\n",
        "    }\n",
        "xdata_acl_json = json.dumps(xdata_acl).replace('\"', '\\\\\"')\n",
        "new_dataspace_cmd = f\"{space_root_cmd} space --new -s {user_dataspace_name} --xdata '{xdata_acl_json}'\"\n",
        "\n",
        "!{docker_cmd} run --rm  --entrypoint=sh open-etp-sslclient -c \"{new_dataspace_cmd}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdEuns25uyje"
      },
      "source": [
        "### 5.3 Pushing RESQML file to the dataspace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljErP9cSuyje"
      },
      "source": [
        "Download sample RESQML files from  OSDU gitlab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avQFi6Zzuyje"
      },
      "outputs": [],
      "source": [
        "# URL of the .epc file to download\n",
        "dataset_repository = \"https://community.opengroup.org/osdu/platform/domain-data-mgmt-services/reservoir/open-etp-server/-/raw/main/data/\"\n",
        "epc_file = \"Volve_Demo_Faults_Depth.epc\"\n",
        "epc_file_url = f\"{dataset_repository}{epc_file}\"\n",
        "\n",
        "# URL of the .hdf5 file to download\n",
        "hdf5_file = \"Volve_Demo_Faults_Depth.h5\"\n",
        "hdf5_file_url = f\"{dataset_repository}{hdf5_file}\"\n",
        "\n",
        "\n",
        "# Function to download a file\n",
        "def download_file(url, save_path):\n",
        "    if os.path.exists(save_path):\n",
        "        print(f\"File already exists at {save_path}. Skipping download.\")\n",
        "        return\n",
        "    response = requests.get(url, stream=True)\n",
        "    if response.ok:\n",
        "        with open(save_path, \"wb\") as file:\n",
        "            file.write(response.content)\n",
        "        print(f\"File downloaded successfully to {save_path}\")\n",
        "    else:\n",
        "        print(f\"Failed to download file from {url}. Status code: {response.status_code}\")\n",
        "\n",
        "# Download both files\n",
        "download_file(hdf5_file_url, hdf5_file)\n",
        "download_file(epc_file_url, epc_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBp8jMQPuyje"
      },
      "source": [
        "Use the OpenETP Client Executable to import the RESQML file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6KgtAbOuyje",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "# Import a RESQML file into a space using the Open ETP SSL client\n",
        "import_resqml_cmd = f\"{space_root_cmd} space -s {user_dataspace_name} --import-epc /data/{epc_file}\"\n",
        "\n",
        "# Mount the local directory containing the RESQML file to the Docker container\n",
        "if IN_COLAB:\n",
        "    !{docker_cmd} run --rm --volume=$(pwd):/data --entrypoint=sh open-etp-sslclient -c \"{import_resqml_cmd}\"\n",
        "else:\n",
        "    !{docker_cmd} run --rm -v .:/data --entrypoint=sh open-etp-sslclient -c \"{import_resqml_cmd}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFU-JNLKuyje"
      },
      "source": [
        "### 5.4 Listing the content of the dataspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65PSjuzmuyje"
      },
      "outputs": [],
      "source": [
        "# Check Dataspace Contents\n",
        "check_dataspace_cmd = f\"{space_root_cmd} space -s {user_dataspace_name} --stats\"\n",
        "print()\n",
        "print(\"-\" * 80)\n",
        "print(f\"Checking contents of dataspace {user_dataspace_name}\")\n",
        "print(\"-\" * 80)\n",
        "!{docker_cmd} run --rm  --entrypoint=sh open-etp-sslclient -c \"{check_dataspace_cmd}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQDPNhMNuyje"
      },
      "source": [
        "## 6. Manifest generation helper and Ingestion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qe7gnC5uyje"
      },
      "source": [
        "## Cleanup for Lab 3\n",
        "\n",
        "This section deletes the resources created during Lab 2 to keep the OSDU instance clean. It attempts to delete:\n",
        "* The InterpretedHorizon record.\n",
        "* The newly created Dataspace\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loP2twMPuyje"
      },
      "source": [
        "**Deleting the newly created Dataspace**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DikZBIMSuyje"
      },
      "outputs": [],
      "source": [
        "if 'user_dataspace_name' in locals() and user_dataspace_name:\n",
        "    try:\n",
        "        print(f\"Deleting dataspace: {user_dataspace_name}\")\n",
        "        encoded_dataspace_name = urllib.parse.quote(user_dataspace_name, safe=\"\")\n",
        "        delete_dataspace_response = requests.delete(\n",
        "            f\"{RDDMS_REST_API}/dataspaces/{encoded_dataspace_name}\",\n",
        "            headers=get_rddms_header()\n",
        "        )\n",
        "        if delete_dataspace_response.status_code == 204:\n",
        "            green_banner(f\"Dataspace '{user_dataspace_name}' deleted successfully.\")\n",
        "        else:\n",
        "            red_banner(f\"Failed to delete dataspace. Status code: {delete_dataspace_response.status_code}\")\n",
        "            # print(f\"Response: {delete_dataspace_response.text}\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        red_banner(f\"Error deleting dataspace: {e}\")\n",
        "else:\n",
        "    green_banner(\"Dataspace name not found.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laNjBsaLuyje"
      },
      "source": [
        "**Deleting the Legal tag**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Nl8ZdA7uyje"
      },
      "outputs": [],
      "source": [
        "# delete the legal tag\n",
        "if 'created_tag_name' in locals() and created_tag_name:\n",
        "    try:\n",
        "        delete_legal_tag_response = requests.delete(\n",
        "            f\"{legal_endpoint}/legaltags/{created_tag_name}\",\n",
        "            headers=get_rddms_header()\n",
        "        )\n",
        "        if delete_legal_tag_response.status_code == 204:\n",
        "            green_banner(f\"Legal tag '{created_tag_name}' deleted successfully.\")\n",
        "        else:\n",
        "            msg = f\"Error: {delete_legal_tag_response.status_code} - {delete_legal_tag_response.text}\"\n",
        "            red_banner(f\"Failed to delete legal tag '{created_tag_name}'.\", msg)\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        red_banner(f\"Error deleting legal tag: {e}\")\n",
        "else:\n",
        "    green_banner(\"Legal tag name not found.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5vIB5rfuyje"
      },
      "source": [
        "**Deleting the locally downloaded RESQML files**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvnA-BGTuyje"
      },
      "outputs": [],
      "source": [
        "if 'epc_file' in locals() and epc_file:\n",
        "    try:\n",
        "        os.remove(epc_file)\n",
        "        os.remove(hdf5_file)\n",
        "        green_banner(f\"Files '{epc_file}' and '{hdf5_file}' deleted successfully.\")\n",
        "    except FileNotFoundError:\n",
        "        green_banner(f\"Files '{epc_file}' and '{hdf5_file}' not found.\")\n",
        "    except Exception as e:\n",
        "        red_banner(f\"Error deleting files: {e}\")\n",
        "else:\n",
        "    green_banner(\"File names not found.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lx2N6m0uyjf"
      },
      "source": [
        "**Deleting the docker images**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBHc7ZJouyjf"
      },
      "outputs": [],
      "source": [
        "if 'docker_cmd' in locals() and docker_cmd:\n",
        "    try:\n",
        "        print(f\"Removing docker image: open-etp-sslclient\")\n",
        "        !{docker_cmd} rmi open-etp-sslclient\n",
        "        !{docker_cmd} rmi osdu/platform/domain-data-mgmt-services/reservoir/open-etp-server/open-etp-sslclient-main:latest\n",
        "        green_banner(\"Docker images removed successfully.\")\n",
        "    except Exception as e:\n",
        "        red_banner(f\"Error removing docker image: {e}\")\n",
        "\n",
        "    if IN_COLAB:\n",
        "        # Remove the created user\n",
        "        try:\n",
        "            print(f\"Removing user: udockerrunner\")\n",
        "            !deluser --remove-home udockerrunner\n",
        "            green_banner(\"User 'udockerrunner' removed successfully.\")\n",
        "        except Exception as e:\n",
        "            red_banner(f\"Error removing user: {e}\")\n",
        "else:\n",
        "    green_banner(\"Docker command not found.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "_MzlmMYIuoXZ"
      ],
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}